{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet5_CIFAR.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmsaYn+TIrsmPWHICHbVdr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JKJIN1999/LeNet5_CIFAR10/blob/main/LeNet5_CIFAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LeNet5 for CIFAR dataset**\n",
        "### This project will explain how to build up a LeNet5 for CIFAR dataset\n",
        "\n",
        "### *Must set the runtime to GPU!* \n",
        "\n",
        "\n",
        "### The process will be as \n",
        "1.  Import requirements\n",
        "2.  Download CIFAR dataset and preprocessing\n",
        "3.  Create LeNet5 model for CIFAR10 \n",
        "4.  Initialize Training, Evaluating process\n",
        "5.  Train the Model and Test\n",
        "6.  \n",
        "7.  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pa2C050PjioA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import requirements"
      ],
      "metadata": {
        "id": "kP1DLk9qn-D1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "qrYdsqHKjIsC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.utils as utils\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.optim import lr_scheduler\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Download CIFAR dataset and preprocessing"
      ],
      "metadata": {
        "id": "34SRC_EToAvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data image horizontal & Vertical flippping and padding the image for random cropping (delete the horizontal flip if you desire)\n",
        "transforms_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        # the arguments inside the normalization is the mean and standard deviation value specifically for CIFAR dataset (https://github.com/kuangliu/pytorch-cifar/issues/19)\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))  \n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))  \n",
        "])\n",
        "\n",
        "train_validation_data = torchvision.datasets.CIFAR10(root='./dataset/', train=True, transform=transforms_train, download=True)\n",
        "train_data, validation_data = torch.utils.data.random_split(train_validation_data, [40000, 10000])\n",
        "test_data = dsets.CIFAR10(root='./dataset/', train=False, transform=transforms_test, download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset = train_data, batch_size = 64, shuffle = True)\n",
        "validation_loader = DataLoader(dataset = validation_data, batch_size = 64, shuffle=False)\n",
        "test_loader = DataLoader(dataset = test_data, batch_size = 64, shuffle=False )\n",
        "\n",
        "# Classify Labels\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "rand = random.randint(0,500)\n",
        "image, label = train_data[rand]\n",
        "\n",
        "print(\"Sample Image Tensor\")\n",
        "print(image)\n",
        "print(\"Shape of this image is : {}\".format(image.shape))\n",
        "# need to transpose the image matrix since the shape is changed from tensor for training\n",
        "plt.imshow(np.transpose(image, (1,2,0)))\n",
        "plt.title(\"Lable : {}\".format(classes[label]))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "COInisE-oAyg",
        "outputId": "c7d7e6ef-1f6d-494c-cb4a-bc700d9a6d78"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Image Tensor\n",
            "tensor([[[-1.9895, -1.9895, -1.9895,  ..., -1.9895, -1.9895, -1.9895],\n",
            "         [-1.9895, -1.9895, -1.9895,  ..., -1.9895, -1.9895, -1.9895],\n",
            "         [-1.9895, -1.9895, -1.9895,  ..., -1.9895, -1.9895, -1.9895],\n",
            "         ...,\n",
            "         [-1.9895, -1.9895, -1.9895,  ...,  1.6939,  1.5828,  1.5987],\n",
            "         [-1.9895, -1.9895, -1.9895,  ...,  1.5669,  1.4875,  1.5352],\n",
            "         [-1.9895, -1.9895, -1.9895,  ...,  1.6939,  1.6304,  1.6304]],\n",
            "\n",
            "        [[-1.9844, -1.9844, -1.9844,  ..., -1.9844, -1.9844, -1.9844],\n",
            "         [-1.9844, -1.9844, -1.9844,  ..., -1.9844, -1.9844, -1.9844],\n",
            "         [-1.9844, -1.9844, -1.9844,  ..., -1.9844, -1.9844, -1.9844],\n",
            "         ...,\n",
            "         [-1.9844, -1.9844, -1.9844,  ...,  1.6144,  1.4531,  1.5015],\n",
            "         [-1.9844, -1.9844, -1.9844,  ...,  1.5983,  1.4369,  1.4531],\n",
            "         [-1.9844, -1.9844, -1.9844,  ...,  1.7435,  1.6629,  1.6144]],\n",
            "\n",
            "        [[-1.7107, -1.7107, -1.7107,  ..., -1.7107, -1.7107, -1.7107],\n",
            "         [-1.7107, -1.7107, -1.7107,  ..., -1.7107, -1.7107, -1.7107],\n",
            "         [-1.7107, -1.7107, -1.7107,  ..., -1.7107, -1.7107, -1.7107],\n",
            "         ...,\n",
            "         [-1.7107, -1.7107, -1.7107,  ...,  1.1591,  0.9788,  0.9788],\n",
            "         [-1.7107, -1.7107, -1.7107,  ...,  1.1441,  0.9638,  1.0088],\n",
            "         [-1.7107, -1.7107, -1.7107,  ...,  1.3093,  1.1891,  1.1441]]])\n",
            "Shape of this image is : torch.Size([3, 32, 32])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of dataset \n",
        "print(\"Training Data size : {}\".format(len(train_data)))\n",
        "print(\"Validation Data size : {}\".format(len(validation_data)))\n",
        "print(\"Testing Data size : {}\".format(len(test_data)))\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HxhwsQS381L",
        "outputId": "affc99b6-ef11-445c-98c7-4b0b8d17283d"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data size : 40000\n",
            "Validation Data size : 10000\n",
            "Testing Data size : 10000\n",
            "True\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Create LeNet5 for CIFAR10 model"
      ],
      "metadata": {
        "id": "nydVEMd8xLTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer1 = nn.Conv2d(3, 6, kernel_size = 5)\n",
        "    self.layer2 = nn.Conv2d(6, 16, kernel_size = 5)\n",
        "    self.layer3 = nn.Linear(400, 120)\n",
        "    self.layer4 = nn.Linear(120, 84)\n",
        "    self.layer5 = nn.Linear(84, 10)\n",
        "    self.avg_pool = nn.AvgPool2d(2,2)\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.tanh(out)\n",
        "    out = self.avg_pool(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.tanh(out)\n",
        "    out = self.avg_pool(out)\n",
        "    out = self.layer3(out.view(out.size(0), -1))\n",
        "    out = self.relu(out)\n",
        "    out = self.layer4(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.layer5(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "# Hyper_Parameters\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = LeNet5().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001,  momentum=0.9, weight_decay=1e-04)\n",
        "\n"
      ],
      "metadata": {
        "id": "99mnkB6H5IZX"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Initialize Training, Evaluation process\n"
      ],
      "metadata": {
        "id": "Bamskf0viKpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, criterion, optimizer):\n",
        "  loss_array = []\n",
        "  model.train()\n",
        "\n",
        "  # enumerate is a built-in function for python where you can use both the index and the value from list or array through each loop\n",
        "  for i ,(image, label) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    output = model(image)\n",
        "    loss = criterion(output, label)\n",
        "    loss_array.append(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Evaluating each 100 steps within 64 batch-size. Thus, after training 6400 images, this will print out\n",
        "    if (i+1) % 100 == 0:\n",
        "      print('Average Loss for {} iteration is : {}'.format( i+1 , sum(loss_array)/len(loss_array)))\n",
        "      loss_array = []\n",
        "\n",
        "def evaluation(validation_loader, model):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for i , (image, label) in enumerate(validation_loader):\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      output = model(image)\n",
        "      _ , predicted = torch.max(output.data, 1)\n",
        "      correct += (predicted == label).sum().item()\n",
        "      total += label.size(0)\n",
        "\n",
        "  return correct/total\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wuBHrLWxiTN1"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why we use both model.eval(), torch.with no_grad() \n",
        "1. model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n",
        "2. torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script)."
      ],
      "metadata": {
        "id": "uU__wpO-89Yl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Train Model and Test"
      ],
      "metadata": {
        "id": "sRP-urLwVYpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for  _ in range(1000):\n",
        "  train(train_loader, model, criterion, optimizer)\n",
        "  accuracy = evaluation(validation_loader, model)\n",
        "  print('Evaluation Accuracy is : {}'.format(accuracy))\n",
        "\n",
        "test_acc = evaluation(test_loader, model)\n",
        "print('Test Accuracy is : {}'.format(test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VZNEnuQVgug",
        "outputId": "a74f6b31-1e08-4ea2-dc1a-bcc10ba34acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for 100 iteration is : 1.9936450028419495\n",
            "Average Loss for 200 iteration is : 1.9896110343933104\n",
            "Average Loss for 300 iteration is : 1.9764859187602997\n",
            "Average Loss for 400 iteration is : 1.965882362127304\n",
            "Average Loss for 500 iteration is : 1.9338435745239257\n",
            "Average Loss for 600 iteration is : 1.9402586615085602\n",
            "Evaluation Accuracy is : 0.2866\n",
            "Average Loss for 100 iteration is : 1.9254053580760955\n",
            "Average Loss for 200 iteration is : 1.9123211848735808\n",
            "Average Loss for 300 iteration is : 1.9130331254005433\n",
            "Average Loss for 400 iteration is : 1.8975920808315276\n",
            "Average Loss for 500 iteration is : 1.886900645494461\n",
            "Average Loss for 600 iteration is : 1.8860277366638183\n",
            "Evaluation Accuracy is : 0.3178\n",
            "Average Loss for 100 iteration is : 1.8901944088935851\n",
            "Average Loss for 200 iteration is : 1.861287739276886\n",
            "Average Loss for 300 iteration is : 1.8687576150894165\n",
            "Average Loss for 400 iteration is : 1.8627811574935913\n",
            "Average Loss for 500 iteration is : 1.841053568124771\n",
            "Average Loss for 600 iteration is : 1.849801094532013\n",
            "Evaluation Accuracy is : 0.3273\n",
            "Average Loss for 100 iteration is : 1.8345542752742767\n",
            "Average Loss for 200 iteration is : 1.8438195979595184\n",
            "Average Loss for 300 iteration is : 1.8320779824256896\n",
            "Average Loss for 400 iteration is : 1.8359996950626374\n",
            "Average Loss for 500 iteration is : 1.8088798093795777\n",
            "Average Loss for 600 iteration is : 1.8133997011184693\n",
            "Evaluation Accuracy is : 0.3378\n",
            "Average Loss for 100 iteration is : 1.8032037425041199\n",
            "Average Loss for 200 iteration is : 1.79376220703125\n",
            "Average Loss for 300 iteration is : 1.803317071199417\n",
            "Average Loss for 400 iteration is : 1.7892459666728973\n",
            "Average Loss for 500 iteration is : 1.79308256149292\n",
            "Average Loss for 600 iteration is : 1.7861118376255036\n",
            "Evaluation Accuracy is : 0.3423\n",
            "Average Loss for 100 iteration is : 1.768201289176941\n",
            "Average Loss for 200 iteration is : 1.776830756664276\n",
            "Average Loss for 300 iteration is : 1.7755807650089264\n",
            "Average Loss for 400 iteration is : 1.7811784934997559\n",
            "Average Loss for 500 iteration is : 1.755408741235733\n",
            "Average Loss for 600 iteration is : 1.7625904488563537\n",
            "Evaluation Accuracy is : 0.3585\n",
            "Average Loss for 100 iteration is : 1.7581613183021545\n",
            "Average Loss for 200 iteration is : 1.7617703914642333\n",
            "Average Loss for 300 iteration is : 1.7310909581184388\n",
            "Average Loss for 400 iteration is : 1.743042013645172\n",
            "Average Loss for 500 iteration is : 1.7205664038658142\n",
            "Average Loss for 600 iteration is : 1.7237521135807037\n",
            "Evaluation Accuracy is : 0.376\n",
            "Average Loss for 100 iteration is : 1.7187243437767028\n",
            "Average Loss for 200 iteration is : 1.7181350827217101\n",
            "Average Loss for 300 iteration is : 1.7118895900249482\n",
            "Average Loss for 400 iteration is : 1.7082259619235993\n",
            "Average Loss for 500 iteration is : 1.7206191289424897\n",
            "Average Loss for 600 iteration is : 1.6944121098518372\n",
            "Evaluation Accuracy is : 0.374\n",
            "Average Loss for 100 iteration is : 1.695757998228073\n",
            "Average Loss for 200 iteration is : 1.7055804336071014\n",
            "Average Loss for 300 iteration is : 1.7005481445789337\n",
            "Average Loss for 400 iteration is : 1.6961499404907228\n",
            "Average Loss for 500 iteration is : 1.6708774864673615\n",
            "Average Loss for 600 iteration is : 1.6727306127548218\n",
            "Evaluation Accuracy is : 0.3908\n",
            "Average Loss for 100 iteration is : 1.6688760554790496\n",
            "Average Loss for 200 iteration is : 1.6636088860034943\n",
            "Average Loss for 300 iteration is : 1.654635306596756\n",
            "Average Loss for 400 iteration is : 1.6577648031711578\n",
            "Average Loss for 500 iteration is : 1.6492338848114014\n",
            "Average Loss for 600 iteration is : 1.6392182195186615\n",
            "Evaluation Accuracy is : 0.399\n",
            "Average Loss for 100 iteration is : 1.6364528357982635\n",
            "Average Loss for 200 iteration is : 1.6186789500713348\n",
            "Average Loss for 300 iteration is : 1.611999627351761\n",
            "Average Loss for 400 iteration is : 1.6279269528388978\n",
            "Average Loss for 500 iteration is : 1.6289952898025513\n",
            "Average Loss for 600 iteration is : 1.6143890309333802\n",
            "Evaluation Accuracy is : 0.4063\n",
            "Average Loss for 100 iteration is : 1.6214481747150422\n",
            "Average Loss for 200 iteration is : 1.6045931005477905\n",
            "Average Loss for 300 iteration is : 1.602177152633667\n",
            "Average Loss for 400 iteration is : 1.5739568650722504\n",
            "Average Loss for 500 iteration is : 1.5749006545543671\n",
            "Average Loss for 600 iteration is : 1.5729809725284576\n",
            "Evaluation Accuracy is : 0.4169\n",
            "Average Loss for 100 iteration is : 1.5703263199329376\n",
            "Average Loss for 200 iteration is : 1.5824208116531373\n",
            "Average Loss for 300 iteration is : 1.5717940080165862\n",
            "Average Loss for 400 iteration is : 1.5814763498306275\n",
            "Average Loss for 500 iteration is : 1.5744816875457763\n",
            "Average Loss for 600 iteration is : 1.5551264810562133\n",
            "Evaluation Accuracy is : 0.4336\n",
            "Average Loss for 100 iteration is : 1.568256198167801\n",
            "Average Loss for 200 iteration is : 1.5371591806411744\n",
            "Average Loss for 300 iteration is : 1.5588437628746032\n",
            "Average Loss for 400 iteration is : 1.5265914285182953\n",
            "Average Loss for 500 iteration is : 1.5508007001876831\n",
            "Average Loss for 600 iteration is : 1.5657555079460144\n",
            "Evaluation Accuracy is : 0.4349\n",
            "Average Loss for 100 iteration is : 1.5339457869529725\n",
            "Average Loss for 200 iteration is : 1.548216574192047\n",
            "Average Loss for 300 iteration is : 1.5223412382602692\n",
            "Average Loss for 400 iteration is : 1.5368299579620361\n",
            "Average Loss for 500 iteration is : 1.5220707190036773\n",
            "Average Loss for 600 iteration is : 1.5365541088581085\n",
            "Evaluation Accuracy is : 0.4435\n",
            "Average Loss for 100 iteration is : 1.5151125597953796\n",
            "Average Loss for 200 iteration is : 1.5160046923160553\n",
            "Average Loss for 300 iteration is : 1.5131778597831727\n",
            "Average Loss for 400 iteration is : 1.533104865550995\n",
            "Average Loss for 500 iteration is : 1.525115624666214\n",
            "Average Loss for 600 iteration is : 1.5175254249572754\n",
            "Evaluation Accuracy is : 0.4449\n",
            "Average Loss for 100 iteration is : 1.513758441209793\n",
            "Average Loss for 200 iteration is : 1.5103455209732055\n",
            "Average Loss for 300 iteration is : 1.5101793313026428\n",
            "Average Loss for 400 iteration is : 1.5091059470176698\n",
            "Average Loss for 500 iteration is : 1.4870294892787934\n",
            "Average Loss for 600 iteration is : 1.4964652204513549\n",
            "Evaluation Accuracy is : 0.4505\n",
            "Average Loss for 100 iteration is : 1.5046945524215698\n",
            "Average Loss for 200 iteration is : 1.4793782114982605\n",
            "Average Loss for 300 iteration is : 1.4656455540657043\n",
            "Average Loss for 400 iteration is : 1.4839787673950195\n",
            "Average Loss for 500 iteration is : 1.4712907457351685\n",
            "Average Loss for 600 iteration is : 1.5062376379966735\n",
            "Evaluation Accuracy is : 0.4563\n",
            "Average Loss for 100 iteration is : 1.473905977010727\n",
            "Average Loss for 200 iteration is : 1.4838975811004638\n",
            "Average Loss for 300 iteration is : 1.4795536875724793\n",
            "Average Loss for 400 iteration is : 1.4552401101589203\n",
            "Average Loss for 500 iteration is : 1.4815736532211303\n",
            "Average Loss for 600 iteration is : 1.4598287880420684\n",
            "Evaluation Accuracy is : 0.4659\n",
            "Average Loss for 100 iteration is : 1.4673334813117982\n",
            "Average Loss for 200 iteration is : 1.4452412009239197\n",
            "Average Loss for 300 iteration is : 1.4576325964927674\n",
            "Average Loss for 400 iteration is : 1.4331500661373138\n",
            "Average Loss for 500 iteration is : 1.4647175145149232\n",
            "Average Loss for 600 iteration is : 1.4613980436325074\n",
            "Evaluation Accuracy is : 0.4726\n",
            "Average Loss for 100 iteration is : 1.4547362005710602\n",
            "Average Loss for 200 iteration is : 1.469738745689392\n",
            "Average Loss for 300 iteration is : 1.4806232452392578\n",
            "Average Loss for 400 iteration is : 1.4377469635009765\n",
            "Average Loss for 500 iteration is : 1.4218629276752472\n",
            "Average Loss for 600 iteration is : 1.425320075750351\n",
            "Evaluation Accuracy is : 0.4692\n",
            "Average Loss for 100 iteration is : 1.4490447425842286\n",
            "Average Loss for 200 iteration is : 1.4386971378326416\n",
            "Average Loss for 300 iteration is : 1.4293483877182007\n",
            "Average Loss for 400 iteration is : 1.427219260931015\n",
            "Average Loss for 500 iteration is : 1.4340435469150543\n",
            "Average Loss for 600 iteration is : 1.4227225172519684\n",
            "Evaluation Accuracy is : 0.4738\n",
            "Average Loss for 100 iteration is : 1.4138244366645814\n",
            "Average Loss for 200 iteration is : 1.4394539058208466\n",
            "Average Loss for 300 iteration is : 1.4138285195827485\n",
            "Average Loss for 400 iteration is : 1.4372133266925813\n",
            "Average Loss for 500 iteration is : 1.4086573803424836\n",
            "Average Loss for 600 iteration is : 1.4209717059135436\n",
            "Evaluation Accuracy is : 0.4815\n",
            "Average Loss for 100 iteration is : 1.4084378170967102\n",
            "Average Loss for 200 iteration is : 1.4204921793937684\n",
            "Average Loss for 300 iteration is : 1.403512111902237\n",
            "Average Loss for 400 iteration is : 1.4240989482402802\n",
            "Average Loss for 500 iteration is : 1.4234417653083802\n",
            "Average Loss for 600 iteration is : 1.3902052247524261\n",
            "Evaluation Accuracy is : 0.4859\n",
            "Average Loss for 100 iteration is : 1.4063867497444154\n",
            "Average Loss for 200 iteration is : 1.4007343244552612\n",
            "Average Loss for 300 iteration is : 1.4001027297973634\n",
            "Average Loss for 400 iteration is : 1.4206537437438964\n",
            "Average Loss for 500 iteration is : 1.3938174510002137\n",
            "Average Loss for 600 iteration is : 1.3756309270858764\n",
            "Evaluation Accuracy is : 0.4888\n",
            "Average Loss for 100 iteration is : 1.3834449899196626\n",
            "Average Loss for 200 iteration is : 1.4023143291473388\n",
            "Average Loss for 300 iteration is : 1.3766097545623779\n",
            "Average Loss for 400 iteration is : 1.3958272516727448\n",
            "Average Loss for 500 iteration is : 1.399937469959259\n",
            "Average Loss for 600 iteration is : 1.369265662431717\n",
            "Evaluation Accuracy is : 0.4841\n",
            "Average Loss for 100 iteration is : 1.3796488094329833\n",
            "Average Loss for 200 iteration is : 1.386477130651474\n",
            "Average Loss for 300 iteration is : 1.375315877199173\n",
            "Average Loss for 400 iteration is : 1.393447415828705\n",
            "Average Loss for 500 iteration is : 1.3521079218387604\n",
            "Average Loss for 600 iteration is : 1.4070731723308563\n",
            "Evaluation Accuracy is : 0.5019\n",
            "Average Loss for 100 iteration is : 1.3746351611614227\n",
            "Average Loss for 200 iteration is : 1.3691540229320527\n",
            "Average Loss for 300 iteration is : 1.3553940486907958\n",
            "Average Loss for 400 iteration is : 1.3560437119007112\n",
            "Average Loss for 500 iteration is : 1.3618314719200135\n",
            "Average Loss for 600 iteration is : 1.3864396548271178\n",
            "Evaluation Accuracy is : 0.4958\n",
            "Average Loss for 100 iteration is : 1.3528532898426056\n",
            "Average Loss for 200 iteration is : 1.3650254237651824\n",
            "Average Loss for 300 iteration is : 1.35802321434021\n",
            "Average Loss for 400 iteration is : 1.37344948887825\n",
            "Average Loss for 500 iteration is : 1.3430679166316986\n",
            "Average Loss for 600 iteration is : 1.346791940331459\n",
            "Evaluation Accuracy is : 0.4986\n",
            "Average Loss for 100 iteration is : 1.3454486680030824\n",
            "Average Loss for 200 iteration is : 1.389798035621643\n",
            "Average Loss for 300 iteration is : 1.3442015421390534\n",
            "Average Loss for 400 iteration is : 1.3577584087848664\n",
            "Average Loss for 500 iteration is : 1.3295042705535889\n",
            "Average Loss for 600 iteration is : 1.3140680015087127\n",
            "Evaluation Accuracy is : 0.504\n",
            "Average Loss for 100 iteration is : 1.3412403285503387\n",
            "Average Loss for 200 iteration is : 1.3418266046047211\n",
            "Average Loss for 300 iteration is : 1.3343223321437836\n",
            "Average Loss for 400 iteration is : 1.3807703232765198\n",
            "Average Loss for 500 iteration is : 1.332369270324707\n",
            "Average Loss for 600 iteration is : 1.3195968973636627\n",
            "Evaluation Accuracy is : 0.5146\n",
            "Average Loss for 100 iteration is : 1.3184373021125793\n",
            "Average Loss for 200 iteration is : 1.3428467035293579\n",
            "Average Loss for 300 iteration is : 1.3335653126239777\n",
            "Average Loss for 400 iteration is : 1.3260248374938965\n",
            "Average Loss for 500 iteration is : 1.3610262513160705\n",
            "Average Loss for 600 iteration is : 1.3121489530801773\n",
            "Evaluation Accuracy is : 0.5068\n",
            "Average Loss for 100 iteration is : 1.2892686712741852\n",
            "Average Loss for 200 iteration is : 1.3410718977451324\n",
            "Average Loss for 300 iteration is : 1.3257196545600891\n",
            "Average Loss for 400 iteration is : 1.3522923612594604\n",
            "Average Loss for 500 iteration is : 1.3131581962108612\n",
            "Average Loss for 600 iteration is : 1.3264112854003907\n",
            "Evaluation Accuracy is : 0.5023\n",
            "Average Loss for 100 iteration is : 1.3138893485069274\n",
            "Average Loss for 200 iteration is : 1.3259871637821197\n",
            "Average Loss for 300 iteration is : 1.3115550673007965\n",
            "Average Loss for 400 iteration is : 1.2932294178009034\n",
            "Average Loss for 500 iteration is : 1.3125664436817168\n",
            "Average Loss for 600 iteration is : 1.3129633498191833\n",
            "Evaluation Accuracy is : 0.5195\n",
            "Average Loss for 100 iteration is : 1.3088309228420258\n",
            "Average Loss for 200 iteration is : 1.3204985713958741\n",
            "Average Loss for 300 iteration is : 1.3314425623416901\n",
            "Average Loss for 400 iteration is : 1.296430189013481\n",
            "Average Loss for 500 iteration is : 1.2889726132154464\n",
            "Average Loss for 600 iteration is : 1.3066138088703156\n",
            "Evaluation Accuracy is : 0.5156\n",
            "Average Loss for 100 iteration is : 1.3083963346481324\n",
            "Average Loss for 200 iteration is : 1.306951720714569\n",
            "Average Loss for 300 iteration is : 1.2697031092643738\n",
            "Average Loss for 400 iteration is : 1.2943073213100433\n",
            "Average Loss for 500 iteration is : 1.305724908709526\n",
            "Average Loss for 600 iteration is : 1.304834857583046\n",
            "Evaluation Accuracy is : 0.5248\n",
            "Average Loss for 100 iteration is : 1.30337677359581\n",
            "Average Loss for 200 iteration is : 1.29503597676754\n",
            "Average Loss for 300 iteration is : 1.2848283994197844\n",
            "Average Loss for 400 iteration is : 1.2858744668960571\n",
            "Average Loss for 500 iteration is : 1.2652037715911866\n",
            "Average Loss for 600 iteration is : 1.292145665884018\n",
            "Evaluation Accuracy is : 0.529\n",
            "Average Loss for 100 iteration is : 1.2774894887208939\n",
            "Average Loss for 200 iteration is : 1.3102627956867219\n",
            "Average Loss for 300 iteration is : 1.2823225736618042\n",
            "Average Loss for 400 iteration is : 1.274073430299759\n",
            "Average Loss for 500 iteration is : 1.2670225811004638\n",
            "Average Loss for 600 iteration is : 1.3005618846416473\n",
            "Evaluation Accuracy is : 0.5249\n",
            "Average Loss for 100 iteration is : 1.2721808326244355\n",
            "Average Loss for 200 iteration is : 1.2697943878173827\n",
            "Average Loss for 300 iteration is : 1.2700417459011077\n",
            "Average Loss for 400 iteration is : 1.2896629989147186\n",
            "Average Loss for 500 iteration is : 1.255077776312828\n",
            "Average Loss for 600 iteration is : 1.28101507127285\n",
            "Evaluation Accuracy is : 0.5296\n",
            "Average Loss for 100 iteration is : 1.2555174964666367\n",
            "Average Loss for 200 iteration is : 1.2892067313194275\n",
            "Average Loss for 300 iteration is : 1.2806485265493393\n",
            "Average Loss for 400 iteration is : 1.242406953573227\n",
            "Average Loss for 500 iteration is : 1.275109521150589\n",
            "Average Loss for 600 iteration is : 1.237646324634552\n",
            "Evaluation Accuracy is : 0.5316\n",
            "Average Loss for 100 iteration is : 1.3041180461645125\n",
            "Average Loss for 200 iteration is : 1.236375368833542\n",
            "Average Loss for 300 iteration is : 1.2588085877895354\n",
            "Average Loss for 400 iteration is : 1.2522416770458222\n",
            "Average Loss for 500 iteration is : 1.256261095404625\n",
            "Average Loss for 600 iteration is : 1.2654200309515\n",
            "Evaluation Accuracy is : 0.5317\n",
            "Average Loss for 100 iteration is : 1.246397031545639\n",
            "Average Loss for 200 iteration is : 1.241067231297493\n",
            "Average Loss for 300 iteration is : 1.2506909269094466\n",
            "Average Loss for 400 iteration is : 1.277103098630905\n",
            "Average Loss for 500 iteration is : 1.2615058028697967\n",
            "Average Loss for 600 iteration is : 1.2532564914226532\n",
            "Evaluation Accuracy is : 0.5382\n",
            "Average Loss for 100 iteration is : 1.24464260160923\n",
            "Average Loss for 200 iteration is : 1.266505160331726\n",
            "Average Loss for 300 iteration is : 1.2563541799783706\n",
            "Average Loss for 400 iteration is : 1.2548215240240097\n",
            "Average Loss for 500 iteration is : 1.243373354077339\n",
            "Average Loss for 600 iteration is : 1.234764405488968\n",
            "Evaluation Accuracy is : 0.5365\n",
            "Average Loss for 100 iteration is : 1.248779096007347\n",
            "Average Loss for 200 iteration is : 1.2447372430562973\n",
            "Average Loss for 300 iteration is : 1.2461258727312088\n",
            "Average Loss for 400 iteration is : 1.2344217598438263\n",
            "Average Loss for 500 iteration is : 1.2615087485313417\n",
            "Average Loss for 600 iteration is : 1.2401083809137345\n",
            "Evaluation Accuracy is : 0.5294\n",
            "Average Loss for 100 iteration is : 1.2386908650398254\n",
            "Average Loss for 200 iteration is : 1.249694042801857\n",
            "Average Loss for 300 iteration is : 1.2267708545923233\n",
            "Average Loss for 400 iteration is : 1.2481505799293517\n",
            "Average Loss for 500 iteration is : 1.244093251824379\n",
            "Average Loss for 600 iteration is : 1.2232739275693894\n",
            "Evaluation Accuracy is : 0.5405\n",
            "Average Loss for 100 iteration is : 1.2163629627227783\n",
            "Average Loss for 200 iteration is : 1.214672023653984\n",
            "Average Loss for 300 iteration is : 1.2526504278182984\n",
            "Average Loss for 400 iteration is : 1.2329946368932725\n",
            "Average Loss for 500 iteration is : 1.2472944623231887\n",
            "Average Loss for 600 iteration is : 1.2353809726238252\n",
            "Evaluation Accuracy is : 0.5448\n",
            "Average Loss for 100 iteration is : 1.2058257758617401\n",
            "Average Loss for 200 iteration is : 1.230642883181572\n",
            "Average Loss for 300 iteration is : 1.2347375857830047\n",
            "Average Loss for 400 iteration is : 1.2240134143829347\n",
            "Average Loss for 500 iteration is : 1.2151325505971908\n",
            "Average Loss for 600 iteration is : 1.2368409883975984\n",
            "Evaluation Accuracy is : 0.5447\n",
            "Average Loss for 100 iteration is : 1.2115394639968873\n",
            "Average Loss for 200 iteration is : 1.20724096596241\n",
            "Average Loss for 300 iteration is : 1.20968590259552\n",
            "Average Loss for 400 iteration is : 1.2239920687675476\n",
            "Average Loss for 500 iteration is : 1.212039875984192\n",
            "Average Loss for 600 iteration is : 1.24685562312603\n",
            "Evaluation Accuracy is : 0.5462\n",
            "Average Loss for 100 iteration is : 1.209641084074974\n",
            "Average Loss for 200 iteration is : 1.2213101428747177\n",
            "Average Loss for 300 iteration is : 1.204341202378273\n",
            "Average Loss for 400 iteration is : 1.207802562713623\n",
            "Average Loss for 500 iteration is : 1.218024645447731\n",
            "Average Loss for 600 iteration is : 1.2115352261066437\n",
            "Evaluation Accuracy is : 0.5595\n",
            "Average Loss for 100 iteration is : 1.1786681151390075\n",
            "Average Loss for 200 iteration is : 1.2307257795333861\n",
            "Average Loss for 300 iteration is : 1.2327746146917342\n",
            "Average Loss for 400 iteration is : 1.1979483127593995\n",
            "Average Loss for 500 iteration is : 1.2100128895044326\n",
            "Average Loss for 600 iteration is : 1.2008405536413194\n",
            "Evaluation Accuracy is : 0.5553\n",
            "Average Loss for 100 iteration is : 1.183910481929779\n",
            "Average Loss for 200 iteration is : 1.2123859894275666\n",
            "Average Loss for 300 iteration is : 1.2019893002510071\n",
            "Average Loss for 400 iteration is : 1.2018724799156189\n",
            "Average Loss for 500 iteration is : 1.2227012932300567\n",
            "Average Loss for 600 iteration is : 1.178526154756546\n",
            "Evaluation Accuracy is : 0.5556\n",
            "Average Loss for 100 iteration is : 1.2047573590278626\n",
            "Average Loss for 200 iteration is : 1.217309736609459\n",
            "Average Loss for 300 iteration is : 1.2135255497694015\n",
            "Average Loss for 400 iteration is : 1.190292747616768\n",
            "Average Loss for 500 iteration is : 1.2124215042591096\n",
            "Average Loss for 600 iteration is : 1.1649474143981933\n",
            "Evaluation Accuracy is : 0.5631\n",
            "Average Loss for 100 iteration is : 1.1902582955360412\n",
            "Average Loss for 200 iteration is : 1.1896374368667602\n",
            "Average Loss for 300 iteration is : 1.2074599087238311\n",
            "Average Loss for 400 iteration is : 1.2015546280145646\n",
            "Average Loss for 500 iteration is : 1.2135474652051925\n",
            "Average Loss for 600 iteration is : 1.2107677417993545\n",
            "Evaluation Accuracy is : 0.5547\n",
            "Average Loss for 100 iteration is : 1.2035298573970794\n",
            "Average Loss for 200 iteration is : 1.199777917265892\n",
            "Average Loss for 300 iteration is : 1.1906160628795623\n",
            "Average Loss for 400 iteration is : 1.1984218776226043\n",
            "Average Loss for 500 iteration is : 1.1668965566158294\n",
            "Average Loss for 600 iteration is : 1.2124960392713546\n",
            "Evaluation Accuracy is : 0.5568\n",
            "Average Loss for 100 iteration is : 1.186948266029358\n",
            "Average Loss for 200 iteration is : 1.1842856574058533\n",
            "Average Loss for 300 iteration is : 1.1981180959939957\n",
            "Average Loss for 400 iteration is : 1.1758339303731917\n",
            "Average Loss for 500 iteration is : 1.1872129154205322\n",
            "Average Loss for 600 iteration is : 1.169293510913849\n",
            "Evaluation Accuracy is : 0.5593\n",
            "Average Loss for 100 iteration is : 1.1791963064670563\n",
            "Average Loss for 200 iteration is : 1.1957822501659394\n",
            "Average Loss for 300 iteration is : 1.171865581870079\n",
            "Average Loss for 400 iteration is : 1.196353810429573\n",
            "Average Loss for 500 iteration is : 1.1731387478113176\n",
            "Average Loss for 600 iteration is : 1.180077273249626\n",
            "Evaluation Accuracy is : 0.5562\n",
            "Average Loss for 100 iteration is : 1.1774185234308243\n",
            "Average Loss for 200 iteration is : 1.1659112733602524\n",
            "Average Loss for 300 iteration is : 1.1860492384433747\n",
            "Average Loss for 400 iteration is : 1.193541818857193\n",
            "Average Loss for 500 iteration is : 1.1809353357553483\n",
            "Average Loss for 600 iteration is : 1.1730687111616134\n",
            "Evaluation Accuracy is : 0.5631\n",
            "Average Loss for 100 iteration is : 1.1584131091833114\n",
            "Average Loss for 200 iteration is : 1.1834765589237213\n",
            "Average Loss for 300 iteration is : 1.1680308765172958\n",
            "Average Loss for 400 iteration is : 1.1812380760908128\n",
            "Average Loss for 500 iteration is : 1.1900536185503006\n",
            "Average Loss for 600 iteration is : 1.1810214459896087\n",
            "Evaluation Accuracy is : 0.5627\n",
            "Average Loss for 100 iteration is : 1.1829360234737396\n",
            "Average Loss for 200 iteration is : 1.1636978685855865\n",
            "Average Loss for 300 iteration is : 1.1800986325740814\n",
            "Average Loss for 400 iteration is : 1.1869110971689225\n",
            "Average Loss for 500 iteration is : 1.1738789695501328\n",
            "Average Loss for 600 iteration is : 1.1534471803903579\n",
            "Evaluation Accuracy is : 0.5627\n",
            "Average Loss for 100 iteration is : 1.1701556807756424\n",
            "Average Loss for 200 iteration is : 1.1603375762701034\n",
            "Average Loss for 300 iteration is : 1.1669450569152833\n",
            "Average Loss for 400 iteration is : 1.1708315068483353\n",
            "Average Loss for 500 iteration is : 1.1854322576522827\n",
            "Average Loss for 600 iteration is : 1.1653522330522537\n",
            "Evaluation Accuracy is : 0.5724\n",
            "Average Loss for 100 iteration is : 1.146646037697792\n",
            "Average Loss for 200 iteration is : 1.1677890038490295\n",
            "Average Loss for 300 iteration is : 1.1702389669418336\n",
            "Average Loss for 400 iteration is : 1.1587102395296096\n",
            "Average Loss for 500 iteration is : 1.174533149600029\n",
            "Average Loss for 600 iteration is : 1.1869429886341094\n",
            "Evaluation Accuracy is : 0.5681\n",
            "Average Loss for 100 iteration is : 1.1782070618867875\n",
            "Average Loss for 200 iteration is : 1.1499213695526123\n",
            "Average Loss for 300 iteration is : 1.1609762763977052\n",
            "Average Loss for 400 iteration is : 1.1616766023635865\n",
            "Average Loss for 500 iteration is : 1.1728927344083786\n",
            "Average Loss for 600 iteration is : 1.1652387952804566\n",
            "Evaluation Accuracy is : 0.5623\n",
            "Average Loss for 100 iteration is : 1.1465492939949036\n",
            "Average Loss for 200 iteration is : 1.1685389083623887\n",
            "Average Loss for 300 iteration is : 1.150265280008316\n",
            "Average Loss for 400 iteration is : 1.152680876851082\n",
            "Average Loss for 500 iteration is : 1.1717180216312408\n",
            "Average Loss for 600 iteration is : 1.1644519478082658\n",
            "Evaluation Accuracy is : 0.5706\n",
            "Average Loss for 100 iteration is : 1.1337211161851883\n",
            "Average Loss for 200 iteration is : 1.1645423793792724\n",
            "Average Loss for 300 iteration is : 1.1618888592720031\n",
            "Average Loss for 400 iteration is : 1.1591111075878144\n",
            "Average Loss for 500 iteration is : 1.148340654373169\n",
            "Average Loss for 600 iteration is : 1.1713887184858323\n",
            "Evaluation Accuracy is : 0.5732\n",
            "Average Loss for 100 iteration is : 1.1631784558296203\n",
            "Average Loss for 200 iteration is : 1.1494636446237565\n",
            "Average Loss for 300 iteration is : 1.153683187365532\n",
            "Average Loss for 400 iteration is : 1.1833630669116975\n",
            "Average Loss for 500 iteration is : 1.1409587699174881\n",
            "Average Loss for 600 iteration is : 1.1286574310064317\n",
            "Evaluation Accuracy is : 0.5672\n",
            "Average Loss for 100 iteration is : 1.153563814163208\n",
            "Average Loss for 200 iteration is : 1.1524719494581221\n",
            "Average Loss for 300 iteration is : 1.1693794214725495\n",
            "Average Loss for 400 iteration is : 1.1453178006410598\n",
            "Average Loss for 500 iteration is : 1.1371941447257996\n",
            "Average Loss for 600 iteration is : 1.1479056286811828\n",
            "Evaluation Accuracy is : 0.5725\n",
            "Average Loss for 100 iteration is : 1.1327048629522323\n",
            "Average Loss for 200 iteration is : 1.1335341501235963\n",
            "Average Loss for 300 iteration is : 1.1319508856534959\n",
            "Average Loss for 400 iteration is : 1.166009560227394\n",
            "Average Loss for 500 iteration is : 1.1294725680351256\n",
            "Average Loss for 600 iteration is : 1.1597536158561708\n",
            "Evaluation Accuracy is : 0.5766\n",
            "Average Loss for 100 iteration is : 1.131851191520691\n",
            "Average Loss for 200 iteration is : 1.1546249878406525\n",
            "Average Loss for 300 iteration is : 1.146088045835495\n",
            "Average Loss for 400 iteration is : 1.1137765800952912\n",
            "Average Loss for 500 iteration is : 1.1526384311914444\n",
            "Average Loss for 600 iteration is : 1.1456051725149154\n",
            "Evaluation Accuracy is : 0.5797\n",
            "Average Loss for 100 iteration is : 1.1397373592853546\n",
            "Average Loss for 200 iteration is : 1.1412928158044815\n",
            "Average Loss for 300 iteration is : 1.1319678974151612\n",
            "Average Loss for 400 iteration is : 1.137306231856346\n",
            "Average Loss for 500 iteration is : 1.1416009563207625\n",
            "Average Loss for 600 iteration is : 1.1362874948978423\n",
            "Evaluation Accuracy is : 0.5808\n",
            "Average Loss for 100 iteration is : 1.1176112282276154\n",
            "Average Loss for 200 iteration is : 1.1119607073068618\n",
            "Average Loss for 300 iteration is : 1.1520537912845612\n",
            "Average Loss for 400 iteration is : 1.1242815887928008\n",
            "Average Loss for 500 iteration is : 1.138971239924431\n",
            "Average Loss for 600 iteration is : 1.1383044987916946\n",
            "Evaluation Accuracy is : 0.5798\n",
            "Average Loss for 100 iteration is : 1.1048756837844849\n",
            "Average Loss for 200 iteration is : 1.1173312574625016\n",
            "Average Loss for 300 iteration is : 1.1379015839099884\n",
            "Average Loss for 400 iteration is : 1.1490519779920578\n",
            "Average Loss for 500 iteration is : 1.1081037408113479\n",
            "Average Loss for 600 iteration is : 1.127356561422348\n",
            "Evaluation Accuracy is : 0.5746\n",
            "Average Loss for 100 iteration is : 1.120139285326004\n",
            "Average Loss for 200 iteration is : 1.1444301187992096\n",
            "Average Loss for 300 iteration is : 1.105604378581047\n",
            "Average Loss for 400 iteration is : 1.1314902210235596\n",
            "Average Loss for 500 iteration is : 1.1537953317165375\n",
            "Average Loss for 600 iteration is : 1.1319290137290954\n",
            "Evaluation Accuracy is : 0.5798\n",
            "Average Loss for 100 iteration is : 1.1075994294881821\n",
            "Average Loss for 200 iteration is : 1.1229571044445037\n",
            "Average Loss for 300 iteration is : 1.15698401927948\n",
            "Average Loss for 400 iteration is : 1.1222205173969269\n",
            "Average Loss for 500 iteration is : 1.1447107213735581\n",
            "Average Loss for 600 iteration is : 1.1219865101575852\n",
            "Evaluation Accuracy is : 0.584\n",
            "Average Loss for 100 iteration is : 1.1060455322265625\n",
            "Average Loss for 200 iteration is : 1.1341454368829726\n",
            "Average Loss for 300 iteration is : 1.1192205184698105\n",
            "Average Loss for 400 iteration is : 1.1213260775804519\n",
            "Average Loss for 500 iteration is : 1.1278151363134383\n",
            "Average Loss for 600 iteration is : 1.124445127248764\n",
            "Evaluation Accuracy is : 0.5818\n",
            "Average Loss for 100 iteration is : 1.1171349096298218\n",
            "Average Loss for 200 iteration is : 1.1122788852453231\n",
            "Average Loss for 300 iteration is : 1.1103179728984833\n",
            "Average Loss for 400 iteration is : 1.1203598469495772\n",
            "Average Loss for 500 iteration is : 1.1167039149999618\n",
            "Average Loss for 600 iteration is : 1.1170490735769272\n",
            "Evaluation Accuracy is : 0.5783\n",
            "Average Loss for 100 iteration is : 1.102983329296112\n",
            "Average Loss for 200 iteration is : 1.1348509496450425\n",
            "Average Loss for 300 iteration is : 1.1195124262571334\n",
            "Average Loss for 400 iteration is : 1.112177129983902\n",
            "Average Loss for 500 iteration is : 1.1127930438518525\n",
            "Average Loss for 600 iteration is : 1.1045695751905442\n",
            "Evaluation Accuracy is : 0.5795\n",
            "Average Loss for 100 iteration is : 1.1040646922588349\n",
            "Average Loss for 200 iteration is : 1.1192630058526993\n",
            "Average Loss for 300 iteration is : 1.1084537941217423\n",
            "Average Loss for 400 iteration is : 1.1170588284730911\n",
            "Average Loss for 500 iteration is : 1.1359801572561263\n",
            "Average Loss for 600 iteration is : 1.0994983118772508\n",
            "Evaluation Accuracy is : 0.5795\n",
            "Average Loss for 100 iteration is : 1.1189007711410524\n",
            "Average Loss for 200 iteration is : 1.093652873635292\n",
            "Average Loss for 300 iteration is : 1.0931595021486282\n",
            "Average Loss for 400 iteration is : 1.1108709007501603\n",
            "Average Loss for 500 iteration is : 1.130886270403862\n",
            "Average Loss for 600 iteration is : 1.1185882139205932\n",
            "Evaluation Accuracy is : 0.5904\n",
            "Average Loss for 100 iteration is : 1.1149488282203674\n",
            "Average Loss for 200 iteration is : 1.0991243356466294\n",
            "Average Loss for 300 iteration is : 1.093799375295639\n",
            "Average Loss for 400 iteration is : 1.1069292324781417\n",
            "Average Loss for 500 iteration is : 1.1139615470170974\n",
            "Average Loss for 600 iteration is : 1.1098092859983444\n",
            "Evaluation Accuracy is : 0.5925\n",
            "Average Loss for 100 iteration is : 1.109359986782074\n",
            "Average Loss for 200 iteration is : 1.0858454900979995\n",
            "Average Loss for 300 iteration is : 1.1109649169445037\n",
            "Average Loss for 400 iteration is : 1.0979643476009369\n",
            "Average Loss for 500 iteration is : 1.118184118270874\n",
            "Average Loss for 600 iteration is : 1.1068830764293671\n",
            "Evaluation Accuracy is : 0.5887\n",
            "Average Loss for 100 iteration is : 1.1089242494106293\n",
            "Average Loss for 200 iteration is : 1.0883052885532378\n",
            "Average Loss for 300 iteration is : 1.1120627254247666\n",
            "Average Loss for 400 iteration is : 1.1110013335943223\n",
            "Average Loss for 500 iteration is : 1.1223174929618835\n",
            "Average Loss for 600 iteration is : 1.0965456283092498\n",
            "Evaluation Accuracy is : 0.5792\n",
            "Average Loss for 100 iteration is : 1.1071420568227768\n",
            "Average Loss for 200 iteration is : 1.0936521834135056\n",
            "Average Loss for 300 iteration is : 1.0853682440519332\n",
            "Average Loss for 400 iteration is : 1.1119128221273422\n",
            "Average Loss for 500 iteration is : 1.0859472000598906\n",
            "Average Loss for 600 iteration is : 1.1188612455129623\n",
            "Evaluation Accuracy is : 0.5817\n",
            "Average Loss for 100 iteration is : 1.0919759666919708\n",
            "Average Loss for 200 iteration is : 1.0871826672554017\n",
            "Average Loss for 300 iteration is : 1.0801334983110429\n",
            "Average Loss for 400 iteration is : 1.0900602948665619\n",
            "Average Loss for 500 iteration is : 1.0955724692344666\n",
            "Average Loss for 600 iteration is : 1.1239451664686202\n",
            "Evaluation Accuracy is : 0.5906\n",
            "Average Loss for 100 iteration is : 1.1016028612852096\n",
            "Average Loss for 200 iteration is : 1.1117834824323654\n",
            "Average Loss for 300 iteration is : 1.0955399483442307\n",
            "Average Loss for 400 iteration is : 1.0918763381242753\n",
            "Average Loss for 500 iteration is : 1.0890463000535966\n",
            "Average Loss for 600 iteration is : 1.0813930451869964\n",
            "Evaluation Accuracy is : 0.592\n",
            "Average Loss for 100 iteration is : 1.107072981595993\n",
            "Average Loss for 200 iteration is : 1.0861772620677947\n",
            "Average Loss for 300 iteration is : 1.0600063824653625\n",
            "Average Loss for 400 iteration is : 1.108952419757843\n",
            "Average Loss for 500 iteration is : 1.0917352044582367\n",
            "Average Loss for 600 iteration is : 1.100357354283333\n",
            "Evaluation Accuracy is : 0.5946\n",
            "Average Loss for 100 iteration is : 1.0751852190494537\n",
            "Average Loss for 200 iteration is : 1.1009040516614914\n",
            "Average Loss for 300 iteration is : 1.1054702693223952\n",
            "Average Loss for 400 iteration is : 1.0725317496061324\n",
            "Average Loss for 500 iteration is : 1.1002985429763794\n",
            "Average Loss for 600 iteration is : 1.0842191278934479\n",
            "Evaluation Accuracy is : 0.5898\n",
            "Average Loss for 100 iteration is : 1.0974895536899567\n",
            "Average Loss for 200 iteration is : 1.0790168839693068\n",
            "Average Loss for 300 iteration is : 1.0688781428337097\n",
            "Average Loss for 400 iteration is : 1.1054473423957825\n",
            "Average Loss for 500 iteration is : 1.090591118335724\n",
            "Average Loss for 600 iteration is : 1.0844104182720185\n",
            "Evaluation Accuracy is : 0.5948\n",
            "Average Loss for 100 iteration is : 1.0717167854309082\n",
            "Average Loss for 200 iteration is : 1.0599467074871063\n",
            "Average Loss for 300 iteration is : 1.075141237974167\n",
            "Average Loss for 400 iteration is : 1.113444555401802\n",
            "Average Loss for 500 iteration is : 1.078092001080513\n",
            "Average Loss for 600 iteration is : 1.1154486966133117\n",
            "Evaluation Accuracy is : 0.6037\n",
            "Average Loss for 100 iteration is : 1.0842901748418807\n",
            "Average Loss for 200 iteration is : 1.072784313559532\n",
            "Average Loss for 300 iteration is : 1.0683637964725494\n",
            "Average Loss for 400 iteration is : 1.0933333879709244\n",
            "Average Loss for 500 iteration is : 1.060965477824211\n",
            "Average Loss for 600 iteration is : 1.0791432881355285\n",
            "Evaluation Accuracy is : 0.5949\n",
            "Average Loss for 100 iteration is : 1.0895530092716217\n",
            "Average Loss for 200 iteration is : 1.0936736929416657\n",
            "Average Loss for 300 iteration is : 1.0621595752239228\n",
            "Average Loss for 400 iteration is : 1.0790125435590745\n",
            "Average Loss for 500 iteration is : 1.0549132192134858\n",
            "Average Loss for 600 iteration is : 1.060093693137169\n",
            "Evaluation Accuracy is : 0.5967\n",
            "Average Loss for 100 iteration is : 1.09517920255661\n",
            "Average Loss for 200 iteration is : 1.0606638205051422\n",
            "Average Loss for 300 iteration is : 1.0736781531572341\n",
            "Average Loss for 400 iteration is : 1.0682480686903\n",
            "Average Loss for 500 iteration is : 1.0723647809028625\n",
            "Average Loss for 600 iteration is : 1.0957884687185286\n",
            "Evaluation Accuracy is : 0.5806\n",
            "Average Loss for 100 iteration is : 1.052728264927864\n",
            "Average Loss for 200 iteration is : 1.0623100179433822\n",
            "Average Loss for 300 iteration is : 1.0806798559427262\n",
            "Average Loss for 400 iteration is : 1.059296314716339\n",
            "Average Loss for 500 iteration is : 1.0814118546247482\n",
            "Average Loss for 600 iteration is : 1.0748023295402527\n",
            "Evaluation Accuracy is : 0.5946\n",
            "Average Loss for 100 iteration is : 1.064617287516594\n",
            "Average Loss for 200 iteration is : 1.085710996389389\n",
            "Average Loss for 300 iteration is : 1.048185031414032\n",
            "Average Loss for 400 iteration is : 1.0672606152296067\n",
            "Average Loss for 500 iteration is : 1.0840934318304063\n",
            "Average Loss for 600 iteration is : 1.066578049659729\n",
            "Evaluation Accuracy is : 0.603\n",
            "Average Loss for 100 iteration is : 1.0764343219995498\n",
            "Average Loss for 200 iteration is : 1.0379312241077423\n",
            "Average Loss for 300 iteration is : 1.0854927664995193\n",
            "Average Loss for 400 iteration is : 1.0846290749311447\n",
            "Average Loss for 500 iteration is : 1.0853941255807877\n",
            "Average Loss for 600 iteration is : 1.0627177214622499\n",
            "Evaluation Accuracy is : 0.5944\n",
            "Average Loss for 100 iteration is : 1.0703312599658965\n",
            "Average Loss for 200 iteration is : 1.058644419312477\n",
            "Average Loss for 300 iteration is : 1.0723392111063004\n",
            "Average Loss for 400 iteration is : 1.0603395646810532\n",
            "Average Loss for 500 iteration is : 1.0656551098823548\n",
            "Average Loss for 600 iteration is : 1.0720833593606949\n",
            "Evaluation Accuracy is : 0.6021\n",
            "Average Loss for 100 iteration is : 1.0595102548599242\n",
            "Average Loss for 200 iteration is : 1.0548298823833466\n",
            "Average Loss for 300 iteration is : 1.0420254129171371\n",
            "Average Loss for 400 iteration is : 1.068328628540039\n",
            "Average Loss for 500 iteration is : 1.074389835000038\n",
            "Average Loss for 600 iteration is : 1.0934085416793824\n",
            "Evaluation Accuracy is : 0.6023\n",
            "Average Loss for 100 iteration is : 1.0759859132766723\n",
            "Average Loss for 200 iteration is : 1.0357720094919205\n",
            "Average Loss for 300 iteration is : 1.0745645952224732\n",
            "Average Loss for 400 iteration is : 1.0927441757917404\n",
            "Average Loss for 500 iteration is : 1.0507821333408356\n",
            "Average Loss for 600 iteration is : 1.0449218386411667\n",
            "Evaluation Accuracy is : 0.6022\n",
            "Average Loss for 100 iteration is : 1.0812022471427918\n",
            "Average Loss for 200 iteration is : 1.0695888113975525\n",
            "Average Loss for 300 iteration is : 1.028412492275238\n",
            "Average Loss for 400 iteration is : 1.0383166944980622\n",
            "Average Loss for 500 iteration is : 1.0491275799274444\n",
            "Average Loss for 600 iteration is : 1.0696877080202103\n",
            "Evaluation Accuracy is : 0.6029\n",
            "Average Loss for 100 iteration is : 1.0505208206176757\n",
            "Average Loss for 200 iteration is : 1.0754861080646514\n",
            "Average Loss for 300 iteration is : 1.0696493524312973\n",
            "Average Loss for 400 iteration is : 1.0478768104314804\n",
            "Average Loss for 500 iteration is : 1.0545004266500473\n",
            "Average Loss for 600 iteration is : 1.0505858486890793\n",
            "Evaluation Accuracy is : 0.6009\n",
            "Average Loss for 100 iteration is : 1.0729447638988494\n",
            "Average Loss for 200 iteration is : 1.0454165107011795\n",
            "Average Loss for 300 iteration is : 1.05196353495121\n",
            "Average Loss for 400 iteration is : 1.0720736503601074\n",
            "Average Loss for 500 iteration is : 1.0524274325370788\n",
            "Average Loss for 600 iteration is : 1.0526491266489029\n",
            "Evaluation Accuracy is : 0.6064\n",
            "Average Loss for 100 iteration is : 1.0638629305362701\n",
            "Average Loss for 200 iteration is : 1.0601749700307845\n",
            "Average Loss for 300 iteration is : 1.0669534170627595\n",
            "Average Loss for 400 iteration is : 1.0435002571344376\n",
            "Average Loss for 500 iteration is : 1.063172333240509\n",
            "Average Loss for 600 iteration is : 1.0542463797330857\n",
            "Evaluation Accuracy is : 0.6059\n",
            "Average Loss for 100 iteration is : 1.064142284989357\n",
            "Average Loss for 200 iteration is : 1.0643414151668549\n",
            "Average Loss for 300 iteration is : 1.047088692188263\n",
            "Average Loss for 400 iteration is : 1.0427470886707306\n",
            "Average Loss for 500 iteration is : 1.053487092256546\n",
            "Average Loss for 600 iteration is : 1.0543503880500793\n",
            "Evaluation Accuracy is : 0.5999\n",
            "Average Loss for 100 iteration is : 1.0542036002874375\n",
            "Average Loss for 200 iteration is : 1.0423435908555985\n",
            "Average Loss for 300 iteration is : 1.0494872611761092\n",
            "Average Loss for 400 iteration is : 1.031529358625412\n",
            "Average Loss for 500 iteration is : 1.0507077139616012\n",
            "Average Loss for 600 iteration is : 1.0729047852754592\n",
            "Evaluation Accuracy is : 0.6032\n",
            "Average Loss for 100 iteration is : 1.0580020654201507\n",
            "Average Loss for 200 iteration is : 1.046490398645401\n",
            "Average Loss for 300 iteration is : 1.045178137421608\n",
            "Average Loss for 400 iteration is : 1.041568363904953\n",
            "Average Loss for 500 iteration is : 1.0435223829746247\n",
            "Average Loss for 600 iteration is : 1.0601838570833206\n",
            "Evaluation Accuracy is : 0.6037\n",
            "Average Loss for 100 iteration is : 1.0372407120466232\n",
            "Average Loss for 200 iteration is : 1.0506903612613678\n",
            "Average Loss for 300 iteration is : 1.0430322808027268\n",
            "Average Loss for 400 iteration is : 1.0574971896409988\n",
            "Average Loss for 500 iteration is : 1.053538323044777\n",
            "Average Loss for 600 iteration is : 1.0434230661392212\n",
            "Evaluation Accuracy is : 0.6142\n",
            "Average Loss for 100 iteration is : 1.0274492871761323\n",
            "Average Loss for 200 iteration is : 1.054729677438736\n",
            "Average Loss for 300 iteration is : 1.0690052330493927\n",
            "Average Loss for 400 iteration is : 1.0462974411249162\n",
            "Average Loss for 500 iteration is : 1.043846406340599\n",
            "Average Loss for 600 iteration is : 1.0455455553531647\n",
            "Evaluation Accuracy is : 0.6029\n",
            "Average Loss for 100 iteration is : 1.035443971157074\n",
            "Average Loss for 200 iteration is : 1.0394181048870086\n",
            "Average Loss for 300 iteration is : 1.0611070585250855\n",
            "Average Loss for 400 iteration is : 1.0383054143190384\n",
            "Average Loss for 500 iteration is : 1.0346698373556138\n",
            "Average Loss for 600 iteration is : 1.039652289748192\n",
            "Evaluation Accuracy is : 0.6072\n",
            "Average Loss for 100 iteration is : 1.0306414306163787\n",
            "Average Loss for 200 iteration is : 1.0514837568998336\n",
            "Average Loss for 300 iteration is : 1.0404809004068374\n",
            "Average Loss for 400 iteration is : 1.0470854377746581\n",
            "Average Loss for 500 iteration is : 1.0473133754730224\n",
            "Average Loss for 600 iteration is : 1.054897676706314\n",
            "Evaluation Accuracy is : 0.6034\n",
            "Average Loss for 100 iteration is : 1.04663301050663\n",
            "Average Loss for 200 iteration is : 1.0224293333292007\n",
            "Average Loss for 300 iteration is : 1.054280868768692\n",
            "Average Loss for 400 iteration is : 1.0490551322698594\n",
            "Average Loss for 500 iteration is : 1.0388088148832322\n",
            "Average Loss for 600 iteration is : 1.0408775734901428\n",
            "Evaluation Accuracy is : 0.6069\n",
            "Average Loss for 100 iteration is : 1.025275896191597\n",
            "Average Loss for 200 iteration is : 1.029920859336853\n",
            "Average Loss for 300 iteration is : 1.0508785212039948\n",
            "Average Loss for 400 iteration is : 1.0478676629066468\n",
            "Average Loss for 500 iteration is : 1.0445946097373962\n",
            "Average Loss for 600 iteration is : 1.0492962104082109\n",
            "Evaluation Accuracy is : 0.6148\n",
            "Average Loss for 100 iteration is : 1.0357310158014297\n",
            "Average Loss for 200 iteration is : 1.0038187634944915\n",
            "Average Loss for 300 iteration is : 1.02696602165699\n",
            "Average Loss for 400 iteration is : 1.0427093482017518\n",
            "Average Loss for 500 iteration is : 1.063376982808113\n",
            "Average Loss for 600 iteration is : 1.0539247113466264\n",
            "Evaluation Accuracy is : 0.6094\n",
            "Average Loss for 100 iteration is : 1.0252074748277664\n",
            "Average Loss for 200 iteration is : 1.0337132740020751\n",
            "Average Loss for 300 iteration is : 1.0357856279611588\n",
            "Average Loss for 400 iteration is : 1.0664099049568176\n",
            "Average Loss for 500 iteration is : 1.0210028564929963\n",
            "Average Loss for 600 iteration is : 1.0163743072748184\n",
            "Evaluation Accuracy is : 0.6044\n",
            "Average Loss for 100 iteration is : 1.0374333864450456\n",
            "Average Loss for 200 iteration is : 1.0297133857011795\n",
            "Average Loss for 300 iteration is : 1.0354443567991256\n",
            "Average Loss for 400 iteration is : 1.0316302716732024\n",
            "Average Loss for 500 iteration is : 1.0629299175739289\n",
            "Average Loss for 600 iteration is : 1.0466289401054383\n",
            "Evaluation Accuracy is : 0.6182\n",
            "Average Loss for 100 iteration is : 1.024238502383232\n",
            "Average Loss for 200 iteration is : 1.047319752573967\n",
            "Average Loss for 300 iteration is : 1.02057184278965\n",
            "Average Loss for 400 iteration is : 1.0179191416501998\n",
            "Average Loss for 500 iteration is : 1.044980016350746\n",
            "Average Loss for 600 iteration is : 1.038218039870262\n",
            "Evaluation Accuracy is : 0.6164\n",
            "Average Loss for 100 iteration is : 1.0433293324708939\n",
            "Average Loss for 200 iteration is : 1.0154723846912384\n",
            "Average Loss for 300 iteration is : 1.047755257487297\n",
            "Average Loss for 400 iteration is : 1.0161154139041901\n",
            "Average Loss for 500 iteration is : 1.04221637070179\n",
            "Average Loss for 600 iteration is : 1.030741150379181\n",
            "Evaluation Accuracy is : 0.6166\n",
            "Average Loss for 100 iteration is : 1.0197514098882676\n",
            "Average Loss for 200 iteration is : 1.0273395931720735\n",
            "Average Loss for 300 iteration is : 1.0409620481729507\n",
            "Average Loss for 400 iteration is : 1.0249080759286882\n",
            "Average Loss for 500 iteration is : 1.0379257702827454\n",
            "Average Loss for 600 iteration is : 1.0127465349435807\n",
            "Evaluation Accuracy is : 0.6106\n",
            "Average Loss for 100 iteration is : 1.016907217502594\n",
            "Average Loss for 200 iteration is : 1.0245585966110229\n",
            "Average Loss for 300 iteration is : 1.0301703679561616\n",
            "Average Loss for 400 iteration is : 1.025123074054718\n",
            "Average Loss for 500 iteration is : 1.0136873918771743\n",
            "Average Loss for 600 iteration is : 1.044023398756981\n",
            "Evaluation Accuracy is : 0.6202\n",
            "Average Loss for 100 iteration is : 1.0371683657169342\n",
            "Average Loss for 200 iteration is : 1.0297420459985733\n",
            "Average Loss for 300 iteration is : 1.0276751935482025\n",
            "Average Loss for 400 iteration is : 0.9988373535871505\n",
            "Average Loss for 500 iteration is : 1.054899538755417\n",
            "Average Loss for 600 iteration is : 1.0372311139106751\n",
            "Evaluation Accuracy is : 0.6106\n",
            "Average Loss for 100 iteration is : 1.029862827062607\n",
            "Average Loss for 200 iteration is : 1.0113637393712998\n",
            "Average Loss for 300 iteration is : 1.024754718542099\n",
            "Average Loss for 400 iteration is : 1.0376830345392227\n",
            "Average Loss for 500 iteration is : 1.0213352876901627\n",
            "Average Loss for 600 iteration is : 1.0086033475399017\n",
            "Evaluation Accuracy is : 0.6214\n",
            "Average Loss for 100 iteration is : 1.00941685795784\n",
            "Average Loss for 200 iteration is : 1.0177693855762482\n",
            "Average Loss for 300 iteration is : 1.0324541753530503\n",
            "Average Loss for 400 iteration is : 1.0230717855691909\n",
            "Average Loss for 500 iteration is : 1.0080309212207794\n",
            "Average Loss for 600 iteration is : 1.03510467171669\n",
            "Evaluation Accuracy is : 0.6074\n",
            "Average Loss for 100 iteration is : 1.0066582089662552\n",
            "Average Loss for 200 iteration is : 1.0157394576072694\n",
            "Average Loss for 300 iteration is : 1.0259593510627747\n",
            "Average Loss for 400 iteration is : 1.031848052740097\n",
            "Average Loss for 500 iteration is : 1.03748601436615\n",
            "Average Loss for 600 iteration is : 1.015384428501129\n",
            "Evaluation Accuracy is : 0.6246\n",
            "Average Loss for 100 iteration is : 1.0089782524108886\n",
            "Average Loss for 200 iteration is : 1.0075887423753738\n",
            "Average Loss for 300 iteration is : 1.0265233969688417\n",
            "Average Loss for 400 iteration is : 1.0048274612426757\n",
            "Average Loss for 500 iteration is : 1.0198049235343933\n",
            "Average Loss for 600 iteration is : 1.039934098124504\n",
            "Evaluation Accuracy is : 0.6141\n",
            "Average Loss for 100 iteration is : 1.0012434333562852\n",
            "Average Loss for 200 iteration is : 1.0106258445978165\n",
            "Average Loss for 300 iteration is : 1.0258284258842467\n",
            "Average Loss for 400 iteration is : 1.0232987415790558\n",
            "Average Loss for 500 iteration is : 1.0231786382198333\n",
            "Average Loss for 600 iteration is : 1.025511114001274\n",
            "Evaluation Accuracy is : 0.6199\n",
            "Average Loss for 100 iteration is : 1.0296530663967132\n",
            "Average Loss for 200 iteration is : 1.0204859548807144\n",
            "Average Loss for 300 iteration is : 1.004386391043663\n",
            "Average Loss for 400 iteration is : 1.0044020050764084\n",
            "Average Loss for 500 iteration is : 1.0040074890851975\n",
            "Average Loss for 600 iteration is : 1.0065141236782074\n",
            "Evaluation Accuracy is : 0.6165\n",
            "Average Loss for 100 iteration is : 1.0009583431482314\n",
            "Average Loss for 200 iteration is : 1.0462588548660279\n",
            "Average Loss for 300 iteration is : 1.0239275634288787\n",
            "Average Loss for 400 iteration is : 1.00064683675766\n",
            "Average Loss for 500 iteration is : 1.0098067617416382\n",
            "Average Loss for 600 iteration is : 1.021671531200409\n",
            "Evaluation Accuracy is : 0.6173\n",
            "Average Loss for 100 iteration is : 1.0148404228687287\n",
            "Average Loss for 200 iteration is : 1.0159366363286972\n",
            "Average Loss for 300 iteration is : 1.0209075456857681\n",
            "Average Loss for 400 iteration is : 0.9992738980054855\n",
            "Average Loss for 500 iteration is : 1.0225994431972503\n",
            "Average Loss for 600 iteration is : 1.011070390343666\n",
            "Evaluation Accuracy is : 0.6178\n",
            "Average Loss for 100 iteration is : 1.0097181898355485\n",
            "Average Loss for 200 iteration is : 0.9994259130954742\n",
            "Average Loss for 300 iteration is : 1.0061528795957566\n",
            "Average Loss for 400 iteration is : 1.0098237884044647\n",
            "Average Loss for 500 iteration is : 0.9968844401836395\n",
            "Average Loss for 600 iteration is : 1.0165910536050797\n",
            "Evaluation Accuracy is : 0.6209\n",
            "Average Loss for 100 iteration is : 1.0156981235742568\n",
            "Average Loss for 200 iteration is : 0.9902446115016937\n",
            "Average Loss for 300 iteration is : 1.0034695690870286\n",
            "Average Loss for 400 iteration is : 1.0108340096473694\n",
            "Average Loss for 500 iteration is : 1.0055687713623047\n",
            "Average Loss for 600 iteration is : 0.9977559357881546\n",
            "Evaluation Accuracy is : 0.6086\n",
            "Average Loss for 100 iteration is : 1.0091113078594207\n",
            "Average Loss for 200 iteration is : 0.9869949132204056\n",
            "Average Loss for 300 iteration is : 1.0139355385303497\n",
            "Average Loss for 400 iteration is : 1.033404256105423\n",
            "Average Loss for 500 iteration is : 0.9961445719003678\n",
            "Average Loss for 600 iteration is : 1.0140074598789215\n",
            "Evaluation Accuracy is : 0.6073\n",
            "Average Loss for 100 iteration is : 1.0152243787050248\n",
            "Average Loss for 200 iteration is : 1.0043398123979568\n",
            "Average Loss for 300 iteration is : 1.0063661134243012\n",
            "Average Loss for 400 iteration is : 1.0056209301948547\n",
            "Average Loss for 500 iteration is : 1.0069363796710968\n",
            "Average Loss for 600 iteration is : 1.0130223554372788\n",
            "Evaluation Accuracy is : 0.6198\n",
            "Average Loss for 100 iteration is : 0.9956298476457596\n",
            "Average Loss for 200 iteration is : 1.0196628606319427\n",
            "Average Loss for 300 iteration is : 1.013745591044426\n",
            "Average Loss for 400 iteration is : 1.004874160885811\n",
            "Average Loss for 500 iteration is : 1.005199710726738\n",
            "Average Loss for 600 iteration is : 1.0033030861616135\n",
            "Evaluation Accuracy is : 0.6245\n",
            "Average Loss for 100 iteration is : 1.0222959172725679\n",
            "Average Loss for 200 iteration is : 1.005428284406662\n",
            "Average Loss for 300 iteration is : 0.9977512359619141\n",
            "Average Loss for 400 iteration is : 1.0199164485931396\n",
            "Average Loss for 500 iteration is : 0.989889332652092\n",
            "Average Loss for 600 iteration is : 0.9802171701192856\n",
            "Evaluation Accuracy is : 0.6173\n",
            "Average Loss for 100 iteration is : 0.9955533081293106\n",
            "Average Loss for 200 iteration is : 1.0091087186336518\n",
            "Average Loss for 300 iteration is : 1.0059855049848556\n",
            "Average Loss for 400 iteration is : 1.0015734112262726\n",
            "Average Loss for 500 iteration is : 0.9945497113466263\n",
            "Average Loss for 600 iteration is : 1.0184241670370102\n",
            "Evaluation Accuracy is : 0.6197\n",
            "Average Loss for 100 iteration is : 0.9868380326032639\n",
            "Average Loss for 200 iteration is : 1.0047481149435042\n",
            "Average Loss for 300 iteration is : 0.9937715125083924\n",
            "Average Loss for 400 iteration is : 0.9691118478775025\n",
            "Average Loss for 500 iteration is : 1.0258196783065796\n",
            "Average Loss for 600 iteration is : 1.0053496891260147\n",
            "Evaluation Accuracy is : 0.6194\n",
            "Average Loss for 100 iteration is : 1.0071667313575745\n",
            "Average Loss for 200 iteration is : 0.9895960748195648\n",
            "Average Loss for 300 iteration is : 1.0039164483547212\n",
            "Average Loss for 400 iteration is : 1.0174565702676772\n",
            "Average Loss for 500 iteration is : 1.0006698375940324\n",
            "Average Loss for 600 iteration is : 0.9823835474252701\n",
            "Evaluation Accuracy is : 0.6221\n",
            "Average Loss for 100 iteration is : 0.9628094238042831\n",
            "Average Loss for 200 iteration is : 1.00268461227417\n",
            "Average Loss for 300 iteration is : 1.002711040377617\n",
            "Average Loss for 400 iteration is : 1.0128444600105286\n",
            "Average Loss for 500 iteration is : 1.0144277769327164\n",
            "Average Loss for 600 iteration is : 0.9940618532896042\n",
            "Evaluation Accuracy is : 0.6247\n",
            "Average Loss for 100 iteration is : 1.007552078962326\n",
            "Average Loss for 200 iteration is : 0.9980346328020095\n",
            "Average Loss for 300 iteration is : 1.0067236071825028\n",
            "Average Loss for 400 iteration is : 0.9870623499155045\n",
            "Average Loss for 500 iteration is : 0.9894808596372604\n",
            "Average Loss for 600 iteration is : 0.978921006321907\n",
            "Evaluation Accuracy is : 0.6301\n",
            "Average Loss for 100 iteration is : 0.9775949800014496\n",
            "Average Loss for 200 iteration is : 0.998399350643158\n",
            "Average Loss for 300 iteration is : 1.0011707121133804\n",
            "Average Loss for 400 iteration is : 0.9947643703222275\n",
            "Average Loss for 500 iteration is : 0.9981353777647018\n",
            "Average Loss for 600 iteration is : 0.9835140162706375\n",
            "Evaluation Accuracy is : 0.6296\n",
            "Average Loss for 100 iteration is : 1.0116172355413438\n",
            "Average Loss for 200 iteration is : 0.9889532136917114\n",
            "Average Loss for 300 iteration is : 1.0000639188289642\n",
            "Average Loss for 400 iteration is : 1.0099580997228623\n",
            "Average Loss for 500 iteration is : 0.9806620812416077\n",
            "Average Loss for 600 iteration is : 0.9818265217542649\n",
            "Evaluation Accuracy is : 0.6248\n",
            "Average Loss for 100 iteration is : 0.98396852850914\n",
            "Average Loss for 200 iteration is : 0.9794688856601715\n",
            "Average Loss for 300 iteration is : 0.996755992770195\n",
            "Average Loss for 400 iteration is : 0.9894688838720321\n",
            "Average Loss for 500 iteration is : 0.9838366037607194\n",
            "Average Loss for 600 iteration is : 0.9949509251117706\n",
            "Evaluation Accuracy is : 0.6251\n",
            "Average Loss for 100 iteration is : 0.9704276496171951\n",
            "Average Loss for 200 iteration is : 0.9972350221872329\n",
            "Average Loss for 300 iteration is : 1.0100002682209015\n",
            "Average Loss for 400 iteration is : 1.0231458556652069\n",
            "Average Loss for 500 iteration is : 0.9663483095169068\n",
            "Average Loss for 600 iteration is : 0.9836658209562301\n",
            "Evaluation Accuracy is : 0.6297\n",
            "Average Loss for 100 iteration is : 0.9816477304697037\n",
            "Average Loss for 200 iteration is : 1.009337506890297\n",
            "Average Loss for 300 iteration is : 1.0050740122795105\n",
            "Average Loss for 400 iteration is : 0.9756425243616104\n",
            "Average Loss for 500 iteration is : 1.0023817121982574\n",
            "Average Loss for 600 iteration is : 0.9727297526597977\n",
            "Evaluation Accuracy is : 0.629\n",
            "Average Loss for 100 iteration is : 0.9698654735088348\n",
            "Average Loss for 200 iteration is : 0.9899201256036758\n",
            "Average Loss for 300 iteration is : 0.983257588148117\n",
            "Average Loss for 400 iteration is : 0.9968860954046249\n",
            "Average Loss for 500 iteration is : 1.0102394407987594\n",
            "Average Loss for 600 iteration is : 0.9872104412317276\n",
            "Evaluation Accuracy is : 0.6348\n",
            "Average Loss for 100 iteration is : 0.9972114312648773\n",
            "Average Loss for 200 iteration is : 0.9725600463151932\n",
            "Average Loss for 300 iteration is : 1.0036889046430588\n",
            "Average Loss for 400 iteration is : 0.9875840455293655\n",
            "Average Loss for 500 iteration is : 0.9993292474746704\n",
            "Average Loss for 600 iteration is : 0.9745237004756927\n",
            "Evaluation Accuracy is : 0.63\n",
            "Average Loss for 100 iteration is : 0.9798401635885239\n",
            "Average Loss for 200 iteration is : 0.9905223602056503\n",
            "Average Loss for 300 iteration is : 0.9824154680967331\n",
            "Average Loss for 400 iteration is : 0.9846099293231965\n",
            "Average Loss for 500 iteration is : 1.008350972533226\n",
            "Average Loss for 600 iteration is : 0.9864760965108872\n",
            "Evaluation Accuracy is : 0.6314\n",
            "Average Loss for 100 iteration is : 0.9955147457122803\n",
            "Average Loss for 200 iteration is : 0.9894025373458862\n",
            "Average Loss for 300 iteration is : 0.9960280895233155\n",
            "Average Loss for 400 iteration is : 0.9723343545198441\n",
            "Average Loss for 500 iteration is : 0.9699477142095566\n",
            "Average Loss for 600 iteration is : 0.9775846576690674\n",
            "Evaluation Accuracy is : 0.6316\n",
            "Average Loss for 100 iteration is : 1.007431182861328\n",
            "Average Loss for 200 iteration is : 0.9634265506267548\n",
            "Average Loss for 300 iteration is : 0.9870271956920624\n",
            "Average Loss for 400 iteration is : 0.9874313753843308\n",
            "Average Loss for 500 iteration is : 0.9829698210954666\n",
            "Average Loss for 600 iteration is : 0.9742068183422089\n",
            "Evaluation Accuracy is : 0.6288\n",
            "Average Loss for 100 iteration is : 0.9692490988969803\n",
            "Average Loss for 200 iteration is : 0.964254702925682\n",
            "Average Loss for 300 iteration is : 0.9792515808343887\n",
            "Average Loss for 400 iteration is : 0.9649301248788834\n",
            "Average Loss for 500 iteration is : 0.979810791015625\n",
            "Average Loss for 600 iteration is : 1.017030428647995\n",
            "Evaluation Accuracy is : 0.6324\n",
            "Average Loss for 100 iteration is : 0.9711914271116256\n",
            "Average Loss for 200 iteration is : 0.9714188879728317\n",
            "Average Loss for 300 iteration is : 0.9598153078556061\n",
            "Average Loss for 400 iteration is : 0.9808909261226654\n",
            "Average Loss for 500 iteration is : 0.9885529226064682\n",
            "Average Loss for 600 iteration is : 1.007713376879692\n",
            "Evaluation Accuracy is : 0.6317\n",
            "Average Loss for 100 iteration is : 0.9787351411581039\n",
            "Average Loss for 200 iteration is : 0.9862623935937882\n",
            "Average Loss for 300 iteration is : 0.9514316666126251\n",
            "Average Loss for 400 iteration is : 0.9787615483999252\n",
            "Average Loss for 500 iteration is : 0.9597097378969193\n",
            "Average Loss for 600 iteration is : 1.0021641278266906\n",
            "Evaluation Accuracy is : 0.6356\n",
            "Average Loss for 100 iteration is : 0.9776692253351211\n",
            "Average Loss for 200 iteration is : 0.9637944209575653\n",
            "Average Loss for 300 iteration is : 0.9814059579372406\n",
            "Average Loss for 400 iteration is : 0.9699845629930496\n",
            "Average Loss for 500 iteration is : 0.988205896615982\n",
            "Average Loss for 600 iteration is : 0.98475106716156\n",
            "Evaluation Accuracy is : 0.6345\n",
            "Average Loss for 100 iteration is : 0.9750094997882843\n",
            "Average Loss for 200 iteration is : 0.9660326182842255\n",
            "Average Loss for 300 iteration is : 0.9864035141468048\n",
            "Average Loss for 400 iteration is : 1.0013737803697587\n",
            "Average Loss for 500 iteration is : 0.9719178307056427\n",
            "Average Loss for 600 iteration is : 0.9609887480735779\n",
            "Evaluation Accuracy is : 0.6176\n",
            "Average Loss for 100 iteration is : 0.9704939770698547\n",
            "Average Loss for 200 iteration is : 0.9521651983261108\n",
            "Average Loss for 300 iteration is : 0.9759390527009963\n",
            "Average Loss for 400 iteration is : 0.9872039514780044\n",
            "Average Loss for 500 iteration is : 0.9756428581476212\n",
            "Average Loss for 600 iteration is : 1.004790558218956\n",
            "Evaluation Accuracy is : 0.6322\n",
            "Average Loss for 100 iteration is : 0.9697536963224411\n",
            "Average Loss for 200 iteration is : 1.0063887149095536\n",
            "Average Loss for 300 iteration is : 0.9824178695678711\n",
            "Average Loss for 400 iteration is : 0.9670578896999359\n",
            "Average Loss for 500 iteration is : 0.969541232585907\n",
            "Average Loss for 600 iteration is : 0.9594085156917572\n",
            "Evaluation Accuracy is : 0.6311\n",
            "Average Loss for 100 iteration is : 0.9833766585588455\n",
            "Average Loss for 200 iteration is : 0.961158447265625\n",
            "Average Loss for 300 iteration is : 0.9733576011657715\n",
            "Average Loss for 400 iteration is : 0.976516700387001\n",
            "Average Loss for 500 iteration is : 0.9682986491918564\n",
            "Average Loss for 600 iteration is : 0.9538508707284927\n",
            "Evaluation Accuracy is : 0.6362\n",
            "Average Loss for 100 iteration is : 0.9567221188545227\n",
            "Average Loss for 200 iteration is : 0.975356113910675\n",
            "Average Loss for 300 iteration is : 0.9876864564418792\n",
            "Average Loss for 400 iteration is : 0.964567455649376\n",
            "Average Loss for 500 iteration is : 0.9930783623456955\n",
            "Average Loss for 600 iteration is : 0.9546472108364106\n",
            "Evaluation Accuracy is : 0.6325\n",
            "Average Loss for 100 iteration is : 0.9618876004219055\n",
            "Average Loss for 200 iteration is : 0.9814510244131088\n",
            "Average Loss for 300 iteration is : 0.9836037492752076\n",
            "Average Loss for 400 iteration is : 0.965540269613266\n",
            "Average Loss for 500 iteration is : 0.9592939561605454\n",
            "Average Loss for 600 iteration is : 0.9612809544801713\n",
            "Evaluation Accuracy is : 0.6357\n",
            "Average Loss for 100 iteration is : 0.9680777269601822\n",
            "Average Loss for 200 iteration is : 0.9954178100824356\n",
            "Average Loss for 300 iteration is : 0.9673330330848694\n",
            "Average Loss for 400 iteration is : 0.971176837682724\n",
            "Average Loss for 500 iteration is : 0.9603145110607147\n",
            "Average Loss for 600 iteration is : 0.966472116112709\n",
            "Evaluation Accuracy is : 0.6286\n",
            "Average Loss for 100 iteration is : 0.9746442437171936\n",
            "Average Loss for 200 iteration is : 0.931123839020729\n",
            "Average Loss for 300 iteration is : 0.9720093363523483\n",
            "Average Loss for 400 iteration is : 0.9508318030834197\n",
            "Average Loss for 500 iteration is : 0.9792341268062592\n",
            "Average Loss for 600 iteration is : 0.9846618807315827\n",
            "Evaluation Accuracy is : 0.6342\n",
            "Average Loss for 100 iteration is : 0.9628911298513413\n",
            "Average Loss for 200 iteration is : 0.9726284295320511\n",
            "Average Loss for 300 iteration is : 0.9689392918348312\n",
            "Average Loss for 400 iteration is : 0.9632906305789948\n",
            "Average Loss for 500 iteration is : 0.9510914653539657\n",
            "Average Loss for 600 iteration is : 0.9791405230760575\n",
            "Evaluation Accuracy is : 0.6414\n",
            "Average Loss for 100 iteration is : 0.980193452835083\n",
            "Average Loss for 200 iteration is : 0.9402844041585923\n",
            "Average Loss for 300 iteration is : 0.9666138011217117\n",
            "Average Loss for 400 iteration is : 0.9772772520780564\n",
            "Average Loss for 500 iteration is : 0.9679589629173279\n",
            "Average Loss for 600 iteration is : 0.9672030526399612\n",
            "Evaluation Accuracy is : 0.6349\n",
            "Average Loss for 100 iteration is : 0.9656246078014373\n",
            "Average Loss for 200 iteration is : 0.9529191744327545\n",
            "Average Loss for 300 iteration is : 0.9553297048807144\n",
            "Average Loss for 400 iteration is : 0.9745581716299057\n",
            "Average Loss for 500 iteration is : 0.9563266605138778\n",
            "Average Loss for 600 iteration is : 0.9671023857593536\n",
            "Evaluation Accuracy is : 0.6345\n",
            "Average Loss for 100 iteration is : 0.9608767104148864\n",
            "Average Loss for 200 iteration is : 0.9611527752876282\n",
            "Average Loss for 300 iteration is : 0.946705157160759\n",
            "Average Loss for 400 iteration is : 0.9671488136053086\n",
            "Average Loss for 500 iteration is : 0.9513097178936004\n",
            "Average Loss for 600 iteration is : 0.9747932094335556\n",
            "Evaluation Accuracy is : 0.6276\n",
            "Average Loss for 100 iteration is : 0.973780653476715\n",
            "Average Loss for 200 iteration is : 0.927784132361412\n",
            "Average Loss for 300 iteration is : 0.9469668287038803\n",
            "Average Loss for 400 iteration is : 0.9898577690124511\n",
            "Average Loss for 500 iteration is : 0.9567498481273651\n",
            "Average Loss for 600 iteration is : 0.9773239547014236\n",
            "Evaluation Accuracy is : 0.6372\n",
            "Average Loss for 100 iteration is : 0.9706856673955917\n",
            "Average Loss for 200 iteration is : 0.9762814712524414\n",
            "Average Loss for 300 iteration is : 0.9569526153802872\n",
            "Average Loss for 400 iteration is : 0.9531636822223664\n",
            "Average Loss for 500 iteration is : 0.9613622778654098\n",
            "Average Loss for 600 iteration is : 0.9508837008476257\n",
            "Evaluation Accuracy is : 0.6301\n",
            "Average Loss for 100 iteration is : 0.9555758905410766\n",
            "Average Loss for 200 iteration is : 0.9510920333862305\n",
            "Average Loss for 300 iteration is : 0.9664878469705581\n",
            "Average Loss for 400 iteration is : 0.9536042022705078\n",
            "Average Loss for 500 iteration is : 0.9853207683563232\n",
            "Average Loss for 600 iteration is : 0.9675741142034531\n",
            "Evaluation Accuracy is : 0.637\n",
            "Average Loss for 100 iteration is : 0.9697122573852539\n",
            "Average Loss for 200 iteration is : 0.9734407985210418\n",
            "Average Loss for 300 iteration is : 0.959413331747055\n",
            "Average Loss for 400 iteration is : 0.9808190041780471\n",
            "Average Loss for 500 iteration is : 0.9586917740106583\n",
            "Average Loss for 600 iteration is : 0.9514037901163102\n",
            "Evaluation Accuracy is : 0.6391\n",
            "Average Loss for 100 iteration is : 0.9501241815090179\n",
            "Average Loss for 200 iteration is : 0.950041208267212\n",
            "Average Loss for 300 iteration is : 0.9768294137716294\n",
            "Average Loss for 400 iteration is : 0.9436432784795761\n",
            "Average Loss for 500 iteration is : 0.9749788480997086\n",
            "Average Loss for 600 iteration is : 0.9588089340925217\n",
            "Evaluation Accuracy is : 0.632\n",
            "Average Loss for 100 iteration is : 0.947999102473259\n",
            "Average Loss for 200 iteration is : 0.9624697083234787\n",
            "Average Loss for 300 iteration is : 0.9454654616117477\n",
            "Average Loss for 400 iteration is : 0.9337313765287399\n",
            "Average Loss for 500 iteration is : 0.9657540267705917\n",
            "Average Loss for 600 iteration is : 0.9384149760007858\n",
            "Evaluation Accuracy is : 0.6388\n",
            "Average Loss for 100 iteration is : 0.9631043392419815\n",
            "Average Loss for 200 iteration is : 0.9650124907493591\n",
            "Average Loss for 300 iteration is : 0.9629137289524078\n",
            "Average Loss for 400 iteration is : 0.9502415537834168\n",
            "Average Loss for 500 iteration is : 0.9378190296888351\n",
            "Average Loss for 600 iteration is : 0.9307112747430801\n",
            "Evaluation Accuracy is : 0.6386\n",
            "Average Loss for 100 iteration is : 0.9588805621862412\n",
            "Average Loss for 200 iteration is : 0.9392564618587493\n",
            "Average Loss for 300 iteration is : 0.9752615433931351\n",
            "Average Loss for 400 iteration is : 0.9557131040096283\n",
            "Average Loss for 500 iteration is : 0.9484106290340424\n",
            "Average Loss for 600 iteration is : 0.9449363678693772\n",
            "Evaluation Accuracy is : 0.6429\n",
            "Average Loss for 100 iteration is : 0.9270711636543274\n",
            "Average Loss for 200 iteration is : 0.9654814547300339\n",
            "Average Loss for 300 iteration is : 0.9588916927576066\n",
            "Average Loss for 400 iteration is : 0.9471369552612304\n",
            "Average Loss for 500 iteration is : 0.957451428771019\n",
            "Average Loss for 600 iteration is : 0.9497316038608551\n",
            "Evaluation Accuracy is : 0.6452\n",
            "Average Loss for 100 iteration is : 0.9549549865722656\n",
            "Average Loss for 200 iteration is : 0.968840519785881\n",
            "Average Loss for 300 iteration is : 0.9524723386764526\n",
            "Average Loss for 400 iteration is : 0.9448965513706207\n",
            "Average Loss for 500 iteration is : 0.9437213039398193\n",
            "Average Loss for 600 iteration is : 0.9569520097970963\n",
            "Evaluation Accuracy is : 0.6388\n",
            "Average Loss for 100 iteration is : 0.9283222943544388\n",
            "Average Loss for 200 iteration is : 0.9364220345020294\n",
            "Average Loss for 300 iteration is : 0.9527628237009048\n",
            "Average Loss for 400 iteration is : 0.9654134845733643\n",
            "Average Loss for 500 iteration is : 0.9329735863208771\n",
            "Average Loss for 600 iteration is : 0.9664698833227158\n",
            "Evaluation Accuracy is : 0.6404\n",
            "Average Loss for 100 iteration is : 0.9405451703071595\n",
            "Average Loss for 200 iteration is : 0.9498265904188156\n",
            "Average Loss for 300 iteration is : 0.9603234618902207\n",
            "Average Loss for 400 iteration is : 0.9613103073835373\n",
            "Average Loss for 500 iteration is : 0.9590147811174393\n",
            "Average Loss for 600 iteration is : 0.9334154975414276\n",
            "Evaluation Accuracy is : 0.6356\n",
            "Average Loss for 100 iteration is : 0.9188292944431304\n",
            "Average Loss for 200 iteration is : 0.9466182243824005\n",
            "Average Loss for 300 iteration is : 0.971952942609787\n",
            "Average Loss for 400 iteration is : 0.9527487826347351\n",
            "Average Loss for 500 iteration is : 0.9494427287578583\n",
            "Average Loss for 600 iteration is : 0.9380644512176514\n",
            "Evaluation Accuracy is : 0.6365\n",
            "Average Loss for 100 iteration is : 0.9640401631593705\n",
            "Average Loss for 200 iteration is : 0.9258522790670395\n",
            "Average Loss for 300 iteration is : 0.9509966737031936\n",
            "Average Loss for 400 iteration is : 0.9437153768539429\n",
            "Average Loss for 500 iteration is : 0.9607336705923081\n",
            "Average Loss for 600 iteration is : 0.9516695713996888\n",
            "Evaluation Accuracy is : 0.6373\n",
            "Average Loss for 100 iteration is : 0.9320592433214188\n",
            "Average Loss for 200 iteration is : 0.9340342688560486\n",
            "Average Loss for 300 iteration is : 0.938679445385933\n",
            "Average Loss for 400 iteration is : 0.9617917269468308\n",
            "Average Loss for 500 iteration is : 0.9382965505123139\n",
            "Average Loss for 600 iteration is : 0.960850710272789\n",
            "Evaluation Accuracy is : 0.6513\n",
            "Average Loss for 100 iteration is : 0.9200656419992447\n",
            "Average Loss for 200 iteration is : 0.9502464509010315\n",
            "Average Loss for 300 iteration is : 0.941880252957344\n",
            "Average Loss for 400 iteration is : 0.9493272787332535\n",
            "Average Loss for 500 iteration is : 0.9577738153934479\n",
            "Average Loss for 600 iteration is : 0.9457397764921188\n",
            "Evaluation Accuracy is : 0.6267\n",
            "Average Loss for 100 iteration is : 0.9516145545244217\n",
            "Average Loss for 200 iteration is : 0.9315339958667755\n",
            "Average Loss for 300 iteration is : 0.9201927679777145\n",
            "Average Loss for 400 iteration is : 0.9289795464277267\n",
            "Average Loss for 500 iteration is : 0.958048301935196\n",
            "Average Loss for 600 iteration is : 0.9415181869268417\n",
            "Evaluation Accuracy is : 0.6444\n",
            "Average Loss for 100 iteration is : 0.9405889183282852\n",
            "Average Loss for 200 iteration is : 0.9485933113098145\n",
            "Average Loss for 300 iteration is : 0.9420872443914413\n",
            "Average Loss for 400 iteration is : 0.963929306268692\n",
            "Average Loss for 500 iteration is : 0.9443453449010849\n",
            "Average Loss for 600 iteration is : 0.9607091200351715\n",
            "Evaluation Accuracy is : 0.6308\n",
            "Average Loss for 100 iteration is : 0.9419722962379455\n",
            "Average Loss for 200 iteration is : 0.9283646041154862\n",
            "Average Loss for 300 iteration is : 0.949974558353424\n",
            "Average Loss for 400 iteration is : 0.9409627085924148\n",
            "Average Loss for 500 iteration is : 0.9581928336620331\n",
            "Average Loss for 600 iteration is : 0.9413630992174149\n",
            "Evaluation Accuracy is : 0.6447\n",
            "Average Loss for 100 iteration is : 0.9347007715702057\n",
            "Average Loss for 200 iteration is : 0.9306179684400558\n",
            "Average Loss for 300 iteration is : 0.9724576771259308\n",
            "Average Loss for 400 iteration is : 0.936301264166832\n",
            "Average Loss for 500 iteration is : 0.9488254100084305\n",
            "Average Loss for 600 iteration is : 0.9289120459556579\n",
            "Evaluation Accuracy is : 0.6474\n",
            "Average Loss for 100 iteration is : 0.9319341784715652\n",
            "Average Loss for 200 iteration is : 0.9394027531147003\n",
            "Average Loss for 300 iteration is : 0.9247156018018723\n",
            "Average Loss for 400 iteration is : 0.9268189638853073\n",
            "Average Loss for 500 iteration is : 0.9378102493286132\n",
            "Average Loss for 600 iteration is : 0.9520222473144532\n",
            "Evaluation Accuracy is : 0.6419\n",
            "Average Loss for 100 iteration is : 0.9288357734680176\n",
            "Average Loss for 200 iteration is : 0.9416958969831467\n",
            "Average Loss for 300 iteration is : 0.9465277743339539\n",
            "Average Loss for 400 iteration is : 0.9647591817378998\n",
            "Average Loss for 500 iteration is : 0.9251347482204437\n",
            "Average Loss for 600 iteration is : 0.9515960520505905\n",
            "Evaluation Accuracy is : 0.6467\n",
            "Average Loss for 100 iteration is : 0.9453595370054245\n",
            "Average Loss for 200 iteration is : 0.9512688314914703\n",
            "Average Loss for 300 iteration is : 0.9263191473484039\n",
            "Average Loss for 400 iteration is : 0.945011529326439\n",
            "Average Loss for 500 iteration is : 0.9441815382242202\n",
            "Average Loss for 600 iteration is : 0.9366912561655044\n",
            "Evaluation Accuracy is : 0.6514\n",
            "Average Loss for 100 iteration is : 0.9221691995859146\n",
            "Average Loss for 200 iteration is : 0.9288183319568634\n",
            "Average Loss for 300 iteration is : 0.9284928339719772\n",
            "Average Loss for 400 iteration is : 0.9234293222427368\n",
            "Average Loss for 500 iteration is : 0.9522423881292343\n",
            "Average Loss for 600 iteration is : 0.956361579298973\n",
            "Evaluation Accuracy is : 0.6331\n",
            "Average Loss for 100 iteration is : 0.931614128947258\n",
            "Average Loss for 200 iteration is : 0.953780151605606\n",
            "Average Loss for 300 iteration is : 0.9220629853010177\n",
            "Average Loss for 400 iteration is : 0.9329092985391617\n",
            "Average Loss for 500 iteration is : 0.9350126779079437\n",
            "Average Loss for 600 iteration is : 0.9208515030145645\n",
            "Evaluation Accuracy is : 0.642\n",
            "Average Loss for 100 iteration is : 0.9147286117076874\n",
            "Average Loss for 200 iteration is : 0.941852656006813\n",
            "Average Loss for 300 iteration is : 0.9447004890441895\n",
            "Average Loss for 400 iteration is : 0.9459993761777877\n",
            "Average Loss for 500 iteration is : 0.9427696734666824\n",
            "Average Loss for 600 iteration is : 0.9160187155008316\n",
            "Evaluation Accuracy is : 0.6462\n",
            "Average Loss for 100 iteration is : 0.9302183496952057\n",
            "Average Loss for 200 iteration is : 0.9211425602436065\n",
            "Average Loss for 300 iteration is : 0.9469843578338623\n",
            "Average Loss for 400 iteration is : 0.9134772849082947\n",
            "Average Loss for 500 iteration is : 0.9403780961036682\n",
            "Average Loss for 600 iteration is : 0.932118015885353\n",
            "Evaluation Accuracy is : 0.6391\n",
            "Average Loss for 100 iteration is : 0.9307180339097977\n",
            "Average Loss for 200 iteration is : 0.9374546545743943\n",
            "Average Loss for 300 iteration is : 0.938524699807167\n",
            "Average Loss for 400 iteration is : 0.9311635911464691\n",
            "Average Loss for 500 iteration is : 0.9256721419095993\n",
            "Average Loss for 600 iteration is : 0.9295869582891464\n",
            "Evaluation Accuracy is : 0.645\n",
            "Average Loss for 100 iteration is : 0.9364570653438569\n",
            "Average Loss for 200 iteration is : 0.931290864944458\n",
            "Average Loss for 300 iteration is : 0.9059293019771576\n",
            "Average Loss for 400 iteration is : 0.9456469839811326\n",
            "Average Loss for 500 iteration is : 0.9290197014808654\n",
            "Average Loss for 600 iteration is : 0.9226826646924019\n",
            "Evaluation Accuracy is : 0.6475\n",
            "Average Loss for 100 iteration is : 0.9327394300699234\n",
            "Average Loss for 200 iteration is : 0.9009611684083939\n",
            "Average Loss for 300 iteration is : 0.9152994573116302\n",
            "Average Loss for 400 iteration is : 0.9418592441082001\n",
            "Average Loss for 500 iteration is : 0.9445175540447235\n",
            "Average Loss for 600 iteration is : 0.9374214875698089\n",
            "Evaluation Accuracy is : 0.6425\n",
            "Average Loss for 100 iteration is : 0.9170235508680343\n",
            "Average Loss for 200 iteration is : 0.9316597843170166\n",
            "Average Loss for 300 iteration is : 0.9169268465042114\n",
            "Average Loss for 400 iteration is : 0.9385509246587753\n",
            "Average Loss for 500 iteration is : 0.9089321798086166\n",
            "Average Loss for 600 iteration is : 0.9250576186180115\n",
            "Evaluation Accuracy is : 0.6417\n",
            "Average Loss for 100 iteration is : 0.9400142461061478\n",
            "Average Loss for 200 iteration is : 0.9372018557786942\n",
            "Average Loss for 300 iteration is : 0.9245784455537795\n",
            "Average Loss for 400 iteration is : 0.9161768543720246\n",
            "Average Loss for 500 iteration is : 0.9324197405576706\n",
            "Average Loss for 600 iteration is : 0.9273563462495804\n",
            "Evaluation Accuracy is : 0.6427\n",
            "Average Loss for 100 iteration is : 0.941049775481224\n",
            "Average Loss for 200 iteration is : 0.9071750849485397\n",
            "Average Loss for 300 iteration is : 0.9306191599369049\n",
            "Average Loss for 400 iteration is : 0.944979208111763\n",
            "Average Loss for 500 iteration is : 0.9385472071170807\n",
            "Average Loss for 600 iteration is : 0.9439989578723907\n",
            "Evaluation Accuracy is : 0.6389\n",
            "Average Loss for 100 iteration is : 0.9312184476852416\n",
            "Average Loss for 200 iteration is : 0.923090655207634\n",
            "Average Loss for 300 iteration is : 0.9208610486984253\n",
            "Average Loss for 400 iteration is : 0.9511745029687881\n",
            "Average Loss for 500 iteration is : 0.9307695841789245\n",
            "Average Loss for 600 iteration is : 0.9239227044582367\n",
            "Evaluation Accuracy is : 0.6464\n",
            "Average Loss for 100 iteration is : 0.9169995599985122\n",
            "Average Loss for 200 iteration is : 0.9073983335494995\n",
            "Average Loss for 300 iteration is : 0.9228391480445862\n",
            "Average Loss for 400 iteration is : 0.9271607911586761\n",
            "Average Loss for 500 iteration is : 0.9458668392896652\n",
            "Average Loss for 600 iteration is : 0.921332129240036\n",
            "Evaluation Accuracy is : 0.6519\n",
            "Average Loss for 100 iteration is : 0.930216276049614\n",
            "Average Loss for 200 iteration is : 0.9359097385406494\n",
            "Average Loss for 300 iteration is : 0.9408880472183228\n",
            "Average Loss for 400 iteration is : 0.9087977689504624\n",
            "Average Loss for 500 iteration is : 0.9309163969755173\n",
            "Average Loss for 600 iteration is : 0.9104330617189408\n",
            "Evaluation Accuracy is : 0.6433\n",
            "Average Loss for 100 iteration is : 0.918608745932579\n",
            "Average Loss for 200 iteration is : 0.918408505320549\n",
            "Average Loss for 300 iteration is : 0.9290188413858413\n",
            "Average Loss for 400 iteration is : 0.9245950496196746\n",
            "Average Loss for 500 iteration is : 0.9245572048425674\n",
            "Average Loss for 600 iteration is : 0.9097362244129181\n",
            "Evaluation Accuracy is : 0.6381\n",
            "Average Loss for 100 iteration is : 0.9244495755434037\n",
            "Average Loss for 200 iteration is : 0.9265174996852875\n",
            "Average Loss for 300 iteration is : 0.9308873498439789\n",
            "Average Loss for 400 iteration is : 0.9424974155426026\n",
            "Average Loss for 500 iteration is : 0.9031193268299103\n",
            "Average Loss for 600 iteration is : 0.913710355758667\n",
            "Evaluation Accuracy is : 0.6365\n",
            "Average Loss for 100 iteration is : 0.9216836148500442\n",
            "Average Loss for 200 iteration is : 0.9164911961555481\n",
            "Average Loss for 300 iteration is : 0.8899075835943222\n",
            "Average Loss for 400 iteration is : 0.9461130768060684\n",
            "Average Loss for 500 iteration is : 0.9347847229242325\n",
            "Average Loss for 600 iteration is : 0.9561933118104935\n",
            "Evaluation Accuracy is : 0.644\n",
            "Average Loss for 100 iteration is : 0.9312454444169999\n",
            "Average Loss for 200 iteration is : 0.9130610316991806\n",
            "Average Loss for 300 iteration is : 0.9297451800107956\n",
            "Average Loss for 400 iteration is : 0.888881859779358\n",
            "Average Loss for 500 iteration is : 0.9265705400705337\n",
            "Average Loss for 600 iteration is : 0.9092792344093322\n",
            "Evaluation Accuracy is : 0.6508\n",
            "Average Loss for 100 iteration is : 0.9082951265573501\n",
            "Average Loss for 200 iteration is : 0.9210139483213424\n",
            "Average Loss for 300 iteration is : 0.923695233464241\n",
            "Average Loss for 400 iteration is : 0.9326118618249893\n",
            "Average Loss for 500 iteration is : 0.8943756878376007\n",
            "Average Loss for 600 iteration is : 0.9281639862060547\n",
            "Evaluation Accuracy is : 0.6474\n",
            "Average Loss for 100 iteration is : 0.935223652124405\n",
            "Average Loss for 200 iteration is : 0.9106652665138245\n",
            "Average Loss for 300 iteration is : 0.9110320532321929\n",
            "Average Loss for 400 iteration is : 0.9159340900182724\n",
            "Average Loss for 500 iteration is : 0.9369060266017913\n",
            "Average Loss for 600 iteration is : 0.9234533393383026\n",
            "Evaluation Accuracy is : 0.6455\n",
            "Average Loss for 100 iteration is : 0.9135150253772736\n",
            "Average Loss for 200 iteration is : 0.9066320896148682\n",
            "Average Loss for 300 iteration is : 0.9154727125167846\n",
            "Average Loss for 400 iteration is : 0.9051720607280731\n",
            "Average Loss for 500 iteration is : 0.9308906143903732\n",
            "Average Loss for 600 iteration is : 0.9191645592451095\n",
            "Evaluation Accuracy is : 0.6364\n",
            "Average Loss for 100 iteration is : 0.8868678319454193\n",
            "Average Loss for 200 iteration is : 0.9154847443103791\n",
            "Average Loss for 300 iteration is : 0.9247652751207351\n",
            "Average Loss for 400 iteration is : 0.9220197832584381\n",
            "Average Loss for 500 iteration is : 0.9237853598594665\n",
            "Average Loss for 600 iteration is : 0.928656889796257\n",
            "Evaluation Accuracy is : 0.6531\n",
            "Average Loss for 100 iteration is : 0.923080216050148\n",
            "Average Loss for 200 iteration is : 0.9239350563287735\n",
            "Average Loss for 300 iteration is : 0.9014168971776962\n",
            "Average Loss for 400 iteration is : 0.9173886901140214\n",
            "Average Loss for 500 iteration is : 0.9117685306072235\n",
            "Average Loss for 600 iteration is : 0.903624153137207\n",
            "Evaluation Accuracy is : 0.6534\n",
            "Average Loss for 100 iteration is : 0.9211638963222504\n",
            "Average Loss for 200 iteration is : 0.8975551056861878\n",
            "Average Loss for 300 iteration is : 0.926218768954277\n",
            "Average Loss for 400 iteration is : 0.9178371751308441\n",
            "Average Loss for 500 iteration is : 0.8993677097558975\n",
            "Average Loss for 600 iteration is : 0.9293606299161911\n",
            "Evaluation Accuracy is : 0.6541\n",
            "Average Loss for 100 iteration is : 0.905824847817421\n",
            "Average Loss for 200 iteration is : 0.9062930345535278\n",
            "Average Loss for 300 iteration is : 0.9289000380039215\n",
            "Average Loss for 400 iteration is : 0.9252018606662751\n",
            "Average Loss for 500 iteration is : 0.907913529574871\n",
            "Average Loss for 600 iteration is : 0.9077517914772034\n",
            "Evaluation Accuracy is : 0.6465\n",
            "Average Loss for 100 iteration is : 0.8919899290800095\n",
            "Average Loss for 200 iteration is : 0.9352445960044861\n",
            "Average Loss for 300 iteration is : 0.9272857159376144\n",
            "Average Loss for 400 iteration is : 0.9149904012680053\n",
            "Average Loss for 500 iteration is : 0.9126367872953415\n",
            "Average Loss for 600 iteration is : 0.8979208171367645\n",
            "Evaluation Accuracy is : 0.6486\n",
            "Average Loss for 100 iteration is : 0.8936680066585541\n",
            "Average Loss for 200 iteration is : 0.9185616195201873\n",
            "Average Loss for 300 iteration is : 0.9003687500953674\n",
            "Average Loss for 400 iteration is : 0.933753318786621\n",
            "Average Loss for 500 iteration is : 0.9153804284334183\n",
            "Average Loss for 600 iteration is : 0.8957965224981308\n",
            "Evaluation Accuracy is : 0.6512\n",
            "Average Loss for 100 iteration is : 0.9135142189264297\n",
            "Average Loss for 200 iteration is : 0.9138975822925568\n",
            "Average Loss for 300 iteration is : 0.8858136117458344\n",
            "Average Loss for 400 iteration is : 0.9172412329912185\n",
            "Average Loss for 500 iteration is : 0.9053706723451614\n",
            "Average Loss for 600 iteration is : 0.9053204530477523\n",
            "Evaluation Accuracy is : 0.658\n",
            "Average Loss for 100 iteration is : 0.9143226236104965\n",
            "Average Loss for 200 iteration is : 0.9092975348234177\n",
            "Average Loss for 300 iteration is : 0.9057358866930008\n",
            "Average Loss for 400 iteration is : 0.9191260808706283\n",
            "Average Loss for 500 iteration is : 0.9043577098846436\n",
            "Average Loss for 600 iteration is : 0.896099653840065\n",
            "Evaluation Accuracy is : 0.6529\n",
            "Average Loss for 100 iteration is : 0.8989577603340149\n",
            "Average Loss for 200 iteration is : 0.9111035627126693\n",
            "Average Loss for 300 iteration is : 0.9352529752254486\n",
            "Average Loss for 400 iteration is : 0.8906463158130645\n",
            "Average Loss for 500 iteration is : 0.9123859411478042\n",
            "Average Loss for 600 iteration is : 0.911909602880478\n",
            "Evaluation Accuracy is : 0.6469\n",
            "Average Loss for 100 iteration is : 0.9118525898456573\n",
            "Average Loss for 200 iteration is : 0.8949167919158936\n",
            "Average Loss for 300 iteration is : 0.909509938955307\n",
            "Average Loss for 400 iteration is : 0.9018483906984329\n",
            "Average Loss for 500 iteration is : 0.9304855632781982\n",
            "Average Loss for 600 iteration is : 0.8979854959249497\n",
            "Evaluation Accuracy is : 0.6545\n",
            "Average Loss for 100 iteration is : 0.9043539494276047\n",
            "Average Loss for 200 iteration is : 0.920727344751358\n",
            "Average Loss for 300 iteration is : 0.9037895381450654\n",
            "Average Loss for 400 iteration is : 0.9188861924409867\n",
            "Average Loss for 500 iteration is : 0.91408458173275\n",
            "Average Loss for 600 iteration is : 0.8806837290525437\n",
            "Evaluation Accuracy is : 0.6501\n",
            "Average Loss for 100 iteration is : 0.9017327952384949\n",
            "Average Loss for 200 iteration is : 0.9137795960903168\n",
            "Average Loss for 300 iteration is : 0.9038302230834961\n",
            "Average Loss for 400 iteration is : 0.9077413713932038\n",
            "Average Loss for 500 iteration is : 0.9101330518722535\n",
            "Average Loss for 600 iteration is : 0.9389676892757416\n",
            "Evaluation Accuracy is : 0.6466\n",
            "Average Loss for 100 iteration is : 0.917076815366745\n",
            "Average Loss for 200 iteration is : 0.8981180620193482\n",
            "Average Loss for 300 iteration is : 0.9308525729179382\n",
            "Average Loss for 400 iteration is : 0.895038771033287\n",
            "Average Loss for 500 iteration is : 0.8950088721513748\n",
            "Average Loss for 600 iteration is : 0.9300245434045792\n",
            "Evaluation Accuracy is : 0.6463\n",
            "Average Loss for 100 iteration is : 0.8947197949886322\n",
            "Average Loss for 200 iteration is : 0.9123695266246795\n",
            "Average Loss for 300 iteration is : 0.9275103110074997\n",
            "Average Loss for 400 iteration is : 0.9019883310794831\n",
            "Average Loss for 500 iteration is : 0.8962294411659241\n",
            "Average Loss for 600 iteration is : 0.8909365338087082\n",
            "Evaluation Accuracy is : 0.6505\n",
            "Average Loss for 100 iteration is : 0.922776095867157\n",
            "Average Loss for 200 iteration is : 0.8986483293771744\n",
            "Average Loss for 300 iteration is : 0.9272342813014984\n",
            "Average Loss for 400 iteration is : 0.900892009139061\n",
            "Average Loss for 500 iteration is : 0.902041699886322\n",
            "Average Loss for 600 iteration is : 0.8872272765636444\n",
            "Evaluation Accuracy is : 0.6474\n",
            "Average Loss for 100 iteration is : 0.8987888282537461\n",
            "Average Loss for 200 iteration is : 0.901919248700142\n",
            "Average Loss for 300 iteration is : 0.8990384060144424\n",
            "Average Loss for 400 iteration is : 0.9071022373437881\n",
            "Average Loss for 500 iteration is : 0.9276131808757782\n",
            "Average Loss for 600 iteration is : 0.891663014292717\n",
            "Evaluation Accuracy is : 0.6474\n",
            "Average Loss for 100 iteration is : 0.8922127717733384\n",
            "Average Loss for 200 iteration is : 0.8808967113494873\n",
            "Average Loss for 300 iteration is : 0.9002340018749238\n",
            "Average Loss for 400 iteration is : 0.9179365342855453\n",
            "Average Loss for 500 iteration is : 0.9109956049919128\n",
            "Average Loss for 600 iteration is : 0.8978440868854523\n",
            "Evaluation Accuracy is : 0.6498\n",
            "Average Loss for 100 iteration is : 0.8814085763692856\n",
            "Average Loss for 200 iteration is : 0.8981164091825485\n",
            "Average Loss for 300 iteration is : 0.9224080210924148\n",
            "Average Loss for 400 iteration is : 0.9071678447723389\n",
            "Average Loss for 500 iteration is : 0.9024290895462036\n",
            "Average Loss for 600 iteration is : 0.9093822890520096\n",
            "Evaluation Accuracy is : 0.6515\n",
            "Average Loss for 100 iteration is : 0.8974685889482498\n",
            "Average Loss for 200 iteration is : 0.9005705899000168\n",
            "Average Loss for 300 iteration is : 0.9023220670223236\n",
            "Average Loss for 400 iteration is : 0.9234570449590683\n",
            "Average Loss for 500 iteration is : 0.8854134029150009\n",
            "Average Loss for 600 iteration is : 0.9017770618200303\n",
            "Evaluation Accuracy is : 0.6483\n",
            "Average Loss for 100 iteration is : 0.9124458265304566\n",
            "Average Loss for 200 iteration is : 0.9032131993770599\n",
            "Average Loss for 300 iteration is : 0.8820330011844635\n",
            "Average Loss for 400 iteration is : 0.8964709109067917\n",
            "Average Loss for 500 iteration is : 0.9245647662878036\n",
            "Average Loss for 600 iteration is : 0.8761811798810959\n",
            "Evaluation Accuracy is : 0.6562\n",
            "Average Loss for 100 iteration is : 0.8684950751066208\n",
            "Average Loss for 200 iteration is : 0.8974008214473724\n",
            "Average Loss for 300 iteration is : 0.9190215218067169\n",
            "Average Loss for 400 iteration is : 0.8920790475606918\n",
            "Average Loss for 500 iteration is : 0.8977931457757949\n",
            "Average Loss for 600 iteration is : 0.9333384954929351\n",
            "Evaluation Accuracy is : 0.6486\n",
            "Average Loss for 100 iteration is : 0.9192526417970658\n",
            "Average Loss for 200 iteration is : 0.9002027863264084\n",
            "Average Loss for 300 iteration is : 0.9135565042495728\n",
            "Average Loss for 400 iteration is : 0.8939841479063034\n",
            "Average Loss for 500 iteration is : 0.9180299532413483\n",
            "Average Loss for 600 iteration is : 0.8752691441774368\n",
            "Evaluation Accuracy is : 0.6575\n",
            "Average Loss for 100 iteration is : 0.9006897628307342\n",
            "Average Loss for 200 iteration is : 0.8998572885990143\n",
            "Average Loss for 300 iteration is : 0.8917076253890991\n",
            "Average Loss for 400 iteration is : 0.8956379687786102\n",
            "Average Loss for 500 iteration is : 0.9019051289558411\n",
            "Average Loss for 600 iteration is : 0.8981204101443291\n",
            "Evaluation Accuracy is : 0.6531\n",
            "Average Loss for 100 iteration is : 0.9026692974567413\n",
            "Average Loss for 200 iteration is : 0.8956801605224609\n",
            "Average Loss for 300 iteration is : 0.8997696578502655\n",
            "Average Loss for 400 iteration is : 0.8868679320812225\n",
            "Average Loss for 500 iteration is : 0.9092310363054276\n",
            "Average Loss for 600 iteration is : 0.8982993334531784\n",
            "Evaluation Accuracy is : 0.6478\n",
            "Average Loss for 100 iteration is : 0.8912495130300522\n",
            "Average Loss for 200 iteration is : 0.8870705372095108\n",
            "Average Loss for 300 iteration is : 0.8976526349782944\n",
            "Average Loss for 400 iteration is : 0.9011735755205155\n",
            "Average Loss for 500 iteration is : 0.8979311668872834\n",
            "Average Loss for 600 iteration is : 0.9025913143157959\n",
            "Evaluation Accuracy is : 0.6579\n",
            "Average Loss for 100 iteration is : 0.8807079964876174\n",
            "Average Loss for 200 iteration is : 0.8942725610733032\n",
            "Average Loss for 300 iteration is : 0.8940213108062744\n",
            "Average Loss for 400 iteration is : 0.9026498287916184\n",
            "Average Loss for 500 iteration is : 0.9081875002384185\n",
            "Average Loss for 600 iteration is : 0.8930252832174301\n",
            "Evaluation Accuracy is : 0.6589\n",
            "Average Loss for 100 iteration is : 0.8805049234628677\n",
            "Average Loss for 200 iteration is : 0.8916896843910217\n",
            "Average Loss for 300 iteration is : 0.8917018419504166\n",
            "Average Loss for 400 iteration is : 0.8676126599311829\n",
            "Average Loss for 500 iteration is : 0.9079250460863113\n",
            "Average Loss for 600 iteration is : 0.8808760356903076\n",
            "Evaluation Accuracy is : 0.6556\n",
            "Average Loss for 100 iteration is : 0.846329345703125\n",
            "Average Loss for 200 iteration is : 0.91414302110672\n",
            "Average Loss for 300 iteration is : 0.8673544579744339\n",
            "Average Loss for 400 iteration is : 0.9154386192560195\n",
            "Average Loss for 500 iteration is : 0.9116584861278534\n",
            "Average Loss for 600 iteration is : 0.9003499531745911\n",
            "Evaluation Accuracy is : 0.6522\n",
            "Average Loss for 100 iteration is : 0.8790875515341758\n",
            "Average Loss for 200 iteration is : 0.90695729970932\n",
            "Average Loss for 300 iteration is : 0.8831585800647735\n",
            "Average Loss for 400 iteration is : 0.9072420942783356\n",
            "Average Loss for 500 iteration is : 0.8970493352413178\n",
            "Average Loss for 600 iteration is : 0.8853085553646087\n",
            "Evaluation Accuracy is : 0.6552\n",
            "Average Loss for 100 iteration is : 0.8935206472873688\n",
            "Average Loss for 200 iteration is : 0.8858089989423752\n",
            "Average Loss for 300 iteration is : 0.8981470215320587\n",
            "Average Loss for 400 iteration is : 0.8957826805114746\n",
            "Average Loss for 500 iteration is : 0.8845433497428894\n",
            "Average Loss for 600 iteration is : 0.8994980359077454\n",
            "Evaluation Accuracy is : 0.6532\n",
            "Average Loss for 100 iteration is : 0.8913030058145524\n",
            "Average Loss for 200 iteration is : 0.8778846907615662\n",
            "Average Loss for 300 iteration is : 0.8991903913021088\n",
            "Average Loss for 400 iteration is : 0.8948695188760758\n",
            "Average Loss for 500 iteration is : 0.9108837550878525\n",
            "Average Loss for 600 iteration is : 0.8840942001342773\n",
            "Evaluation Accuracy is : 0.6574\n",
            "Average Loss for 100 iteration is : 0.8958761101961136\n",
            "Average Loss for 200 iteration is : 0.9001647984981537\n",
            "Average Loss for 300 iteration is : 0.885075985789299\n",
            "Average Loss for 400 iteration is : 0.884827898144722\n",
            "Average Loss for 500 iteration is : 0.8742550933361053\n",
            "Average Loss for 600 iteration is : 0.9026905113458633\n",
            "Evaluation Accuracy is : 0.6569\n",
            "Average Loss for 100 iteration is : 0.8728285259008408\n",
            "Average Loss for 200 iteration is : 0.8987861776351929\n",
            "Average Loss for 300 iteration is : 0.8897323787212372\n",
            "Average Loss for 400 iteration is : 0.9118900626897812\n",
            "Average Loss for 500 iteration is : 0.9039360606670379\n",
            "Average Loss for 600 iteration is : 0.8784059327840805\n",
            "Evaluation Accuracy is : 0.6555\n",
            "Average Loss for 100 iteration is : 0.8833754247426987\n",
            "Average Loss for 200 iteration is : 0.8955831289291382\n",
            "Average Loss for 300 iteration is : 0.8707616782188415\n",
            "Average Loss for 400 iteration is : 0.8724131315946579\n",
            "Average Loss for 500 iteration is : 0.8942824220657348\n",
            "Average Loss for 600 iteration is : 0.8990791952610016\n",
            "Evaluation Accuracy is : 0.6587\n",
            "Average Loss for 100 iteration is : 0.8727993267774582\n",
            "Average Loss for 200 iteration is : 0.8940323305130005\n",
            "Average Loss for 300 iteration is : 0.8617586553096771\n",
            "Average Loss for 400 iteration is : 0.9077101141214371\n",
            "Average Loss for 500 iteration is : 0.897498117685318\n",
            "Average Loss for 600 iteration is : 0.9097352880239487\n",
            "Evaluation Accuracy is : 0.6487\n",
            "Average Loss for 100 iteration is : 0.8965169209241867\n",
            "Average Loss for 200 iteration is : 0.8720579302310943\n",
            "Average Loss for 300 iteration is : 0.8818065911531449\n",
            "Average Loss for 400 iteration is : 0.8915329390764236\n",
            "Average Loss for 500 iteration is : 0.8852599221467972\n",
            "Average Loss for 600 iteration is : 0.8970962947607041\n",
            "Evaluation Accuracy is : 0.6554\n",
            "Average Loss for 100 iteration is : 0.8908891320228577\n",
            "Average Loss for 200 iteration is : 0.8698244839906693\n",
            "Average Loss for 300 iteration is : 0.8835741823911667\n",
            "Average Loss for 400 iteration is : 0.8735419362783432\n",
            "Average Loss for 500 iteration is : 0.8709285461902618\n",
            "Average Loss for 600 iteration is : 0.890718766450882\n",
            "Evaluation Accuracy is : 0.6582\n",
            "Average Loss for 100 iteration is : 0.9005090549588204\n",
            "Average Loss for 200 iteration is : 0.8833720362186432\n",
            "Average Loss for 300 iteration is : 0.8862211549282074\n",
            "Average Loss for 400 iteration is : 0.8795660710334778\n",
            "Average Loss for 500 iteration is : 0.8826729452610016\n",
            "Average Loss for 600 iteration is : 0.8772545427083969\n",
            "Evaluation Accuracy is : 0.6603\n",
            "Average Loss for 100 iteration is : 0.8773164516687393\n",
            "Average Loss for 200 iteration is : 0.8927463495731354\n",
            "Average Loss for 300 iteration is : 0.8846843165159225\n",
            "Average Loss for 400 iteration is : 0.8908633518218995\n",
            "Average Loss for 500 iteration is : 0.8868085730075836\n",
            "Average Loss for 600 iteration is : 0.8674880248308182\n",
            "Evaluation Accuracy is : 0.6579\n",
            "Average Loss for 100 iteration is : 0.8711853611469269\n",
            "Average Loss for 200 iteration is : 0.8834298485517502\n",
            "Average Loss for 300 iteration is : 0.8649139034748078\n",
            "Average Loss for 400 iteration is : 0.9093787342309951\n",
            "Average Loss for 500 iteration is : 0.8827054995298386\n",
            "Average Loss for 600 iteration is : 0.8713377273082733\n",
            "Evaluation Accuracy is : 0.6583\n",
            "Average Loss for 100 iteration is : 0.8770217072963714\n",
            "Average Loss for 200 iteration is : 0.8950702744722366\n",
            "Average Loss for 300 iteration is : 0.8649047654867172\n",
            "Average Loss for 400 iteration is : 0.9005481970310211\n",
            "Average Loss for 500 iteration is : 0.8765301018953323\n",
            "Average Loss for 600 iteration is : 0.9006493866443634\n",
            "Evaluation Accuracy is : 0.6572\n",
            "Average Loss for 100 iteration is : 0.8792802560329437\n",
            "Average Loss for 200 iteration is : 0.8510350924730301\n",
            "Average Loss for 300 iteration is : 0.8884426099061966\n",
            "Average Loss for 400 iteration is : 0.8963655096292495\n",
            "Average Loss for 500 iteration is : 0.8874147993326187\n",
            "Average Loss for 600 iteration is : 0.8959160000085831\n",
            "Evaluation Accuracy is : 0.6645\n",
            "Average Loss for 100 iteration is : 0.8864313578605652\n",
            "Average Loss for 200 iteration is : 0.8854966640472413\n",
            "Average Loss for 300 iteration is : 0.8883973956108093\n",
            "Average Loss for 400 iteration is : 0.8469982010126114\n",
            "Average Loss for 500 iteration is : 0.9032031631469727\n",
            "Average Loss for 600 iteration is : 0.8553749722242355\n",
            "Evaluation Accuracy is : 0.6477\n",
            "Average Loss for 100 iteration is : 0.8788781601190567\n",
            "Average Loss for 200 iteration is : 0.9092190593481064\n",
            "Average Loss for 300 iteration is : 0.8597650125622749\n",
            "Average Loss for 400 iteration is : 0.8754211670160293\n",
            "Average Loss for 500 iteration is : 0.8784755355119706\n",
            "Average Loss for 600 iteration is : 0.8809437119960785\n",
            "Evaluation Accuracy is : 0.6634\n",
            "Average Loss for 100 iteration is : 0.8825075805187226\n",
            "Average Loss for 200 iteration is : 0.8754275810718536\n",
            "Average Loss for 300 iteration is : 0.8872787153720856\n",
            "Average Loss for 400 iteration is : 0.898125729560852\n",
            "Average Loss for 500 iteration is : 0.8649273800849915\n",
            "Average Loss for 600 iteration is : 0.9023973387479782\n",
            "Evaluation Accuracy is : 0.6595\n",
            "Average Loss for 100 iteration is : 0.8655881813168526\n",
            "Average Loss for 200 iteration is : 0.8867065024375915\n",
            "Average Loss for 300 iteration is : 0.8782021132111549\n",
            "Average Loss for 400 iteration is : 0.8647088283300399\n",
            "Average Loss for 500 iteration is : 0.8874339431524276\n",
            "Average Loss for 600 iteration is : 0.889586724638939\n",
            "Evaluation Accuracy is : 0.6612\n",
            "Average Loss for 100 iteration is : 0.8708833622932434\n",
            "Average Loss for 200 iteration is : 0.8881340336799621\n",
            "Average Loss for 300 iteration is : 0.8825527101755142\n",
            "Average Loss for 400 iteration is : 0.8733515912294387\n",
            "Average Loss for 500 iteration is : 0.8731957018375397\n",
            "Average Loss for 600 iteration is : 0.8679832231998443\n",
            "Evaluation Accuracy is : 0.6681\n",
            "Average Loss for 100 iteration is : 0.8660820698738099\n",
            "Average Loss for 200 iteration is : 0.8736652719974518\n",
            "Average Loss for 300 iteration is : 0.8829295152425766\n",
            "Average Loss for 400 iteration is : 0.8767679566144944\n",
            "Average Loss for 500 iteration is : 0.8865741509199142\n",
            "Average Loss for 600 iteration is : 0.8789853075146675\n",
            "Evaluation Accuracy is : 0.6592\n",
            "Average Loss for 100 iteration is : 0.8701298838853836\n",
            "Average Loss for 200 iteration is : 0.8573517847061157\n",
            "Average Loss for 300 iteration is : 0.8716197872161865\n",
            "Average Loss for 400 iteration is : 0.8889349007606506\n",
            "Average Loss for 500 iteration is : 0.8694745099544525\n",
            "Average Loss for 600 iteration is : 0.8758689296245575\n",
            "Evaluation Accuracy is : 0.6608\n",
            "Average Loss for 100 iteration is : 0.8653775292634964\n",
            "Average Loss for 200 iteration is : 0.8385679841041564\n",
            "Average Loss for 300 iteration is : 0.8807695230841637\n",
            "Average Loss for 400 iteration is : 0.8846496510505676\n",
            "Average Loss for 500 iteration is : 0.8876602631807328\n",
            "Average Loss for 600 iteration is : 0.901384471654892\n",
            "Evaluation Accuracy is : 0.6666\n",
            "Average Loss for 100 iteration is : 0.8698353290557861\n",
            "Average Loss for 200 iteration is : 0.8753846228122711\n",
            "Average Loss for 300 iteration is : 0.8605855363607406\n",
            "Average Loss for 400 iteration is : 0.8724731355905533\n",
            "Average Loss for 500 iteration is : 0.8812354868650436\n",
            "Average Loss for 600 iteration is : 0.8831757807731628\n",
            "Evaluation Accuracy is : 0.6668\n",
            "Average Loss for 100 iteration is : 0.8873372805118561\n",
            "Average Loss for 200 iteration is : 0.8746593606472015\n",
            "Average Loss for 300 iteration is : 0.8911098980903626\n",
            "Average Loss for 400 iteration is : 0.8448240578174591\n",
            "Average Loss for 500 iteration is : 0.8847881153225898\n",
            "Average Loss for 600 iteration is : 0.8785039848089218\n",
            "Evaluation Accuracy is : 0.6639\n",
            "Average Loss for 100 iteration is : 0.8842391610145569\n",
            "Average Loss for 200 iteration is : 0.8697725796699524\n",
            "Average Loss for 300 iteration is : 0.865314878821373\n",
            "Average Loss for 400 iteration is : 0.8843553978204727\n",
            "Average Loss for 500 iteration is : 0.863621574640274\n",
            "Average Loss for 600 iteration is : 0.8741137939691543\n",
            "Evaluation Accuracy is : 0.6642\n",
            "Average Loss for 100 iteration is : 0.8705372238159179\n",
            "Average Loss for 200 iteration is : 0.8810042363405227\n",
            "Average Loss for 300 iteration is : 0.8693733823299408\n",
            "Average Loss for 400 iteration is : 0.8386431008577346\n",
            "Average Loss for 500 iteration is : 0.8791621726751327\n",
            "Average Loss for 600 iteration is : 0.8751193445920944\n",
            "Evaluation Accuracy is : 0.6636\n",
            "Average Loss for 100 iteration is : 0.8738406306505203\n",
            "Average Loss for 200 iteration is : 0.8890404975414277\n",
            "Average Loss for 300 iteration is : 0.8653584170341492\n",
            "Average Loss for 400 iteration is : 0.8446129056811332\n",
            "Average Loss for 500 iteration is : 0.8346112811565399\n",
            "Average Loss for 600 iteration is : 0.8692733982205391\n",
            "Evaluation Accuracy is : 0.6551\n",
            "Average Loss for 100 iteration is : 0.8401622611284256\n",
            "Average Loss for 200 iteration is : 0.8796710115671158\n",
            "Average Loss for 300 iteration is : 0.8837318855524063\n",
            "Average Loss for 400 iteration is : 0.8618633180856705\n",
            "Average Loss for 500 iteration is : 0.8742177748680114\n",
            "Average Loss for 600 iteration is : 0.8725724750757218\n",
            "Evaluation Accuracy is : 0.6664\n",
            "Average Loss for 100 iteration is : 0.8602030992507934\n",
            "Average Loss for 200 iteration is : 0.8778055536746979\n",
            "Average Loss for 300 iteration is : 0.8685211443901062\n",
            "Average Loss for 400 iteration is : 0.8494283127784729\n",
            "Average Loss for 500 iteration is : 0.8753841191530227\n",
            "Average Loss for 600 iteration is : 0.867260273694992\n",
            "Evaluation Accuracy is : 0.6621\n",
            "Average Loss for 100 iteration is : 0.8660221338272095\n",
            "Average Loss for 200 iteration is : 0.8486307942867279\n",
            "Average Loss for 300 iteration is : 0.8574337959289551\n",
            "Average Loss for 400 iteration is : 0.8737613224983215\n",
            "Average Loss for 500 iteration is : 0.8699241316318512\n",
            "Average Loss for 600 iteration is : 0.8643922472000122\n",
            "Evaluation Accuracy is : 0.6692\n",
            "Average Loss for 100 iteration is : 0.8673599946498871\n",
            "Average Loss for 200 iteration is : 0.8535523107647895\n",
            "Average Loss for 300 iteration is : 0.8786968094110489\n",
            "Average Loss for 400 iteration is : 0.8497876185178757\n",
            "Average Loss for 500 iteration is : 0.8688950109481811\n",
            "Average Loss for 600 iteration is : 0.8795543169975281\n",
            "Evaluation Accuracy is : 0.6659\n",
            "Average Loss for 100 iteration is : 0.8806513291597367\n",
            "Average Loss for 200 iteration is : 0.8791935509443283\n",
            "Average Loss for 300 iteration is : 0.8667681282758712\n",
            "Average Loss for 400 iteration is : 0.8865962350368499\n",
            "Average Loss for 500 iteration is : 0.8473897045850753\n",
            "Average Loss for 600 iteration is : 0.8544730132818222\n",
            "Evaluation Accuracy is : 0.6619\n",
            "Average Loss for 100 iteration is : 0.8694382083415985\n",
            "Average Loss for 200 iteration is : 0.8689016884565354\n",
            "Average Loss for 300 iteration is : 0.8661574625968933\n",
            "Average Loss for 400 iteration is : 0.860522729754448\n",
            "Average Loss for 500 iteration is : 0.866744459271431\n",
            "Average Loss for 600 iteration is : 0.8797483706474304\n",
            "Evaluation Accuracy is : 0.6682\n",
            "Average Loss for 100 iteration is : 0.8866961669921875\n",
            "Average Loss for 200 iteration is : 0.8718638402223587\n",
            "Average Loss for 300 iteration is : 0.8606001061201095\n",
            "Average Loss for 400 iteration is : 0.8474790871143341\n",
            "Average Loss for 500 iteration is : 0.8545506858825683\n",
            "Average Loss for 600 iteration is : 0.8592891189455986\n",
            "Evaluation Accuracy is : 0.6614\n",
            "Average Loss for 100 iteration is : 0.8694772118330002\n",
            "Average Loss for 200 iteration is : 0.8755803799629212\n",
            "Average Loss for 300 iteration is : 0.8573282933235169\n",
            "Average Loss for 400 iteration is : 0.8750258773565293\n",
            "Average Loss for 500 iteration is : 0.8718712520599365\n",
            "Average Loss for 600 iteration is : 0.8768077635765076\n",
            "Evaluation Accuracy is : 0.6604\n",
            "Average Loss for 100 iteration is : 0.8474682748317719\n",
            "Average Loss for 200 iteration is : 0.8739055466651916\n",
            "Average Loss for 300 iteration is : 0.8493363296985627\n",
            "Average Loss for 400 iteration is : 0.8579794007539749\n",
            "Average Loss for 500 iteration is : 0.8839367777109146\n",
            "Average Loss for 600 iteration is : 0.8824814409017563\n",
            "Evaluation Accuracy is : 0.6523\n",
            "Average Loss for 100 iteration is : 0.8698736721277237\n",
            "Average Loss for 200 iteration is : 0.8669602423906326\n",
            "Average Loss for 300 iteration is : 0.8536100226640702\n",
            "Average Loss for 400 iteration is : 0.8772923624515534\n",
            "Average Loss for 500 iteration is : 0.8424749106168747\n",
            "Average Loss for 600 iteration is : 0.8839638191461563\n",
            "Evaluation Accuracy is : 0.6569\n",
            "Average Loss for 100 iteration is : 0.8711757797002793\n",
            "Average Loss for 200 iteration is : 0.8579362446069717\n",
            "Average Loss for 300 iteration is : 0.8712076878547669\n",
            "Average Loss for 400 iteration is : 0.850860139131546\n",
            "Average Loss for 500 iteration is : 0.8570120686292648\n",
            "Average Loss for 600 iteration is : 0.8705827224254609\n",
            "Evaluation Accuracy is : 0.665\n",
            "Average Loss for 100 iteration is : 0.8336085885763168\n",
            "Average Loss for 200 iteration is : 0.8593613111972809\n",
            "Average Loss for 300 iteration is : 0.8555357086658478\n",
            "Average Loss for 400 iteration is : 0.8636312890052795\n",
            "Average Loss for 500 iteration is : 0.8826635283231735\n",
            "Average Loss for 600 iteration is : 0.8789090460538864\n",
            "Evaluation Accuracy is : 0.6657\n",
            "Average Loss for 100 iteration is : 0.8877602308988571\n",
            "Average Loss for 200 iteration is : 0.8646950137615204\n",
            "Average Loss for 300 iteration is : 0.8647507226467133\n",
            "Average Loss for 400 iteration is : 0.869507087469101\n",
            "Average Loss for 500 iteration is : 0.8620641022920609\n",
            "Average Loss for 600 iteration is : 0.857955030798912\n",
            "Evaluation Accuracy is : 0.6652\n",
            "Average Loss for 100 iteration is : 0.8524835968017578\n",
            "Average Loss for 200 iteration is : 0.8606251162290574\n",
            "Average Loss for 300 iteration is : 0.8463238376379013\n",
            "Average Loss for 400 iteration is : 0.8608315896987915\n",
            "Average Loss for 500 iteration is : 0.857446380853653\n",
            "Average Loss for 600 iteration is : 0.8605883556604386\n",
            "Evaluation Accuracy is : 0.669\n",
            "Average Loss for 100 iteration is : 0.8438792955875397\n",
            "Average Loss for 200 iteration is : 0.8603161805868149\n",
            "Average Loss for 300 iteration is : 0.8596264731884002\n",
            "Average Loss for 400 iteration is : 0.8553995525836945\n",
            "Average Loss for 500 iteration is : 0.8750085443258285\n",
            "Average Loss for 600 iteration is : 0.8649215245246887\n",
            "Evaluation Accuracy is : 0.6593\n",
            "Average Loss for 100 iteration is : 0.8285783684253692\n",
            "Average Loss for 200 iteration is : 0.8491808933019638\n",
            "Average Loss for 300 iteration is : 0.8469304084777832\n",
            "Average Loss for 400 iteration is : 0.8539611130952836\n",
            "Average Loss for 500 iteration is : 0.8571724963188171\n",
            "Average Loss for 600 iteration is : 0.8592092210054397\n",
            "Evaluation Accuracy is : 0.6683\n",
            "Average Loss for 100 iteration is : 0.8637089753150939\n",
            "Average Loss for 200 iteration is : 0.8493045598268509\n",
            "Average Loss for 300 iteration is : 0.8693884235620498\n",
            "Average Loss for 400 iteration is : 0.8434705239534378\n",
            "Average Loss for 500 iteration is : 0.8709147936105728\n",
            "Average Loss for 600 iteration is : 0.8605164647102356\n",
            "Evaluation Accuracy is : 0.6688\n",
            "Average Loss for 100 iteration is : 0.8357862889766693\n",
            "Average Loss for 200 iteration is : 0.8522699534893036\n",
            "Average Loss for 300 iteration is : 0.8648601579666138\n",
            "Average Loss for 400 iteration is : 0.8637451493740081\n",
            "Average Loss for 500 iteration is : 0.880198677778244\n",
            "Average Loss for 600 iteration is : 0.8508460539579391\n",
            "Evaluation Accuracy is : 0.6663\n",
            "Average Loss for 100 iteration is : 0.853551653623581\n",
            "Average Loss for 200 iteration is : 0.8841633623838425\n",
            "Average Loss for 300 iteration is : 0.8301861357688903\n",
            "Average Loss for 400 iteration is : 0.8727841180562973\n",
            "Average Loss for 500 iteration is : 0.8647707629203797\n",
            "Average Loss for 600 iteration is : 0.8497241264581681\n",
            "Evaluation Accuracy is : 0.662\n",
            "Average Loss for 100 iteration is : 0.8464496451616287\n",
            "Average Loss for 200 iteration is : 0.8722429817914963\n",
            "Average Loss for 300 iteration is : 0.8493727302551269\n",
            "Average Loss for 400 iteration is : 0.8626579666137695\n",
            "Average Loss for 500 iteration is : 0.8432146495580674\n",
            "Average Loss for 600 iteration is : 0.870906965136528\n",
            "Evaluation Accuracy is : 0.6649\n",
            "Average Loss for 100 iteration is : 0.8262510240077973\n",
            "Average Loss for 200 iteration is : 0.8634040868282318\n",
            "Average Loss for 300 iteration is : 0.8451238995790482\n",
            "Average Loss for 400 iteration is : 0.8460783755779266\n",
            "Average Loss for 500 iteration is : 0.8751542311906815\n",
            "Average Loss for 600 iteration is : 0.8535673153400422\n",
            "Evaluation Accuracy is : 0.6612\n",
            "Average Loss for 100 iteration is : 0.8357311779260636\n",
            "Average Loss for 200 iteration is : 0.8528311336040497\n",
            "Average Loss for 300 iteration is : 0.8614350467920303\n",
            "Average Loss for 400 iteration is : 0.8688220912218094\n",
            "Average Loss for 500 iteration is : 0.8599161159992218\n",
            "Average Loss for 600 iteration is : 0.839884244799614\n",
            "Evaluation Accuracy is : 0.6707\n",
            "Average Loss for 100 iteration is : 0.8357650315761567\n",
            "Average Loss for 200 iteration is : 0.8602182298898697\n",
            "Average Loss for 300 iteration is : 0.8390420430898666\n",
            "Average Loss for 400 iteration is : 0.8790621370077133\n",
            "Average Loss for 500 iteration is : 0.8516654002666474\n",
            "Average Loss for 600 iteration is : 0.8419916504621505\n",
            "Evaluation Accuracy is : 0.6619\n",
            "Average Loss for 100 iteration is : 0.8420073944330215\n",
            "Average Loss for 200 iteration is : 0.8601981198787689\n",
            "Average Loss for 300 iteration is : 0.8542784559726715\n",
            "Average Loss for 400 iteration is : 0.8563781040906906\n",
            "Average Loss for 500 iteration is : 0.8555229878425599\n",
            "Average Loss for 600 iteration is : 0.8646213781833648\n",
            "Evaluation Accuracy is : 0.6698\n",
            "Average Loss for 100 iteration is : 0.8494459533691406\n",
            "Average Loss for 200 iteration is : 0.8653420078754425\n",
            "Average Loss for 300 iteration is : 0.852771269083023\n",
            "Average Loss for 400 iteration is : 0.8465653425455093\n",
            "Average Loss for 500 iteration is : 0.8382320708036423\n",
            "Average Loss for 600 iteration is : 0.8696424376964569\n",
            "Evaluation Accuracy is : 0.6548\n",
            "Average Loss for 100 iteration is : 0.8727943420410156\n",
            "Average Loss for 200 iteration is : 0.8583609616756439\n",
            "Average Loss for 300 iteration is : 0.8465822023153305\n",
            "Average Loss for 400 iteration is : 0.8192204892635345\n",
            "Average Loss for 500 iteration is : 0.8725476396083832\n",
            "Average Loss for 600 iteration is : 0.8523024487495422\n",
            "Evaluation Accuracy is : 0.6681\n",
            "Average Loss for 100 iteration is : 0.8375197207927704\n",
            "Average Loss for 200 iteration is : 0.8378931140899658\n",
            "Average Loss for 300 iteration is : 0.8523029774427414\n",
            "Average Loss for 400 iteration is : 0.8414735716581344\n",
            "Average Loss for 500 iteration is : 0.8508550876379013\n",
            "Average Loss for 600 iteration is : 0.8740726429224014\n",
            "Evaluation Accuracy is : 0.6689\n",
            "Average Loss for 100 iteration is : 0.8321899682283401\n",
            "Average Loss for 200 iteration is : 0.8303550755977631\n",
            "Average Loss for 300 iteration is : 0.8262460064888001\n",
            "Average Loss for 400 iteration is : 0.8543376541137695\n",
            "Average Loss for 500 iteration is : 0.8514473193883896\n",
            "Average Loss for 600 iteration is : 0.8805893105268479\n",
            "Evaluation Accuracy is : 0.6756\n",
            "Average Loss for 100 iteration is : 0.8336985963582992\n",
            "Average Loss for 200 iteration is : 0.8429689401388168\n",
            "Average Loss for 300 iteration is : 0.8452023702859879\n",
            "Average Loss for 400 iteration is : 0.8420847642421723\n",
            "Average Loss for 500 iteration is : 0.8449381476640702\n",
            "Average Loss for 600 iteration is : 0.8549760544300079\n",
            "Evaluation Accuracy is : 0.6764\n",
            "Average Loss for 100 iteration is : 0.8510221302509308\n",
            "Average Loss for 200 iteration is : 0.8495912367105484\n",
            "Average Loss for 300 iteration is : 0.8506478089094162\n",
            "Average Loss for 400 iteration is : 0.8421594822406768\n",
            "Average Loss for 500 iteration is : 0.8383995807170868\n",
            "Average Loss for 600 iteration is : 0.8245947331190109\n",
            "Evaluation Accuracy is : 0.6724\n",
            "Average Loss for 100 iteration is : 0.8639726716279984\n",
            "Average Loss for 200 iteration is : 0.8454485088586807\n",
            "Average Loss for 300 iteration is : 0.8326732420921326\n",
            "Average Loss for 400 iteration is : 0.8484332066774368\n",
            "Average Loss for 500 iteration is : 0.8519408708810806\n",
            "Average Loss for 600 iteration is : 0.8510009628534317\n",
            "Evaluation Accuracy is : 0.6616\n",
            "Average Loss for 100 iteration is : 0.8726103079319\n",
            "Average Loss for 200 iteration is : 0.8561380261182785\n",
            "Average Loss for 300 iteration is : 0.8502551639080047\n",
            "Average Loss for 400 iteration is : 0.8665554195642471\n",
            "Average Loss for 500 iteration is : 0.8633069491386414\n",
            "Average Loss for 600 iteration is : 0.8572858333587646\n",
            "Evaluation Accuracy is : 0.6777\n",
            "Average Loss for 100 iteration is : 0.8361801254749298\n",
            "Average Loss for 200 iteration is : 0.8560245078802109\n",
            "Average Loss for 300 iteration is : 0.8426557409763337\n",
            "Average Loss for 400 iteration is : 0.8552375888824463\n",
            "Average Loss for 500 iteration is : 0.8409329545497894\n",
            "Average Loss for 600 iteration is : 0.8555939710140228\n",
            "Evaluation Accuracy is : 0.6699\n",
            "Average Loss for 100 iteration is : 0.8292212969064713\n",
            "Average Loss for 200 iteration is : 0.8295811894536018\n",
            "Average Loss for 300 iteration is : 0.8565873688459397\n",
            "Average Loss for 400 iteration is : 0.8279552474617958\n",
            "Average Loss for 500 iteration is : 0.8654040259122848\n",
            "Average Loss for 600 iteration is : 0.8667096328735352\n",
            "Evaluation Accuracy is : 0.6632\n",
            "Average Loss for 100 iteration is : 0.8509750092029571\n",
            "Average Loss for 200 iteration is : 0.8413056647777557\n",
            "Average Loss for 300 iteration is : 0.8451201814413071\n",
            "Average Loss for 400 iteration is : 0.8273772954940796\n",
            "Average Loss for 500 iteration is : 0.8403494435548783\n",
            "Average Loss for 600 iteration is : 0.8453583294153213\n",
            "Evaluation Accuracy is : 0.6762\n",
            "Average Loss for 100 iteration is : 0.8389514327049256\n",
            "Average Loss for 200 iteration is : 0.8301643788814544\n",
            "Average Loss for 300 iteration is : 0.836639906167984\n",
            "Average Loss for 400 iteration is : 0.837669740319252\n",
            "Average Loss for 500 iteration is : 0.8755912566184998\n",
            "Average Loss for 600 iteration is : 0.8389639461040497\n",
            "Evaluation Accuracy is : 0.6743\n",
            "Average Loss for 100 iteration is : 0.833935005068779\n",
            "Average Loss for 200 iteration is : 0.8487171971797943\n",
            "Average Loss for 300 iteration is : 0.8317430537939071\n",
            "Average Loss for 400 iteration is : 0.8444487637281418\n",
            "Average Loss for 500 iteration is : 0.8511936157941818\n",
            "Average Loss for 600 iteration is : 0.8529765093326569\n",
            "Evaluation Accuracy is : 0.6683\n",
            "Average Loss for 100 iteration is : 0.8244907087087632\n",
            "Average Loss for 200 iteration is : 0.8455603167414665\n",
            "Average Loss for 300 iteration is : 0.8240585649013519\n",
            "Average Loss for 400 iteration is : 0.8500455951690674\n",
            "Average Loss for 500 iteration is : 0.8332464253902435\n",
            "Average Loss for 600 iteration is : 0.8528315091133117\n",
            "Evaluation Accuracy is : 0.6762\n",
            "Average Loss for 100 iteration is : 0.8417815798521042\n",
            "Average Loss for 200 iteration is : 0.8223291802406311\n",
            "Average Loss for 300 iteration is : 0.8469884967803956\n",
            "Average Loss for 400 iteration is : 0.8353228199481965\n",
            "Average Loss for 500 iteration is : 0.837491963505745\n",
            "Average Loss for 600 iteration is : 0.8596458470821381\n",
            "Evaluation Accuracy is : 0.6676\n",
            "Average Loss for 100 iteration is : 0.8257169896364212\n",
            "Average Loss for 200 iteration is : 0.8461825215816497\n",
            "Average Loss for 300 iteration is : 0.8133134195208549\n",
            "Average Loss for 400 iteration is : 0.8519430083036422\n",
            "Average Loss for 500 iteration is : 0.8360040757060051\n",
            "Average Loss for 600 iteration is : 0.849235822558403\n",
            "Evaluation Accuracy is : 0.6743\n",
            "Average Loss for 100 iteration is : 0.830782650411129\n",
            "Average Loss for 200 iteration is : 0.8225520366430282\n",
            "Average Loss for 300 iteration is : 0.8552314573526383\n",
            "Average Loss for 400 iteration is : 0.8373027700185776\n",
            "Average Loss for 500 iteration is : 0.8291958907246589\n",
            "Average Loss for 600 iteration is : 0.8567193979024887\n",
            "Evaluation Accuracy is : 0.672\n",
            "Average Loss for 100 iteration is : 0.8293140178918839\n",
            "Average Loss for 200 iteration is : 0.8442210805416107\n",
            "Average Loss for 300 iteration is : 0.841208074092865\n",
            "Average Loss for 400 iteration is : 0.8263392913341522\n",
            "Average Loss for 500 iteration is : 0.8353779494762421\n",
            "Average Loss for 600 iteration is : 0.8360764241218567\n",
            "Evaluation Accuracy is : 0.6693\n",
            "Average Loss for 100 iteration is : 0.8389447838068008\n",
            "Average Loss for 200 iteration is : 0.8572634410858154\n",
            "Average Loss for 300 iteration is : 0.8544620013237\n",
            "Average Loss for 400 iteration is : 0.8388625538349151\n",
            "Average Loss for 500 iteration is : 0.8135725235939026\n",
            "Average Loss for 600 iteration is : 0.8477968710660935\n",
            "Evaluation Accuracy is : 0.6686\n",
            "Average Loss for 100 iteration is : 0.8329281258583069\n",
            "Average Loss for 200 iteration is : 0.8383729547262192\n",
            "Average Loss for 300 iteration is : 0.8455976450443268\n",
            "Average Loss for 400 iteration is : 0.8329709029197693\n",
            "Average Loss for 500 iteration is : 0.8219398903846741\n",
            "Average Loss for 600 iteration is : 0.854271879196167\n",
            "Evaluation Accuracy is : 0.6785\n",
            "Average Loss for 100 iteration is : 0.8275890856981277\n",
            "Average Loss for 200 iteration is : 0.8391915225982666\n",
            "Average Loss for 300 iteration is : 0.8295721089839936\n",
            "Average Loss for 400 iteration is : 0.850108385682106\n",
            "Average Loss for 500 iteration is : 0.8466041645407677\n",
            "Average Loss for 600 iteration is : 0.8504487562179566\n",
            "Evaluation Accuracy is : 0.6671\n",
            "Average Loss for 100 iteration is : 0.8508089256286621\n",
            "Average Loss for 200 iteration is : 0.8479692628979683\n",
            "Average Loss for 300 iteration is : 0.8139811789989472\n",
            "Average Loss for 400 iteration is : 0.8462765568494797\n",
            "Average Loss for 500 iteration is : 0.8193901705741883\n",
            "Average Loss for 600 iteration is : 0.8693258845806122\n",
            "Evaluation Accuracy is : 0.6634\n",
            "Average Loss for 100 iteration is : 0.8447195929288864\n",
            "Average Loss for 200 iteration is : 0.8278590500354767\n",
            "Average Loss for 300 iteration is : 0.8338414716720581\n",
            "Average Loss for 400 iteration is : 0.8375216507911682\n",
            "Average Loss for 500 iteration is : 0.8368055739998818\n",
            "Average Loss for 600 iteration is : 0.8382785022258759\n",
            "Evaluation Accuracy is : 0.6806\n",
            "Average Loss for 100 iteration is : 0.8218006044626236\n",
            "Average Loss for 200 iteration is : 0.835319384932518\n",
            "Average Loss for 300 iteration is : 0.8376522117853165\n",
            "Average Loss for 400 iteration is : 0.8408451789617538\n",
            "Average Loss for 500 iteration is : 0.8453847473859787\n",
            "Average Loss for 600 iteration is : 0.816683692932129\n",
            "Evaluation Accuracy is : 0.6742\n",
            "Average Loss for 100 iteration is : 0.8269410035014153\n",
            "Average Loss for 200 iteration is : 0.8406629526615143\n",
            "Average Loss for 300 iteration is : 0.8301520949602127\n",
            "Average Loss for 400 iteration is : 0.844100878238678\n",
            "Average Loss for 500 iteration is : 0.8525236678123475\n",
            "Average Loss for 600 iteration is : 0.8450722754001617\n",
            "Evaluation Accuracy is : 0.6739\n",
            "Average Loss for 100 iteration is : 0.8291319179534912\n",
            "Average Loss for 200 iteration is : 0.8224667567014694\n",
            "Average Loss for 300 iteration is : 0.8206132137775421\n",
            "Average Loss for 400 iteration is : 0.8462035989761353\n",
            "Average Loss for 500 iteration is : 0.8601337730884552\n",
            "Average Loss for 600 iteration is : 0.8486950278282166\n",
            "Evaluation Accuracy is : 0.673\n",
            "Average Loss for 100 iteration is : 0.826943998336792\n",
            "Average Loss for 200 iteration is : 0.8440570014715195\n",
            "Average Loss for 300 iteration is : 0.838980712890625\n",
            "Average Loss for 400 iteration is : 0.8393357247114182\n",
            "Average Loss for 500 iteration is : 0.834395621418953\n",
            "Average Loss for 600 iteration is : 0.8483832049369812\n",
            "Evaluation Accuracy is : 0.6707\n",
            "Average Loss for 100 iteration is : 0.8372054380178452\n",
            "Average Loss for 200 iteration is : 0.8401495558023453\n",
            "Average Loss for 300 iteration is : 0.8151537054777145\n",
            "Average Loss for 400 iteration is : 0.8601546591520309\n",
            "Average Loss for 500 iteration is : 0.8098386192321777\n",
            "Average Loss for 600 iteration is : 0.8302385008335114\n",
            "Evaluation Accuracy is : 0.6739\n",
            "Average Loss for 100 iteration is : 0.8003293597698211\n",
            "Average Loss for 200 iteration is : 0.8261743569374085\n",
            "Average Loss for 300 iteration is : 0.840587387084961\n",
            "Average Loss for 400 iteration is : 0.8445440751314163\n",
            "Average Loss for 500 iteration is : 0.8456288981437683\n",
            "Average Loss for 600 iteration is : 0.8421818709373474\n",
            "Evaluation Accuracy is : 0.671\n",
            "Average Loss for 100 iteration is : 0.8377263259887695\n",
            "Average Loss for 200 iteration is : 0.8317144727706909\n",
            "Average Loss for 300 iteration is : 0.839954269528389\n",
            "Average Loss for 400 iteration is : 0.8338023525476456\n",
            "Average Loss for 500 iteration is : 0.8267545813322067\n",
            "Average Loss for 600 iteration is : 0.8302674973011017\n",
            "Evaluation Accuracy is : 0.6776\n",
            "Average Loss for 100 iteration is : 0.844223096370697\n",
            "Average Loss for 200 iteration is : 0.8122899055480957\n",
            "Average Loss for 300 iteration is : 0.8385572054982185\n",
            "Average Loss for 400 iteration is : 0.8059702908992767\n",
            "Average Loss for 500 iteration is : 0.8285149294137955\n",
            "Average Loss for 600 iteration is : 0.8222434747219086\n",
            "Evaluation Accuracy is : 0.6708\n",
            "Average Loss for 100 iteration is : 0.826822710633278\n",
            "Average Loss for 200 iteration is : 0.8259993755817413\n",
            "Average Loss for 300 iteration is : 0.8414424020051956\n",
            "Average Loss for 400 iteration is : 0.8582173973321915\n",
            "Average Loss for 500 iteration is : 0.834657930135727\n",
            "Average Loss for 600 iteration is : 0.8188222479820252\n",
            "Evaluation Accuracy is : 0.6745\n",
            "Average Loss for 100 iteration is : 0.8278305965662003\n",
            "Average Loss for 200 iteration is : 0.816094842851162\n",
            "Average Loss for 300 iteration is : 0.8328142488002777\n",
            "Average Loss for 400 iteration is : 0.8587843066453934\n",
            "Average Loss for 500 iteration is : 0.826719440817833\n",
            "Average Loss for 600 iteration is : 0.81989293217659\n",
            "Evaluation Accuracy is : 0.6757\n",
            "Average Loss for 100 iteration is : 0.8243336421251297\n",
            "Average Loss for 200 iteration is : 0.8126751208305358\n",
            "Average Loss for 300 iteration is : 0.8405366736650467\n",
            "Average Loss for 400 iteration is : 0.8511177676916123\n",
            "Average Loss for 500 iteration is : 0.8107943773269654\n",
            "Average Loss for 600 iteration is : 0.8275802999734878\n",
            "Evaluation Accuracy is : 0.6826\n",
            "Average Loss for 100 iteration is : 0.8189612674713135\n",
            "Average Loss for 200 iteration is : 0.8138551503419876\n",
            "Average Loss for 300 iteration is : 0.8248537796735763\n",
            "Average Loss for 400 iteration is : 0.8335617649555206\n",
            "Average Loss for 500 iteration is : 0.819969579577446\n",
            "Average Loss for 600 iteration is : 0.8465427315235138\n",
            "Evaluation Accuracy is : 0.678\n",
            "Average Loss for 100 iteration is : 0.8442735028266907\n",
            "Average Loss for 200 iteration is : 0.8313371068239213\n",
            "Average Loss for 300 iteration is : 0.8170942705869675\n",
            "Average Loss for 400 iteration is : 0.8397627544403076\n",
            "Average Loss for 500 iteration is : 0.8230401390790939\n",
            "Average Loss for 600 iteration is : 0.8333502393960953\n",
            "Evaluation Accuracy is : 0.6694\n",
            "Average Loss for 100 iteration is : 0.8474303847551345\n",
            "Average Loss for 200 iteration is : 0.8344161856174469\n",
            "Average Loss for 300 iteration is : 0.8635269945859909\n",
            "Average Loss for 400 iteration is : 0.8322758060693741\n",
            "Average Loss for 500 iteration is : 0.806152813732624\n",
            "Average Loss for 600 iteration is : 0.8155428332090378\n",
            "Evaluation Accuracy is : 0.675\n",
            "Average Loss for 100 iteration is : 0.8183409041166305\n",
            "Average Loss for 200 iteration is : 0.8003159368038177\n",
            "Average Loss for 300 iteration is : 0.8448830491304398\n",
            "Average Loss for 400 iteration is : 0.8150568360090256\n",
            "Average Loss for 500 iteration is : 0.8411959528923034\n",
            "Average Loss for 600 iteration is : 0.8286939960718155\n",
            "Evaluation Accuracy is : 0.674\n",
            "Average Loss for 100 iteration is : 0.8057791656255722\n",
            "Average Loss for 200 iteration is : 0.8270807558298111\n",
            "Average Loss for 300 iteration is : 0.8260012036561966\n",
            "Average Loss for 400 iteration is : 0.8315001010894776\n",
            "Average Loss for 500 iteration is : 0.8518004357814789\n",
            "Average Loss for 600 iteration is : 0.8243957543373108\n",
            "Evaluation Accuracy is : 0.678\n",
            "Average Loss for 100 iteration is : 0.8147961050271988\n",
            "Average Loss for 200 iteration is : 0.8416395276784897\n",
            "Average Loss for 300 iteration is : 0.8379521131515503\n",
            "Average Loss for 400 iteration is : 0.8466540968418121\n",
            "Average Loss for 500 iteration is : 0.8141551893949509\n",
            "Average Loss for 600 iteration is : 0.8153470939397812\n",
            "Evaluation Accuracy is : 0.6784\n",
            "Average Loss for 100 iteration is : 0.82532013297081\n",
            "Average Loss for 200 iteration is : 0.826141105890274\n",
            "Average Loss for 300 iteration is : 0.8254241052269936\n",
            "Average Loss for 400 iteration is : 0.8538145738840103\n",
            "Average Loss for 500 iteration is : 0.8194450658559799\n",
            "Average Loss for 600 iteration is : 0.8157841676473617\n",
            "Evaluation Accuracy is : 0.6674\n",
            "Average Loss for 100 iteration is : 0.8082366234064102\n",
            "Average Loss for 200 iteration is : 0.8206676492094993\n",
            "Average Loss for 300 iteration is : 0.8466176927089691\n",
            "Average Loss for 400 iteration is : 0.8272305166721344\n",
            "Average Loss for 500 iteration is : 0.8180207622051239\n",
            "Average Loss for 600 iteration is : 0.844789400100708\n",
            "Evaluation Accuracy is : 0.6736\n",
            "Average Loss for 100 iteration is : 0.8227811545133591\n",
            "Average Loss for 200 iteration is : 0.8146724194288254\n",
            "Average Loss for 300 iteration is : 0.8427942979335785\n",
            "Average Loss for 400 iteration is : 0.8463520342111588\n",
            "Average Loss for 500 iteration is : 0.8375311177968979\n",
            "Average Loss for 600 iteration is : 0.8045965123176575\n",
            "Evaluation Accuracy is : 0.6734\n",
            "Average Loss for 100 iteration is : 0.8333002245426178\n",
            "Average Loss for 200 iteration is : 0.8162917995452881\n",
            "Average Loss for 300 iteration is : 0.8161548462510109\n",
            "Average Loss for 400 iteration is : 0.8261365741491318\n",
            "Average Loss for 500 iteration is : 0.812740575671196\n",
            "Average Loss for 600 iteration is : 0.8214004760980607\n",
            "Evaluation Accuracy is : 0.6765\n",
            "Average Loss for 100 iteration is : 0.8171813035011292\n",
            "Average Loss for 200 iteration is : 0.8191720777750016\n",
            "Average Loss for 300 iteration is : 0.8484718400239945\n",
            "Average Loss for 400 iteration is : 0.828147965669632\n",
            "Average Loss for 500 iteration is : 0.8238506609201431\n",
            "Average Loss for 600 iteration is : 0.820744759440422\n",
            "Evaluation Accuracy is : 0.681\n",
            "Average Loss for 100 iteration is : 0.8327203035354614\n",
            "Average Loss for 200 iteration is : 0.8265190696716309\n",
            "Average Loss for 300 iteration is : 0.8024619066715241\n",
            "Average Loss for 400 iteration is : 0.8257250902056694\n",
            "Average Loss for 500 iteration is : 0.8455870151519775\n",
            "Average Loss for 600 iteration is : 0.8366054117679596\n",
            "Evaluation Accuracy is : 0.6761\n",
            "Average Loss for 100 iteration is : 0.7975610637664795\n",
            "Average Loss for 200 iteration is : 0.831871525645256\n",
            "Average Loss for 300 iteration is : 0.8318187209963799\n",
            "Average Loss for 400 iteration is : 0.8247542273998261\n",
            "Average Loss for 500 iteration is : 0.8198886483907699\n",
            "Average Loss for 600 iteration is : 0.8219878315925598\n",
            "Evaluation Accuracy is : 0.6795\n",
            "Average Loss for 100 iteration is : 0.8042562532424927\n",
            "Average Loss for 200 iteration is : 0.840528279542923\n",
            "Average Loss for 300 iteration is : 0.8238185501098633\n",
            "Average Loss for 400 iteration is : 0.8177871692180634\n",
            "Average Loss for 500 iteration is : 0.8167193531990051\n",
            "Average Loss for 600 iteration is : 0.8459848862886429\n",
            "Evaluation Accuracy is : 0.6758\n",
            "Average Loss for 100 iteration is : 0.8302430951595307\n",
            "Average Loss for 200 iteration is : 0.8179444694519042\n",
            "Average Loss for 300 iteration is : 0.8162506765127182\n",
            "Average Loss for 400 iteration is : 0.8039708602428436\n",
            "Average Loss for 500 iteration is : 0.8315312224626541\n",
            "Average Loss for 600 iteration is : 0.7991485637426377\n",
            "Evaluation Accuracy is : 0.6718\n",
            "Average Loss for 100 iteration is : 0.8407615393400192\n",
            "Average Loss for 200 iteration is : 0.8154742997884751\n",
            "Average Loss for 300 iteration is : 0.8147245168685913\n",
            "Average Loss for 400 iteration is : 0.8225239765644073\n",
            "Average Loss for 500 iteration is : 0.8210904601216317\n",
            "Average Loss for 600 iteration is : 0.8172949773073196\n",
            "Evaluation Accuracy is : 0.6764\n",
            "Average Loss for 100 iteration is : 0.8115165328979492\n",
            "Average Loss for 200 iteration is : 0.8445967698097229\n",
            "Average Loss for 300 iteration is : 0.8174442267417907\n",
            "Average Loss for 400 iteration is : 0.8126750087738037\n",
            "Average Loss for 500 iteration is : 0.8185197520256042\n",
            "Average Loss for 600 iteration is : 0.815508576631546\n",
            "Evaluation Accuracy is : 0.6784\n",
            "Average Loss for 100 iteration is : 0.8155596691370011\n",
            "Average Loss for 200 iteration is : 0.8149721217155457\n",
            "Average Loss for 300 iteration is : 0.8159310528635979\n",
            "Average Loss for 400 iteration is : 0.8249959814548492\n",
            "Average Loss for 500 iteration is : 0.8107955145835877\n",
            "Average Loss for 600 iteration is : 0.8120957228541374\n",
            "Evaluation Accuracy is : 0.669\n",
            "Average Loss for 100 iteration is : 0.8267881089448929\n",
            "Average Loss for 200 iteration is : 0.7974367612600326\n",
            "Average Loss for 300 iteration is : 0.8271815270185471\n",
            "Average Loss for 400 iteration is : 0.802546678185463\n",
            "Average Loss for 500 iteration is : 0.8166546350717545\n",
            "Average Loss for 600 iteration is : 0.8308745670318604\n",
            "Evaluation Accuracy is : 0.67\n",
            "Average Loss for 100 iteration is : 0.8118735718727111\n",
            "Average Loss for 200 iteration is : 0.8230101412534714\n",
            "Average Loss for 300 iteration is : 0.829705805182457\n",
            "Average Loss for 400 iteration is : 0.7938640999794007\n",
            "Average Loss for 500 iteration is : 0.8355277806520462\n",
            "Average Loss for 600 iteration is : 0.8275921803712845\n",
            "Evaluation Accuracy is : 0.685\n",
            "Average Loss for 100 iteration is : 0.8098263454437256\n",
            "Average Loss for 200 iteration is : 0.8146537458896637\n",
            "Average Loss for 300 iteration is : 0.8225075072050094\n",
            "Average Loss for 400 iteration is : 0.8179161047935486\n",
            "Average Loss for 500 iteration is : 0.8210182243585586\n",
            "Average Loss for 600 iteration is : 0.8389693886041641\n",
            "Evaluation Accuracy is : 0.6833\n",
            "Average Loss for 100 iteration is : 0.8111070537567139\n",
            "Average Loss for 200 iteration is : 0.79952561378479\n",
            "Average Loss for 300 iteration is : 0.8133262205123901\n",
            "Average Loss for 400 iteration is : 0.8277437660098076\n",
            "Average Loss for 500 iteration is : 0.8108637329936027\n",
            "Average Loss for 600 iteration is : 0.8221619880199432\n",
            "Evaluation Accuracy is : 0.678\n",
            "Average Loss for 100 iteration is : 0.8132501357793808\n",
            "Average Loss for 200 iteration is : 0.814829157590866\n",
            "Average Loss for 300 iteration is : 0.8055769559741021\n",
            "Average Loss for 400 iteration is : 0.8301339250802994\n",
            "Average Loss for 500 iteration is : 0.8375045377016067\n",
            "Average Loss for 600 iteration is : 0.8210133957862854\n",
            "Evaluation Accuracy is : 0.6751\n",
            "Average Loss for 100 iteration is : 0.8247252267599106\n",
            "Average Loss for 200 iteration is : 0.8024080592393875\n",
            "Average Loss for 300 iteration is : 0.8107417106628418\n",
            "Average Loss for 400 iteration is : 0.8307178071141244\n",
            "Average Loss for 500 iteration is : 0.8288846826553344\n",
            "Average Loss for 600 iteration is : 0.7944571322202683\n",
            "Evaluation Accuracy is : 0.6795\n",
            "Average Loss for 100 iteration is : 0.8306821078062058\n",
            "Average Loss for 200 iteration is : 0.8263875657320022\n",
            "Average Loss for 300 iteration is : 0.812348803281784\n",
            "Average Loss for 400 iteration is : 0.79208561450243\n",
            "Average Loss for 500 iteration is : 0.8196230870485306\n",
            "Average Loss for 600 iteration is : 0.8312245869636535\n",
            "Evaluation Accuracy is : 0.6793\n",
            "Average Loss for 100 iteration is : 0.8498048979043961\n",
            "Average Loss for 200 iteration is : 0.822969854772091\n",
            "Average Loss for 300 iteration is : 0.8075323635339737\n",
            "Average Loss for 400 iteration is : 0.8047492134571076\n",
            "Average Loss for 500 iteration is : 0.8111515054106713\n",
            "Average Loss for 600 iteration is : 0.8183027577400207\n",
            "Evaluation Accuracy is : 0.6775\n",
            "Average Loss for 100 iteration is : 0.7828155037760735\n",
            "Average Loss for 200 iteration is : 0.8287952542304993\n",
            "Average Loss for 300 iteration is : 0.8229553180932999\n",
            "Average Loss for 400 iteration is : 0.8158626559376717\n",
            "Average Loss for 500 iteration is : 0.8242466992139816\n",
            "Average Loss for 600 iteration is : 0.8189427322149276\n",
            "Evaluation Accuracy is : 0.689\n",
            "Average Loss for 100 iteration is : 0.7796424031257629\n",
            "Average Loss for 200 iteration is : 0.8159618628025055\n",
            "Average Loss for 300 iteration is : 0.8159431231021881\n",
            "Average Loss for 400 iteration is : 0.8271381860971451\n",
            "Average Loss for 500 iteration is : 0.8317346280813217\n",
            "Average Loss for 600 iteration is : 0.8093305301666259\n",
            "Evaluation Accuracy is : 0.6778\n",
            "Average Loss for 100 iteration is : 0.7955395865440369\n",
            "Average Loss for 200 iteration is : 0.7945532250404358\n",
            "Average Loss for 300 iteration is : 0.8154386270046234\n",
            "Average Loss for 400 iteration is : 0.8183766755461693\n",
            "Average Loss for 500 iteration is : 0.8135751724243164\n",
            "Average Loss for 600 iteration is : 0.8328208366036415\n",
            "Evaluation Accuracy is : 0.6794\n",
            "Average Loss for 100 iteration is : 0.8117880719900131\n",
            "Average Loss for 200 iteration is : 0.8284703105688095\n",
            "Average Loss for 300 iteration is : 0.8041561183333397\n",
            "Average Loss for 400 iteration is : 0.8040503603219986\n",
            "Average Loss for 500 iteration is : 0.8056574994325638\n",
            "Average Loss for 600 iteration is : 0.8272801896929741\n",
            "Evaluation Accuracy is : 0.6857\n",
            "Average Loss for 100 iteration is : 0.8216525512933731\n",
            "Average Loss for 200 iteration is : 0.8087397348880768\n",
            "Average Loss for 300 iteration is : 0.8079293066263199\n",
            "Average Loss for 400 iteration is : 0.8109688854217529\n",
            "Average Loss for 500 iteration is : 0.8239845842123031\n",
            "Average Loss for 600 iteration is : 0.8092754793167114\n",
            "Evaluation Accuracy is : 0.6768\n",
            "Average Loss for 100 iteration is : 0.8239471286535263\n",
            "Average Loss for 200 iteration is : 0.812688359618187\n",
            "Average Loss for 300 iteration is : 0.8124228298664093\n",
            "Average Loss for 400 iteration is : 0.8182888180017471\n",
            "Average Loss for 500 iteration is : 0.795034421980381\n",
            "Average Loss for 600 iteration is : 0.8126463848352432\n",
            "Evaluation Accuracy is : 0.6757\n",
            "Average Loss for 100 iteration is : 0.7915761017799378\n",
            "Average Loss for 200 iteration is : 0.8361843729019165\n",
            "Average Loss for 300 iteration is : 0.8052487242221832\n",
            "Average Loss for 400 iteration is : 0.7977864098548889\n",
            "Average Loss for 500 iteration is : 0.8240707004070282\n",
            "Average Loss for 600 iteration is : 0.8039995670318604\n",
            "Evaluation Accuracy is : 0.6796\n",
            "Average Loss for 100 iteration is : 0.7900541937351226\n",
            "Average Loss for 200 iteration is : 0.8273532438278198\n",
            "Average Loss for 300 iteration is : 0.8070394146442413\n",
            "Average Loss for 400 iteration is : 0.8218070781230926\n",
            "Average Loss for 500 iteration is : 0.8058518928289413\n",
            "Average Loss for 600 iteration is : 0.8141677868366242\n",
            "Evaluation Accuracy is : 0.6806\n",
            "Average Loss for 100 iteration is : 0.8200988194346428\n",
            "Average Loss for 200 iteration is : 0.8231452450156211\n",
            "Average Loss for 300 iteration is : 0.8045116621255874\n",
            "Average Loss for 400 iteration is : 0.8166842252016068\n",
            "Average Loss for 500 iteration is : 0.7866977334022522\n",
            "Average Loss for 600 iteration is : 0.7964889931678772\n",
            "Evaluation Accuracy is : 0.6814\n",
            "Average Loss for 100 iteration is : 0.8091865536570549\n",
            "Average Loss for 200 iteration is : 0.8039847940206528\n",
            "Average Loss for 300 iteration is : 0.8080697321891784\n",
            "Average Loss for 400 iteration is : 0.7808885642886162\n",
            "Average Loss for 500 iteration is : 0.8379753470420838\n",
            "Average Loss for 600 iteration is : 0.8297170501947403\n",
            "Evaluation Accuracy is : 0.6757\n",
            "Average Loss for 100 iteration is : 0.7970711249113083\n",
            "Average Loss for 200 iteration is : 0.814170657992363\n",
            "Average Loss for 300 iteration is : 0.818852322101593\n",
            "Average Loss for 400 iteration is : 0.8059394758939743\n",
            "Average Loss for 500 iteration is : 0.8275978541374207\n",
            "Average Loss for 600 iteration is : 0.7852673476934433\n",
            "Evaluation Accuracy is : 0.6781\n",
            "Average Loss for 100 iteration is : 0.8148876324295997\n",
            "Average Loss for 200 iteration is : 0.8000185704231262\n",
            "Average Loss for 300 iteration is : 0.7956054699420929\n",
            "Average Loss for 400 iteration is : 0.8273203092813491\n",
            "Average Loss for 500 iteration is : 0.8109712964296341\n",
            "Average Loss for 600 iteration is : 0.8206622296571732\n",
            "Evaluation Accuracy is : 0.6823\n",
            "Average Loss for 100 iteration is : 0.7907838237285614\n",
            "Average Loss for 200 iteration is : 0.8082014757394791\n",
            "Average Loss for 300 iteration is : 0.8111075901985169\n",
            "Average Loss for 400 iteration is : 0.8054870635271072\n",
            "Average Loss for 500 iteration is : 0.8315120905637741\n",
            "Average Loss for 600 iteration is : 0.8020320850610733\n",
            "Evaluation Accuracy is : 0.685\n",
            "Average Loss for 100 iteration is : 0.8093778669834137\n",
            "Average Loss for 200 iteration is : 0.8212961930036545\n",
            "Average Loss for 300 iteration is : 0.7820963335037231\n",
            "Average Loss for 400 iteration is : 0.8198487114906311\n",
            "Average Loss for 500 iteration is : 0.8267395567893981\n",
            "Average Loss for 600 iteration is : 0.8123954182863236\n",
            "Evaluation Accuracy is : 0.6744\n",
            "Average Loss for 100 iteration is : 0.8110753923654557\n",
            "Average Loss for 200 iteration is : 0.8127766793966293\n",
            "Average Loss for 300 iteration is : 0.7776680669188499\n",
            "Average Loss for 400 iteration is : 0.825729900598526\n",
            "Average Loss for 500 iteration is : 0.8131027656793595\n",
            "Average Loss for 600 iteration is : 0.8100107324123382\n",
            "Evaluation Accuracy is : 0.6727\n",
            "Average Loss for 100 iteration is : 0.806457349061966\n",
            "Average Loss for 200 iteration is : 0.8128594881296158\n",
            "Average Loss for 300 iteration is : 0.8203445005416871\n",
            "Average Loss for 400 iteration is : 0.82327621281147\n",
            "Average Loss for 500 iteration is : 0.789425650537014\n",
            "Average Loss for 600 iteration is : 0.7989208036661148\n",
            "Evaluation Accuracy is : 0.6822\n",
            "Average Loss for 100 iteration is : 0.8313395655155182\n",
            "Average Loss for 200 iteration is : 0.7910273697972298\n",
            "Average Loss for 300 iteration is : 0.8076362711191177\n",
            "Average Loss for 400 iteration is : 0.8033978563547134\n",
            "Average Loss for 500 iteration is : 0.7888778451085091\n",
            "Average Loss for 600 iteration is : 0.8140724635124207\n",
            "Evaluation Accuracy is : 0.6834\n",
            "Average Loss for 100 iteration is : 0.8255626624822616\n",
            "Average Loss for 200 iteration is : 0.7999733528494835\n",
            "Average Loss for 300 iteration is : 0.8015536218881607\n",
            "Average Loss for 400 iteration is : 0.8225995209813118\n",
            "Average Loss for 500 iteration is : 0.7891209125518799\n",
            "Average Loss for 600 iteration is : 0.834650456905365\n",
            "Evaluation Accuracy is : 0.6801\n",
            "Average Loss for 100 iteration is : 0.7896097475290298\n",
            "Average Loss for 200 iteration is : 0.797695337831974\n",
            "Average Loss for 300 iteration is : 0.793803589940071\n",
            "Average Loss for 400 iteration is : 0.8141769939661025\n",
            "Average Loss for 500 iteration is : 0.8081038922071457\n",
            "Average Loss for 600 iteration is : 0.7895560920238495\n",
            "Evaluation Accuracy is : 0.6784\n",
            "Average Loss for 100 iteration is : 0.7918868938088417\n",
            "Average Loss for 200 iteration is : 0.8133141106367111\n",
            "Average Loss for 300 iteration is : 0.780536316037178\n",
            "Average Loss for 400 iteration is : 0.8283860582113266\n",
            "Average Loss for 500 iteration is : 0.8133729022741317\n",
            "Average Loss for 600 iteration is : 0.8012417331337929\n",
            "Evaluation Accuracy is : 0.6802\n",
            "Average Loss for 100 iteration is : 0.7974627673625946\n",
            "Average Loss for 200 iteration is : 0.81322270154953\n",
            "Average Loss for 300 iteration is : 0.7874464899301529\n",
            "Average Loss for 400 iteration is : 0.8175237172842026\n",
            "Average Loss for 500 iteration is : 0.7892485874891281\n",
            "Average Loss for 600 iteration is : 0.7975910639762879\n",
            "Evaluation Accuracy is : 0.6847\n",
            "Average Loss for 100 iteration is : 0.8135238546133041\n",
            "Average Loss for 200 iteration is : 0.8072884425520896\n",
            "Average Loss for 300 iteration is : 0.8188665419816971\n",
            "Average Loss for 400 iteration is : 0.8125284820795059\n",
            "Average Loss for 500 iteration is : 0.7903715309500694\n",
            "Average Loss for 600 iteration is : 0.802479197382927\n",
            "Evaluation Accuracy is : 0.6756\n",
            "Average Loss for 100 iteration is : 0.8008137536048889\n",
            "Average Loss for 200 iteration is : 0.7978612285852432\n",
            "Average Loss for 300 iteration is : 0.7976381725072861\n",
            "Average Loss for 400 iteration is : 0.8208183574676514\n",
            "Average Loss for 500 iteration is : 0.8031450605392456\n",
            "Average Loss for 600 iteration is : 0.7968221825361251\n",
            "Evaluation Accuracy is : 0.6883\n",
            "Average Loss for 100 iteration is : 0.8341645348072052\n",
            "Average Loss for 200 iteration is : 0.8053091442584992\n",
            "Average Loss for 300 iteration is : 0.8075594168901443\n",
            "Average Loss for 400 iteration is : 0.8066186052560806\n",
            "Average Loss for 500 iteration is : 0.7874243780970573\n",
            "Average Loss for 600 iteration is : 0.7871855014562607\n",
            "Evaluation Accuracy is : 0.6817\n",
            "Average Loss for 100 iteration is : 0.8014571982622146\n",
            "Average Loss for 200 iteration is : 0.7860621762275696\n",
            "Average Loss for 300 iteration is : 0.8180701380968094\n",
            "Average Loss for 400 iteration is : 0.786854707300663\n",
            "Average Loss for 500 iteration is : 0.8305429184436798\n",
            "Average Loss for 600 iteration is : 0.7982189577817916\n",
            "Evaluation Accuracy is : 0.6855\n",
            "Average Loss for 100 iteration is : 0.7875427353382111\n",
            "Average Loss for 200 iteration is : 0.8186795312166214\n",
            "Average Loss for 300 iteration is : 0.7962186115980149\n",
            "Average Loss for 400 iteration is : 0.804870707988739\n",
            "Average Loss for 500 iteration is : 0.7910729950666427\n",
            "Average Loss for 600 iteration is : 0.824967902302742\n",
            "Evaluation Accuracy is : 0.6816\n",
            "Average Loss for 100 iteration is : 0.7683646029233933\n",
            "Average Loss for 200 iteration is : 0.7987415343523026\n",
            "Average Loss for 300 iteration is : 0.8218643569946289\n",
            "Average Loss for 400 iteration is : 0.799453934431076\n",
            "Average Loss for 500 iteration is : 0.7941686302423477\n",
            "Average Loss for 600 iteration is : 0.8174444100260735\n",
            "Evaluation Accuracy is : 0.6778\n",
            "Average Loss for 100 iteration is : 0.817928030192852\n",
            "Average Loss for 200 iteration is : 0.8052890962362289\n",
            "Average Loss for 300 iteration is : 0.7951070886850357\n",
            "Average Loss for 400 iteration is : 0.79559739112854\n",
            "Average Loss for 500 iteration is : 0.802678011059761\n",
            "Average Loss for 600 iteration is : 0.8037285333871842\n",
            "Evaluation Accuracy is : 0.6902\n",
            "Average Loss for 100 iteration is : 0.7937026026844979\n",
            "Average Loss for 200 iteration is : 0.8032928514480591\n",
            "Average Loss for 300 iteration is : 0.8094295316934585\n",
            "Average Loss for 400 iteration is : 0.7865919342637062\n",
            "Average Loss for 500 iteration is : 0.808931936621666\n",
            "Average Loss for 600 iteration is : 0.7831885185837746\n",
            "Evaluation Accuracy is : 0.6837\n",
            "Average Loss for 100 iteration is : 0.8026600897312164\n",
            "Average Loss for 200 iteration is : 0.8205395156145096\n",
            "Average Loss for 300 iteration is : 0.7677307394146919\n",
            "Average Loss for 400 iteration is : 0.8144044363498688\n",
            "Average Loss for 500 iteration is : 0.8087471067905426\n",
            "Average Loss for 600 iteration is : 0.794122905433178\n",
            "Evaluation Accuracy is : 0.6858\n",
            "Average Loss for 100 iteration is : 0.8105557078123092\n",
            "Average Loss for 200 iteration is : 0.7876118636131286\n",
            "Average Loss for 300 iteration is : 0.8197969359159469\n",
            "Average Loss for 400 iteration is : 0.8043960309028626\n",
            "Average Loss for 500 iteration is : 0.784050022661686\n",
            "Average Loss for 600 iteration is : 0.7929103752970695\n",
            "Evaluation Accuracy is : 0.6837\n",
            "Average Loss for 100 iteration is : 0.7882134634256363\n",
            "Average Loss for 200 iteration is : 0.7974086689949036\n",
            "Average Loss for 300 iteration is : 0.8057663530111313\n",
            "Average Loss for 400 iteration is : 0.8069847378134728\n",
            "Average Loss for 500 iteration is : 0.7986672353744507\n",
            "Average Loss for 600 iteration is : 0.8018362092971801\n",
            "Evaluation Accuracy is : 0.6779\n",
            "Average Loss for 100 iteration is : 0.8003908401727676\n",
            "Average Loss for 200 iteration is : 0.8382670521736145\n",
            "Average Loss for 300 iteration is : 0.7924703729152679\n",
            "Average Loss for 400 iteration is : 0.8171274223923684\n",
            "Average Loss for 500 iteration is : 0.8081174963712692\n",
            "Average Loss for 600 iteration is : 0.7781553420424462\n",
            "Evaluation Accuracy is : 0.6805\n",
            "Average Loss for 100 iteration is : 0.8167202761769294\n",
            "Average Loss for 200 iteration is : 0.7950534147024154\n",
            "Average Loss for 300 iteration is : 0.7823681521415711\n",
            "Average Loss for 400 iteration is : 0.8022705298662186\n",
            "Average Loss for 500 iteration is : 0.8025243371725083\n",
            "Average Loss for 600 iteration is : 0.8161554676294327\n",
            "Evaluation Accuracy is : 0.6822\n",
            "Average Loss for 100 iteration is : 0.8079874679446221\n",
            "Average Loss for 200 iteration is : 0.7832050094008446\n",
            "Average Loss for 300 iteration is : 0.8035924410820008\n",
            "Average Loss for 400 iteration is : 0.7749147003889084\n",
            "Average Loss for 500 iteration is : 0.8029502022266388\n",
            "Average Loss for 600 iteration is : 0.7975117200613022\n",
            "Evaluation Accuracy is : 0.6839\n",
            "Average Loss for 100 iteration is : 0.8052710887789726\n",
            "Average Loss for 200 iteration is : 0.801635639667511\n",
            "Average Loss for 300 iteration is : 0.8112139570713043\n",
            "Average Loss for 400 iteration is : 0.7902986460924148\n",
            "Average Loss for 500 iteration is : 0.8034100049734115\n",
            "Average Loss for 600 iteration is : 0.8149233162403107\n",
            "Evaluation Accuracy is : 0.6818\n",
            "Average Loss for 100 iteration is : 0.8013479316234589\n",
            "Average Loss for 200 iteration is : 0.7819994640350342\n",
            "Average Loss for 300 iteration is : 0.7901168632507324\n",
            "Average Loss for 400 iteration is : 0.7995758786797523\n",
            "Average Loss for 500 iteration is : 0.8035081887245178\n",
            "Average Loss for 600 iteration is : 0.8076673129200935\n",
            "Evaluation Accuracy is : 0.6892\n",
            "Average Loss for 100 iteration is : 0.791120673418045\n",
            "Average Loss for 200 iteration is : 0.7995123463869095\n",
            "Average Loss for 300 iteration is : 0.797651554942131\n",
            "Average Loss for 400 iteration is : 0.7931282782554626\n",
            "Average Loss for 500 iteration is : 0.8229522114992142\n",
            "Average Loss for 600 iteration is : 0.7861709040403366\n",
            "Evaluation Accuracy is : 0.6858\n",
            "Average Loss for 100 iteration is : 0.7990296840667724\n",
            "Average Loss for 200 iteration is : 0.7889193162322045\n",
            "Average Loss for 300 iteration is : 0.8135610431432724\n",
            "Average Loss for 400 iteration is : 0.8080304771661758\n",
            "Average Loss for 500 iteration is : 0.804780792593956\n",
            "Average Loss for 600 iteration is : 0.8088845270872116\n",
            "Evaluation Accuracy is : 0.6907\n",
            "Average Loss for 100 iteration is : 0.772283644080162\n",
            "Average Loss for 200 iteration is : 0.8104788267612457\n",
            "Average Loss for 300 iteration is : 0.8078456753492356\n",
            "Average Loss for 400 iteration is : 0.8053763729333877\n",
            "Average Loss for 500 iteration is : 0.8036159986257553\n",
            "Average Loss for 600 iteration is : 0.7993190628290177\n",
            "Evaluation Accuracy is : 0.6815\n",
            "Average Loss for 100 iteration is : 0.7907102704048157\n",
            "Average Loss for 200 iteration is : 0.78301299482584\n",
            "Average Loss for 300 iteration is : 0.7935155564546585\n",
            "Average Loss for 400 iteration is : 0.8078339740633964\n",
            "Average Loss for 500 iteration is : 0.8100105291604995\n",
            "Average Loss for 600 iteration is : 0.8011387187242508\n",
            "Evaluation Accuracy is : 0.6862\n",
            "Average Loss for 100 iteration is : 0.785645614862442\n",
            "Average Loss for 200 iteration is : 0.783483418226242\n",
            "Average Loss for 300 iteration is : 0.794239049255848\n",
            "Average Loss for 400 iteration is : 0.7705531573295593\n",
            "Average Loss for 500 iteration is : 0.8133069181442261\n",
            "Average Loss for 600 iteration is : 0.8121275651454926\n",
            "Evaluation Accuracy is : 0.6855\n",
            "Average Loss for 100 iteration is : 0.8020086234807968\n",
            "Average Loss for 200 iteration is : 0.7919905132055283\n",
            "Average Loss for 300 iteration is : 0.7894150882959365\n",
            "Average Loss for 400 iteration is : 0.7957471287250519\n",
            "Average Loss for 500 iteration is : 0.8166517478227615\n",
            "Average Loss for 600 iteration is : 0.785825836956501\n",
            "Evaluation Accuracy is : 0.6761\n",
            "Average Loss for 100 iteration is : 0.7925622671842575\n",
            "Average Loss for 200 iteration is : 0.7886816155910492\n",
            "Average Loss for 300 iteration is : 0.7851290982961655\n",
            "Average Loss for 400 iteration is : 0.8134046271443367\n",
            "Average Loss for 500 iteration is : 0.8025864526629448\n",
            "Average Loss for 600 iteration is : 0.7880278700590133\n",
            "Evaluation Accuracy is : 0.6794\n",
            "Average Loss for 100 iteration is : 0.8034675788879394\n",
            "Average Loss for 200 iteration is : 0.7751704329252243\n",
            "Average Loss for 300 iteration is : 0.8026023149490357\n",
            "Average Loss for 400 iteration is : 0.7782875835895539\n",
            "Average Loss for 500 iteration is : 0.7884139329195022\n",
            "Average Loss for 600 iteration is : 0.7982675153017044\n",
            "Evaluation Accuracy is : 0.6838\n",
            "Average Loss for 100 iteration is : 0.8056385618448257\n",
            "Average Loss for 200 iteration is : 0.8067277759313584\n",
            "Average Loss for 300 iteration is : 0.7877413982152939\n",
            "Average Loss for 400 iteration is : 0.7998178416490554\n",
            "Average Loss for 500 iteration is : 0.7860153397917747\n",
            "Average Loss for 600 iteration is : 0.7888005730509758\n",
            "Evaluation Accuracy is : 0.6801\n",
            "Average Loss for 100 iteration is : 0.788253935277462\n",
            "Average Loss for 200 iteration is : 0.8045795047283173\n",
            "Average Loss for 300 iteration is : 0.7747842681407928\n",
            "Average Loss for 400 iteration is : 0.7982259666919709\n",
            "Average Loss for 500 iteration is : 0.7965623188018799\n",
            "Average Loss for 600 iteration is : 0.818991619348526\n",
            "Evaluation Accuracy is : 0.6872\n",
            "Average Loss for 100 iteration is : 0.7885715243220329\n",
            "Average Loss for 200 iteration is : 0.778897819519043\n",
            "Average Loss for 300 iteration is : 0.7844642227888108\n",
            "Average Loss for 400 iteration is : 0.8082730269432068\n",
            "Average Loss for 500 iteration is : 0.8162691655755043\n",
            "Average Loss for 600 iteration is : 0.8113036158680916\n",
            "Evaluation Accuracy is : 0.676\n",
            "Average Loss for 100 iteration is : 0.8002123093605041\n",
            "Average Loss for 200 iteration is : 0.7769947868585586\n",
            "Average Loss for 300 iteration is : 0.7952108255028725\n",
            "Average Loss for 400 iteration is : 0.7659036457538605\n",
            "Average Loss for 500 iteration is : 0.8090978556871414\n",
            "Average Loss for 600 iteration is : 0.7967909467220307\n",
            "Evaluation Accuracy is : 0.6846\n",
            "Average Loss for 100 iteration is : 0.8078710237145423\n",
            "Average Loss for 200 iteration is : 0.7886319568753243\n",
            "Average Loss for 300 iteration is : 0.7743723338842392\n",
            "Average Loss for 400 iteration is : 0.809544238448143\n",
            "Average Loss for 500 iteration is : 0.8026311856508255\n",
            "Average Loss for 600 iteration is : 0.7856792336702347\n",
            "Evaluation Accuracy is : 0.6848\n",
            "Average Loss for 100 iteration is : 0.7846984499692917\n",
            "Average Loss for 200 iteration is : 0.7929241859912872\n",
            "Average Loss for 300 iteration is : 0.8086499601602555\n",
            "Average Loss for 400 iteration is : 0.7797505429387093\n",
            "Average Loss for 500 iteration is : 0.8156331840157509\n",
            "Average Loss for 600 iteration is : 0.797559934258461\n",
            "Evaluation Accuracy is : 0.6827\n",
            "Average Loss for 100 iteration is : 0.7787357497215271\n",
            "Average Loss for 200 iteration is : 0.798007164299488\n",
            "Average Loss for 300 iteration is : 0.7963164454698562\n",
            "Average Loss for 400 iteration is : 0.7909211748838425\n",
            "Average Loss for 500 iteration is : 0.8007489877939225\n",
            "Average Loss for 600 iteration is : 0.7846663877367973\n",
            "Evaluation Accuracy is : 0.6855\n",
            "Average Loss for 100 iteration is : 0.7853302448987961\n",
            "Average Loss for 200 iteration is : 0.8099220359325409\n",
            "Average Loss for 300 iteration is : 0.7981331902742386\n",
            "Average Loss for 400 iteration is : 0.7956333261728287\n",
            "Average Loss for 500 iteration is : 0.7911244922876358\n",
            "Average Loss for 600 iteration is : 0.8007353860139846\n",
            "Evaluation Accuracy is : 0.6894\n",
            "Average Loss for 100 iteration is : 0.7712166738510132\n",
            "Average Loss for 200 iteration is : 0.7641079419851303\n",
            "Average Loss for 300 iteration is : 0.8083347046375274\n",
            "Average Loss for 400 iteration is : 0.7925634095072747\n",
            "Average Loss for 500 iteration is : 0.8185964858531952\n",
            "Average Loss for 600 iteration is : 0.8006641292572021\n",
            "Evaluation Accuracy is : 0.6836\n",
            "Average Loss for 100 iteration is : 0.7846847796440124\n",
            "Average Loss for 200 iteration is : 0.7780020278692246\n",
            "Average Loss for 300 iteration is : 0.7998797610402107\n",
            "Average Loss for 400 iteration is : 0.7892930006980896\n",
            "Average Loss for 500 iteration is : 0.7937956893444061\n",
            "Average Loss for 600 iteration is : 0.7894324579834938\n",
            "Evaluation Accuracy is : 0.6886\n",
            "Average Loss for 100 iteration is : 0.7897930762171745\n",
            "Average Loss for 200 iteration is : 0.7806838199496269\n",
            "Average Loss for 300 iteration is : 0.7977635276317596\n",
            "Average Loss for 400 iteration is : 0.8003781640529632\n",
            "Average Loss for 500 iteration is : 0.7933936715126038\n",
            "Average Loss for 600 iteration is : 0.7925745284557343\n",
            "Evaluation Accuracy is : 0.6849\n",
            "Average Loss for 100 iteration is : 0.7707528042793274\n",
            "Average Loss for 200 iteration is : 0.8020800894498825\n",
            "Average Loss for 300 iteration is : 0.8007236969470978\n",
            "Average Loss for 400 iteration is : 0.7978708270192146\n",
            "Average Loss for 500 iteration is : 0.7899736830592156\n",
            "Average Loss for 600 iteration is : 0.7853264993429184\n",
            "Evaluation Accuracy is : 0.6938\n",
            "Average Loss for 100 iteration is : 0.7640541276335716\n",
            "Average Loss for 200 iteration is : 0.7956526398658752\n",
            "Average Loss for 300 iteration is : 0.7789869463443756\n",
            "Average Loss for 400 iteration is : 0.7719098979234695\n",
            "Average Loss for 500 iteration is : 0.7940028184652328\n",
            "Average Loss for 600 iteration is : 0.7813373196125031\n",
            "Evaluation Accuracy is : 0.6844\n",
            "Average Loss for 100 iteration is : 0.8032527041435241\n",
            "Average Loss for 200 iteration is : 0.7906214126944542\n",
            "Average Loss for 300 iteration is : 0.7829134553670883\n",
            "Average Loss for 400 iteration is : 0.7972663727402687\n",
            "Average Loss for 500 iteration is : 0.7970243185758591\n",
            "Average Loss for 600 iteration is : 0.7856080621480942\n",
            "Evaluation Accuracy is : 0.6877\n",
            "Average Loss for 100 iteration is : 0.7824807345867157\n",
            "Average Loss for 200 iteration is : 0.7570361748337746\n",
            "Average Loss for 300 iteration is : 0.7806903398036957\n",
            "Average Loss for 400 iteration is : 0.7732659366726875\n",
            "Average Loss for 500 iteration is : 0.8237847703695297\n",
            "Average Loss for 600 iteration is : 0.7908076816797256\n",
            "Evaluation Accuracy is : 0.6808\n",
            "Average Loss for 100 iteration is : 0.7876270219683648\n",
            "Average Loss for 200 iteration is : 0.782753172814846\n",
            "Average Loss for 300 iteration is : 0.7689113849401474\n",
            "Average Loss for 400 iteration is : 0.8071333116292954\n",
            "Average Loss for 500 iteration is : 0.8031107044219971\n",
            "Average Loss for 600 iteration is : 0.7867677503824234\n",
            "Evaluation Accuracy is : 0.6811\n",
            "Average Loss for 100 iteration is : 0.7823724788427353\n",
            "Average Loss for 200 iteration is : 0.7974827033281326\n",
            "Average Loss for 300 iteration is : 0.7852364706993104\n",
            "Average Loss for 400 iteration is : 0.7964152672886848\n",
            "Average Loss for 500 iteration is : 0.7699656558036804\n",
            "Average Loss for 600 iteration is : 0.7903638732433319\n",
            "Evaluation Accuracy is : 0.6881\n",
            "Average Loss for 100 iteration is : 0.7870547926425934\n",
            "Average Loss for 200 iteration is : 0.7842506289482116\n",
            "Average Loss for 300 iteration is : 0.7905788618326187\n",
            "Average Loss for 400 iteration is : 0.7693816936016082\n",
            "Average Loss for 500 iteration is : 0.7940474432706833\n",
            "Average Loss for 600 iteration is : 0.7983512628078461\n",
            "Evaluation Accuracy is : 0.6898\n",
            "Average Loss for 100 iteration is : 0.7710783863067627\n",
            "Average Loss for 200 iteration is : 0.7764680141210556\n",
            "Average Loss for 300 iteration is : 0.7843478548526764\n",
            "Average Loss for 400 iteration is : 0.8119095027446747\n",
            "Average Loss for 500 iteration is : 0.8004044955968856\n",
            "Average Loss for 600 iteration is : 0.780527885556221\n",
            "Evaluation Accuracy is : 0.6866\n",
            "Average Loss for 100 iteration is : 0.8035675764083863\n",
            "Average Loss for 200 iteration is : 0.7850054237246513\n",
            "Average Loss for 300 iteration is : 0.7992850226163865\n",
            "Average Loss for 400 iteration is : 0.7772753441333771\n",
            "Average Loss for 500 iteration is : 0.7825443381071091\n",
            "Average Loss for 600 iteration is : 0.7954368740320206\n",
            "Evaluation Accuracy is : 0.684\n",
            "Average Loss for 100 iteration is : 0.7885066789388656\n",
            "Average Loss for 200 iteration is : 0.7912788152694702\n",
            "Average Loss for 300 iteration is : 0.8024208012223244\n",
            "Average Loss for 400 iteration is : 0.7643897610902787\n",
            "Average Loss for 500 iteration is : 0.8038747787475586\n",
            "Average Loss for 600 iteration is : 0.7797711151838302\n",
            "Evaluation Accuracy is : 0.6825\n",
            "Average Loss for 100 iteration is : 0.7869782382249833\n",
            "Average Loss for 200 iteration is : 0.7794951558113098\n",
            "Average Loss for 300 iteration is : 0.781889243721962\n",
            "Average Loss for 400 iteration is : 0.7876248320937157\n",
            "Average Loss for 500 iteration is : 0.7835878527164459\n",
            "Average Loss for 600 iteration is : 0.780964145064354\n",
            "Evaluation Accuracy is : 0.6822\n",
            "Average Loss for 100 iteration is : 0.7787523928284645\n",
            "Average Loss for 200 iteration is : 0.7659466740489006\n",
            "Average Loss for 300 iteration is : 0.8064430195093155\n",
            "Average Loss for 400 iteration is : 0.7882245349884033\n",
            "Average Loss for 500 iteration is : 0.7814725279808045\n",
            "Average Loss for 600 iteration is : 0.8074712058901787\n",
            "Evaluation Accuracy is : 0.6921\n",
            "Average Loss for 100 iteration is : 0.7912517684698105\n",
            "Average Loss for 200 iteration is : 0.7818274247646332\n",
            "Average Loss for 300 iteration is : 0.7809835439920425\n",
            "Average Loss for 400 iteration is : 0.7929997202754021\n",
            "Average Loss for 500 iteration is : 0.7896547889709473\n",
            "Average Loss for 600 iteration is : 0.7880780771374702\n",
            "Evaluation Accuracy is : 0.6838\n",
            "Average Loss for 100 iteration is : 0.7942100247740745\n",
            "Average Loss for 200 iteration is : 0.7597117680311203\n",
            "Average Loss for 300 iteration is : 0.7893576472997665\n",
            "Average Loss for 400 iteration is : 0.766254167854786\n",
            "Average Loss for 500 iteration is : 0.80045181453228\n",
            "Average Loss for 600 iteration is : 0.7758934849500656\n",
            "Evaluation Accuracy is : 0.697\n",
            "Average Loss for 100 iteration is : 0.7919081845879554\n",
            "Average Loss for 200 iteration is : 0.7799734264612198\n",
            "Average Loss for 300 iteration is : 0.761763436794281\n",
            "Average Loss for 400 iteration is : 0.7477200815081596\n",
            "Average Loss for 500 iteration is : 0.7971131485700608\n",
            "Average Loss for 600 iteration is : 0.797762348651886\n",
            "Evaluation Accuracy is : 0.6852\n",
            "Average Loss for 100 iteration is : 0.7908591479063034\n",
            "Average Loss for 200 iteration is : 0.788755521774292\n",
            "Average Loss for 300 iteration is : 0.7823347854614258\n",
            "Average Loss for 400 iteration is : 0.7687632083892822\n",
            "Average Loss for 500 iteration is : 0.7786369201540947\n",
            "Average Loss for 600 iteration is : 0.7812693226337433\n",
            "Evaluation Accuracy is : 0.6836\n",
            "Average Loss for 100 iteration is : 0.7906119674444199\n",
            "Average Loss for 200 iteration is : 0.7509495878219604\n",
            "Average Loss for 300 iteration is : 0.7510287153720856\n",
            "Average Loss for 400 iteration is : 0.7911966717243195\n",
            "Average Loss for 500 iteration is : 0.7796560826897622\n",
            "Average Loss for 600 iteration is : 0.8019281274080277\n",
            "Evaluation Accuracy is : 0.6918\n",
            "Average Loss for 100 iteration is : 0.7712790450453758\n",
            "Average Loss for 200 iteration is : 0.7888565409183502\n",
            "Average Loss for 300 iteration is : 0.7640778189897537\n",
            "Average Loss for 400 iteration is : 0.792268899679184\n",
            "Average Loss for 500 iteration is : 0.818663495182991\n",
            "Average Loss for 600 iteration is : 0.7866781276464462\n",
            "Evaluation Accuracy is : 0.6836\n",
            "Average Loss for 100 iteration is : 0.7687539917230606\n",
            "Average Loss for 200 iteration is : 0.782192320227623\n",
            "Average Loss for 300 iteration is : 0.7867589491605759\n",
            "Average Loss for 400 iteration is : 0.791102665066719\n",
            "Average Loss for 500 iteration is : 0.8134249502420425\n",
            "Average Loss for 600 iteration is : 0.8008948796987534\n",
            "Evaluation Accuracy is : 0.6892\n",
            "Average Loss for 100 iteration is : 0.7959340950846672\n",
            "Average Loss for 200 iteration is : 0.7711598581075668\n",
            "Average Loss for 300 iteration is : 0.7873719531297684\n",
            "Average Loss for 400 iteration is : 0.7802141106128693\n",
            "Average Loss for 500 iteration is : 0.7830503860116005\n",
            "Average Loss for 600 iteration is : 0.7861498114466667\n",
            "Evaluation Accuracy is : 0.682\n",
            "Average Loss for 100 iteration is : 0.755987339913845\n",
            "Average Loss for 200 iteration is : 0.7690941160917282\n",
            "Average Loss for 300 iteration is : 0.7938891315460205\n",
            "Average Loss for 400 iteration is : 0.7946903121471405\n",
            "Average Loss for 500 iteration is : 0.778454794883728\n",
            "Average Loss for 600 iteration is : 0.7631007876992225\n",
            "Evaluation Accuracy is : 0.686\n",
            "Average Loss for 100 iteration is : 0.7676412016153336\n",
            "Average Loss for 200 iteration is : 0.7945997431874275\n",
            "Average Loss for 300 iteration is : 0.7892545381188393\n",
            "Average Loss for 400 iteration is : 0.7974395960569381\n",
            "Average Loss for 500 iteration is : 0.75674306422472\n",
            "Average Loss for 600 iteration is : 0.772942741215229\n",
            "Evaluation Accuracy is : 0.6955\n",
            "Average Loss for 100 iteration is : 0.7730669155716896\n",
            "Average Loss for 200 iteration is : 0.7675751248002052\n",
            "Average Loss for 300 iteration is : 0.7725800058245659\n",
            "Average Loss for 400 iteration is : 0.8065548244118691\n",
            "Average Loss for 500 iteration is : 0.7783639690279961\n",
            "Average Loss for 600 iteration is : 0.7891023382544518\n",
            "Evaluation Accuracy is : 0.6884\n",
            "Average Loss for 100 iteration is : 0.773240156173706\n",
            "Average Loss for 200 iteration is : 0.772894271016121\n",
            "Average Loss for 300 iteration is : 0.7774918138980865\n",
            "Average Loss for 400 iteration is : 0.7837498724460602\n",
            "Average Loss for 500 iteration is : 0.7749380281567574\n",
            "Average Loss for 600 iteration is : 0.7802646166086197\n",
            "Evaluation Accuracy is : 0.6876\n",
            "Average Loss for 100 iteration is : 0.7730019152164459\n",
            "Average Loss for 200 iteration is : 0.7808567526936531\n",
            "Average Loss for 300 iteration is : 0.7903068041801453\n",
            "Average Loss for 400 iteration is : 0.7769461408257484\n",
            "Average Loss for 500 iteration is : 0.7673312973976135\n",
            "Average Loss for 600 iteration is : 0.7811665144562722\n",
            "Evaluation Accuracy is : 0.6807\n",
            "Average Loss for 100 iteration is : 0.786176648736\n",
            "Average Loss for 200 iteration is : 0.7581020432710648\n",
            "Average Loss for 300 iteration is : 0.7861934950947762\n",
            "Average Loss for 400 iteration is : 0.7849705934524536\n",
            "Average Loss for 500 iteration is : 0.7924165090918541\n",
            "Average Loss for 600 iteration is : 0.7831231504678726\n",
            "Evaluation Accuracy is : 0.6915\n",
            "Average Loss for 100 iteration is : 0.7876692020893097\n",
            "Average Loss for 200 iteration is : 0.7939441341161728\n",
            "Average Loss for 300 iteration is : 0.7637858107686043\n",
            "Average Loss for 400 iteration is : 0.7862504339218139\n",
            "Average Loss for 500 iteration is : 0.7815422183275222\n",
            "Average Loss for 600 iteration is : 0.7566823479533196\n",
            "Evaluation Accuracy is : 0.6877\n",
            "Average Loss for 100 iteration is : 0.7414429557323455\n",
            "Average Loss for 200 iteration is : 0.7727852684259414\n",
            "Average Loss for 300 iteration is : 0.7661269718408584\n",
            "Average Loss for 400 iteration is : 0.7866276097297669\n",
            "Average Loss for 500 iteration is : 0.7777650898694992\n",
            "Average Loss for 600 iteration is : 0.7860997331142425\n",
            "Evaluation Accuracy is : 0.6851\n",
            "Average Loss for 100 iteration is : 0.778756445646286\n",
            "Average Loss for 200 iteration is : 0.7963122913241386\n",
            "Average Loss for 300 iteration is : 0.7729586443305015\n",
            "Average Loss for 400 iteration is : 0.7717559948563576\n",
            "Average Loss for 500 iteration is : 0.8085430777072906\n",
            "Average Loss for 600 iteration is : 0.7695242419838906\n",
            "Evaluation Accuracy is : 0.6873\n",
            "Average Loss for 100 iteration is : 0.7821702107787132\n",
            "Average Loss for 200 iteration is : 0.800258032977581\n",
            "Average Loss for 300 iteration is : 0.7984631687402726\n",
            "Average Loss for 400 iteration is : 0.7518889844417572\n",
            "Average Loss for 500 iteration is : 0.7852707582712174\n",
            "Average Loss for 600 iteration is : 0.7678131639957428\n",
            "Evaluation Accuracy is : 0.685\n",
            "Average Loss for 100 iteration is : 0.7933932602405548\n",
            "Average Loss for 200 iteration is : 0.7582412612438202\n",
            "Average Loss for 300 iteration is : 0.7747883301973343\n",
            "Average Loss for 400 iteration is : 0.8062077629566192\n",
            "Average Loss for 500 iteration is : 0.7877304166555404\n",
            "Average Loss for 600 iteration is : 0.7684824639558792\n",
            "Evaluation Accuracy is : 0.6887\n",
            "Average Loss for 100 iteration is : 0.7662395751476287\n",
            "Average Loss for 200 iteration is : 0.7769637060165405\n",
            "Average Loss for 300 iteration is : 0.7767057943344117\n",
            "Average Loss for 400 iteration is : 0.7895518004894256\n",
            "Average Loss for 500 iteration is : 0.7966154891252518\n",
            "Average Loss for 600 iteration is : 0.7921849226951599\n",
            "Evaluation Accuracy is : 0.6908\n",
            "Average Loss for 100 iteration is : 0.7641033664345741\n",
            "Average Loss for 200 iteration is : 0.8027845135331154\n",
            "Average Loss for 300 iteration is : 0.7715438568592071\n",
            "Average Loss for 400 iteration is : 0.7806790208816529\n",
            "Average Loss for 500 iteration is : 0.7675851100683212\n",
            "Average Loss for 600 iteration is : 0.7357132548093795\n",
            "Evaluation Accuracy is : 0.6873\n",
            "Average Loss for 100 iteration is : 0.7832408353686333\n",
            "Average Loss for 200 iteration is : 0.76165889441967\n",
            "Average Loss for 300 iteration is : 0.7738557875156402\n",
            "Average Loss for 400 iteration is : 0.7597005471587182\n",
            "Average Loss for 500 iteration is : 0.7587488007545471\n",
            "Average Loss for 600 iteration is : 0.7812434875965119\n",
            "Evaluation Accuracy is : 0.6876\n",
            "Average Loss for 100 iteration is : 0.7695800343155861\n",
            "Average Loss for 200 iteration is : 0.7957101964950561\n",
            "Average Loss for 300 iteration is : 0.7683379298448563\n",
            "Average Loss for 400 iteration is : 0.7654065215587615\n",
            "Average Loss for 500 iteration is : 0.7880515146255493\n",
            "Average Loss for 600 iteration is : 0.7748140498995781\n",
            "Evaluation Accuracy is : 0.6956\n",
            "Average Loss for 100 iteration is : 0.7600466650724411\n",
            "Average Loss for 200 iteration is : 0.7562290835380554\n",
            "Average Loss for 300 iteration is : 0.7865273571014404\n",
            "Average Loss for 400 iteration is : 0.7697684559226036\n",
            "Average Loss for 500 iteration is : 0.7890858778357506\n",
            "Average Loss for 600 iteration is : 0.7842493027448654\n",
            "Evaluation Accuracy is : 0.6905\n",
            "Average Loss for 100 iteration is : 0.7776071995496749\n",
            "Average Loss for 200 iteration is : 0.7747521623969078\n",
            "Average Loss for 300 iteration is : 0.7614334237575531\n",
            "Average Loss for 400 iteration is : 0.7696889871358872\n",
            "Average Loss for 500 iteration is : 0.7702545034885406\n",
            "Average Loss for 600 iteration is : 0.8063147789239884\n",
            "Evaluation Accuracy is : 0.6854\n",
            "Average Loss for 100 iteration is : 0.765082859992981\n",
            "Average Loss for 200 iteration is : 0.769852534532547\n",
            "Average Loss for 300 iteration is : 0.7734225434064865\n",
            "Average Loss for 400 iteration is : 0.783868647813797\n",
            "Average Loss for 500 iteration is : 0.7875760504603386\n",
            "Average Loss for 600 iteration is : 0.7740103560686111\n",
            "Evaluation Accuracy is : 0.6907\n",
            "Average Loss for 100 iteration is : 0.7601266020536422\n",
            "Average Loss for 200 iteration is : 0.7689936816692352\n",
            "Average Loss for 300 iteration is : 0.7665784227848053\n",
            "Average Loss for 400 iteration is : 0.7813611483573913\n",
            "Average Loss for 500 iteration is : 0.7910576614737511\n",
            "Average Loss for 600 iteration is : 0.7749148041009903\n",
            "Evaluation Accuracy is : 0.6852\n",
            "Average Loss for 100 iteration is : 0.7621388950943947\n",
            "Average Loss for 200 iteration is : 0.7644028532505035\n",
            "Average Loss for 300 iteration is : 0.7776178523898125\n",
            "Average Loss for 400 iteration is : 0.7568605378270149\n",
            "Average Loss for 500 iteration is : 0.7896058261394501\n",
            "Average Loss for 600 iteration is : 0.7731119483709336\n",
            "Evaluation Accuracy is : 0.6931\n",
            "Average Loss for 100 iteration is : 0.7607051092386246\n",
            "Average Loss for 200 iteration is : 0.7720393258333206\n",
            "Average Loss for 300 iteration is : 0.7822261697053909\n",
            "Average Loss for 400 iteration is : 0.7640341225266457\n",
            "Average Loss for 500 iteration is : 0.766287887096405\n",
            "Average Loss for 600 iteration is : 0.7792837914824485\n",
            "Evaluation Accuracy is : 0.6908\n",
            "Average Loss for 100 iteration is : 0.7455921006202698\n",
            "Average Loss for 200 iteration is : 0.7673497477173805\n",
            "Average Loss for 300 iteration is : 0.7653504821658135\n",
            "Average Loss for 400 iteration is : 0.7738018804788589\n",
            "Average Loss for 500 iteration is : 0.7942985203862191\n",
            "Average Loss for 600 iteration is : 0.7823807156085968\n",
            "Evaluation Accuracy is : 0.6907\n",
            "Average Loss for 100 iteration is : 0.7814586073160171\n",
            "Average Loss for 200 iteration is : 0.7570875805616378\n",
            "Average Loss for 300 iteration is : 0.7765829956531525\n",
            "Average Loss for 400 iteration is : 0.7728341245651245\n",
            "Average Loss for 500 iteration is : 0.7694678205251694\n",
            "Average Loss for 600 iteration is : 0.7623619610071182\n",
            "Evaluation Accuracy is : 0.692\n",
            "Average Loss for 100 iteration is : 0.7581660294532776\n",
            "Average Loss for 200 iteration is : 0.759402457177639\n",
            "Average Loss for 300 iteration is : 0.7636201789975167\n",
            "Average Loss for 400 iteration is : 0.8037239027023315\n",
            "Average Loss for 500 iteration is : 0.7845368364453316\n",
            "Average Loss for 600 iteration is : 0.7840523266792297\n",
            "Evaluation Accuracy is : 0.6913\n",
            "Average Loss for 100 iteration is : 0.76555713057518\n",
            "Average Loss for 200 iteration is : 0.7474996426701546\n",
            "Average Loss for 300 iteration is : 0.7786935538053512\n",
            "Average Loss for 400 iteration is : 0.7887736043334007\n",
            "Average Loss for 500 iteration is : 0.78519870698452\n",
            "Average Loss for 600 iteration is : 0.7858135145902634\n",
            "Evaluation Accuracy is : 0.6911\n",
            "Average Loss for 100 iteration is : 0.7484200519323349\n",
            "Average Loss for 200 iteration is : 0.7993149507045746\n",
            "Average Loss for 300 iteration is : 0.7790544885396957\n",
            "Average Loss for 400 iteration is : 0.7933217257261276\n",
            "Average Loss for 500 iteration is : 0.7624480697512627\n",
            "Average Loss for 600 iteration is : 0.763957736492157\n",
            "Evaluation Accuracy is : 0.688\n",
            "Average Loss for 100 iteration is : 0.7924764370918274\n",
            "Average Loss for 200 iteration is : 0.7648699679970741\n",
            "Average Loss for 300 iteration is : 0.7803353595733643\n",
            "Average Loss for 400 iteration is : 0.7847678864002228\n",
            "Average Loss for 500 iteration is : 0.7628843626379966\n",
            "Average Loss for 600 iteration is : 0.7763849979639054\n",
            "Evaluation Accuracy is : 0.6895\n",
            "Average Loss for 100 iteration is : 0.756892628967762\n",
            "Average Loss for 200 iteration is : 0.7671787443757058\n",
            "Average Loss for 300 iteration is : 0.7784245455265045\n",
            "Average Loss for 400 iteration is : 0.7659483435750007\n",
            "Average Loss for 500 iteration is : 0.7991399812698364\n",
            "Average Loss for 600 iteration is : 0.7647282519936561\n",
            "Evaluation Accuracy is : 0.6872\n",
            "Average Loss for 100 iteration is : 0.7893880352377891\n",
            "Average Loss for 200 iteration is : 0.7924183803796768\n",
            "Average Loss for 300 iteration is : 0.7711166730523109\n",
            "Average Loss for 400 iteration is : 0.7602210557460785\n",
            "Average Loss for 500 iteration is : 0.7516679239273071\n",
            "Average Loss for 600 iteration is : 0.7684251388907433\n",
            "Evaluation Accuracy is : 0.6911\n",
            "Average Loss for 100 iteration is : 0.7574889668822289\n",
            "Average Loss for 200 iteration is : 0.7624791541695595\n",
            "Average Loss for 300 iteration is : 0.779713757634163\n",
            "Average Loss for 400 iteration is : 0.7719075098633766\n",
            "Average Loss for 500 iteration is : 0.761826657652855\n",
            "Average Loss for 600 iteration is : 0.7773913419246674\n",
            "Evaluation Accuracy is : 0.688\n",
            "Average Loss for 100 iteration is : 0.7644147464632988\n",
            "Average Loss for 200 iteration is : 0.7705462110042572\n",
            "Average Loss for 300 iteration is : 0.7750820386409759\n",
            "Average Loss for 400 iteration is : 0.765767851471901\n",
            "Average Loss for 500 iteration is : 0.7557565027475357\n",
            "Average Loss for 600 iteration is : 0.7980046367645264\n",
            "Evaluation Accuracy is : 0.6889\n",
            "Average Loss for 100 iteration is : 0.7894915628433228\n",
            "Average Loss for 200 iteration is : 0.7608637344837189\n",
            "Average Loss for 300 iteration is : 0.7677316725254059\n",
            "Average Loss for 400 iteration is : 0.7399654379487037\n",
            "Average Loss for 500 iteration is : 0.778692107796669\n",
            "Average Loss for 600 iteration is : 0.7932072293758392\n",
            "Evaluation Accuracy is : 0.6933\n",
            "Average Loss for 100 iteration is : 0.7714851897954941\n",
            "Average Loss for 200 iteration is : 0.7701510873436928\n",
            "Average Loss for 300 iteration is : 0.7584625574946403\n",
            "Average Loss for 400 iteration is : 0.7660640561580658\n",
            "Average Loss for 500 iteration is : 0.7662009689211845\n",
            "Average Loss for 600 iteration is : 0.7846020513772964\n",
            "Evaluation Accuracy is : 0.6822\n",
            "Average Loss for 100 iteration is : 0.7757043144106865\n",
            "Average Loss for 200 iteration is : 0.7661835107207299\n",
            "Average Loss for 300 iteration is : 0.7583878600597381\n",
            "Average Loss for 400 iteration is : 0.7599162590503693\n",
            "Average Loss for 500 iteration is : 0.7858628135919571\n",
            "Average Loss for 600 iteration is : 0.7683767771720886\n",
            "Evaluation Accuracy is : 0.6958\n",
            "Average Loss for 100 iteration is : 0.7570152080059052\n",
            "Average Loss for 200 iteration is : 0.7622955602407455\n",
            "Average Loss for 300 iteration is : 0.7661058104038239\n",
            "Average Loss for 400 iteration is : 0.7493577879667283\n",
            "Average Loss for 500 iteration is : 0.7694515064358711\n",
            "Average Loss for 600 iteration is : 0.7796570020914078\n",
            "Evaluation Accuracy is : 0.6862\n",
            "Average Loss for 100 iteration is : 0.7739818894863129\n",
            "Average Loss for 200 iteration is : 0.7584930574893951\n",
            "Average Loss for 300 iteration is : 0.7835522943735123\n",
            "Average Loss for 400 iteration is : 0.7785038134455681\n",
            "Average Loss for 500 iteration is : 0.7648207819461823\n",
            "Average Loss for 600 iteration is : 0.7518967652320862\n",
            "Evaluation Accuracy is : 0.6933\n",
            "Average Loss for 100 iteration is : 0.7601614195108414\n",
            "Average Loss for 200 iteration is : 0.765973464846611\n",
            "Average Loss for 300 iteration is : 0.771254563331604\n",
            "Average Loss for 400 iteration is : 0.7750336948037148\n",
            "Average Loss for 500 iteration is : 0.7992949664592743\n",
            "Average Loss for 600 iteration is : 0.7606483554840088\n",
            "Evaluation Accuracy is : 0.6895\n",
            "Average Loss for 100 iteration is : 0.7706242975592613\n",
            "Average Loss for 200 iteration is : 0.7665682578086853\n",
            "Average Loss for 300 iteration is : 0.7776098918914794\n",
            "Average Loss for 400 iteration is : 0.760279332101345\n",
            "Average Loss for 500 iteration is : 0.7692499700188636\n",
            "Average Loss for 600 iteration is : 0.7709545513987541\n",
            "Evaluation Accuracy is : 0.6866\n",
            "Average Loss for 100 iteration is : 0.7765516048669815\n",
            "Average Loss for 200 iteration is : 0.7653880223631859\n",
            "Average Loss for 300 iteration is : 0.764015554189682\n",
            "Average Loss for 400 iteration is : 0.7531570988893509\n",
            "Average Loss for 500 iteration is : 0.7826868277788163\n",
            "Average Loss for 600 iteration is : 0.7845245885848999\n",
            "Evaluation Accuracy is : 0.6897\n",
            "Average Loss for 100 iteration is : 0.755298530459404\n",
            "Average Loss for 200 iteration is : 0.7726131263375282\n",
            "Average Loss for 300 iteration is : 0.7737230855226517\n",
            "Average Loss for 400 iteration is : 0.7507833257317543\n",
            "Average Loss for 500 iteration is : 0.776035141646862\n",
            "Average Loss for 600 iteration is : 0.7737200224399566\n",
            "Evaluation Accuracy is : 0.6941\n",
            "Average Loss for 100 iteration is : 0.7260385516285897\n",
            "Average Loss for 200 iteration is : 0.7916098958253861\n",
            "Average Loss for 300 iteration is : 0.7728992635011673\n",
            "Average Loss for 400 iteration is : 0.7717146930098534\n",
            "Average Loss for 500 iteration is : 0.772615076303482\n",
            "Average Loss for 600 iteration is : 0.7817652064561844\n",
            "Evaluation Accuracy is : 0.6938\n",
            "Average Loss for 100 iteration is : 0.7701098814606666\n",
            "Average Loss for 200 iteration is : 0.7797450193762779\n",
            "Average Loss for 300 iteration is : 0.7894426485896111\n",
            "Average Loss for 400 iteration is : 0.7396989953517914\n",
            "Average Loss for 500 iteration is : 0.7521404406428337\n",
            "Average Loss for 600 iteration is : 0.7814382201433182\n",
            "Evaluation Accuracy is : 0.6923\n",
            "Average Loss for 100 iteration is : 0.7589770269393921\n",
            "Average Loss for 200 iteration is : 0.7679313403367997\n",
            "Average Loss for 300 iteration is : 0.7979115635156632\n",
            "Average Loss for 400 iteration is : 0.7389431113004684\n",
            "Average Loss for 500 iteration is : 0.7609999772906303\n",
            "Average Loss for 600 iteration is : 0.7701086664199829\n",
            "Evaluation Accuracy is : 0.6917\n",
            "Average Loss for 100 iteration is : 0.7468380501866341\n",
            "Average Loss for 200 iteration is : 0.7750582104921341\n",
            "Average Loss for 300 iteration is : 0.7604968705773354\n",
            "Average Loss for 400 iteration is : 0.7792280757427216\n",
            "Average Loss for 500 iteration is : 0.7627329635620117\n",
            "Average Loss for 600 iteration is : 0.771437435746193\n",
            "Evaluation Accuracy is : 0.6908\n",
            "Average Loss for 100 iteration is : 0.7608748084306717\n",
            "Average Loss for 200 iteration is : 0.7665314674377441\n",
            "Average Loss for 300 iteration is : 0.7724746364355087\n",
            "Average Loss for 400 iteration is : 0.767530026435852\n",
            "Average Loss for 500 iteration is : 0.7428646180033683\n",
            "Average Loss for 600 iteration is : 0.7756782305240632\n",
            "Evaluation Accuracy is : 0.6861\n",
            "Average Loss for 100 iteration is : 0.7609522625803947\n",
            "Average Loss for 200 iteration is : 0.7548020216822624\n",
            "Average Loss for 300 iteration is : 0.7814105108380318\n",
            "Average Loss for 400 iteration is : 0.7565941840410233\n",
            "Average Loss for 500 iteration is : 0.7761175990104675\n",
            "Average Loss for 600 iteration is : 0.7733961349725723\n",
            "Evaluation Accuracy is : 0.692\n",
            "Average Loss for 100 iteration is : 0.7645167496800422\n",
            "Average Loss for 200 iteration is : 0.7549673664569855\n",
            "Average Loss for 300 iteration is : 0.7813406759500503\n",
            "Average Loss for 400 iteration is : 0.7442086562514305\n",
            "Average Loss for 500 iteration is : 0.7772924304008484\n",
            "Average Loss for 600 iteration is : 0.790567684173584\n",
            "Evaluation Accuracy is : 0.6962\n",
            "Average Loss for 100 iteration is : 0.7507283392548562\n",
            "Average Loss for 200 iteration is : 0.7711113786697388\n",
            "Average Loss for 300 iteration is : 0.7703827470541\n",
            "Average Loss for 400 iteration is : 0.7673501786589623\n",
            "Average Loss for 500 iteration is : 0.7715583696961403\n",
            "Average Loss for 600 iteration is : 0.7569475644826889\n",
            "Evaluation Accuracy is : 0.6881\n",
            "Average Loss for 100 iteration is : 0.758094294667244\n",
            "Average Loss for 200 iteration is : 0.7692678105831147\n",
            "Average Loss for 300 iteration is : 0.7629601994156837\n",
            "Average Loss for 400 iteration is : 0.7607070690393448\n",
            "Average Loss for 500 iteration is : 0.768055607676506\n",
            "Average Loss for 600 iteration is : 0.7662271958589554\n",
            "Evaluation Accuracy is : 0.6959\n",
            "Average Loss for 100 iteration is : 0.7588729584217071\n",
            "Average Loss for 200 iteration is : 0.7556320026516914\n",
            "Average Loss for 300 iteration is : 0.7675781938433647\n",
            "Average Loss for 400 iteration is : 0.7597685897350311\n",
            "Average Loss for 500 iteration is : 0.7795050179958344\n",
            "Average Loss for 600 iteration is : 0.7523662373423576\n",
            "Evaluation Accuracy is : 0.6961\n",
            "Average Loss for 100 iteration is : 0.758031659424305\n",
            "Average Loss for 200 iteration is : 0.7603314203023911\n",
            "Average Loss for 300 iteration is : 0.7599667418003082\n",
            "Average Loss for 400 iteration is : 0.7653665614128112\n",
            "Average Loss for 500 iteration is : 0.7625344032049179\n",
            "Average Loss for 600 iteration is : 0.7939302974939346\n",
            "Evaluation Accuracy is : 0.6899\n",
            "Average Loss for 100 iteration is : 0.7489591711759567\n",
            "Average Loss for 200 iteration is : 0.7769760146737099\n",
            "Average Loss for 300 iteration is : 0.7466870215535164\n",
            "Average Loss for 400 iteration is : 0.7579480367898941\n",
            "Average Loss for 500 iteration is : 0.7578362190723419\n",
            "Average Loss for 600 iteration is : 0.7599600720405578\n",
            "Evaluation Accuracy is : 0.6942\n",
            "Average Loss for 100 iteration is : 0.7359665933251381\n",
            "Average Loss for 200 iteration is : 0.7755718377232551\n",
            "Average Loss for 300 iteration is : 0.78294478058815\n",
            "Average Loss for 400 iteration is : 0.7764720714092255\n",
            "Average Loss for 500 iteration is : 0.7740175288915634\n",
            "Average Loss for 600 iteration is : 0.7774568024277687\n",
            "Evaluation Accuracy is : 0.6794\n",
            "Average Loss for 100 iteration is : 0.7473267090320587\n",
            "Average Loss for 200 iteration is : 0.7769211021065712\n",
            "Average Loss for 300 iteration is : 0.7739630353450775\n",
            "Average Loss for 400 iteration is : 0.7797843670845032\n",
            "Average Loss for 500 iteration is : 0.7539175096154213\n",
            "Average Loss for 600 iteration is : 0.7692343145608902\n",
            "Evaluation Accuracy is : 0.7017\n",
            "Average Loss for 100 iteration is : 0.762375813126564\n",
            "Average Loss for 200 iteration is : 0.7541167783737183\n",
            "Average Loss for 300 iteration is : 0.7667351561784744\n",
            "Average Loss for 400 iteration is : 0.7414884775876999\n",
            "Average Loss for 500 iteration is : 0.7605670094490051\n",
            "Average Loss for 600 iteration is : 0.7567081013321877\n",
            "Evaluation Accuracy is : 0.6873\n",
            "Average Loss for 100 iteration is : 0.7555364865064621\n",
            "Average Loss for 200 iteration is : 0.763011400103569\n",
            "Average Loss for 300 iteration is : 0.7860516321659088\n",
            "Average Loss for 400 iteration is : 0.7668067812919617\n",
            "Average Loss for 500 iteration is : 0.76493925511837\n",
            "Average Loss for 600 iteration is : 0.7442930084466934\n",
            "Evaluation Accuracy is : 0.6887\n",
            "Average Loss for 100 iteration is : 0.7507687592506409\n",
            "Average Loss for 200 iteration is : 0.7487784725427628\n",
            "Average Loss for 300 iteration is : 0.7606430357694626\n",
            "Average Loss for 400 iteration is : 0.768019117116928\n",
            "Average Loss for 500 iteration is : 0.7682437306642532\n",
            "Average Loss for 600 iteration is : 0.7779823642969131\n",
            "Evaluation Accuracy is : 0.6844\n",
            "Average Loss for 100 iteration is : 0.7581619855761528\n",
            "Average Loss for 200 iteration is : 0.7577779188752174\n",
            "Average Loss for 300 iteration is : 0.7767731416225433\n",
            "Average Loss for 400 iteration is : 0.7595630651712417\n",
            "Average Loss for 500 iteration is : 0.7892836731672287\n",
            "Average Loss for 600 iteration is : 0.7711069890856743\n",
            "Evaluation Accuracy is : 0.6969\n",
            "Average Loss for 100 iteration is : 0.7676209151744843\n",
            "Average Loss for 200 iteration is : 0.7421713954210282\n",
            "Average Loss for 300 iteration is : 0.7746387034654617\n",
            "Average Loss for 400 iteration is : 0.7288485163450241\n",
            "Average Loss for 500 iteration is : 0.790118108689785\n",
            "Average Loss for 600 iteration is : 0.771810136437416\n",
            "Evaluation Accuracy is : 0.695\n",
            "Average Loss for 100 iteration is : 0.7543851706385613\n",
            "Average Loss for 200 iteration is : 0.7508590811491013\n",
            "Average Loss for 300 iteration is : 0.7693929335474968\n",
            "Average Loss for 400 iteration is : 0.7586369526386261\n",
            "Average Loss for 500 iteration is : 0.748121063709259\n",
            "Average Loss for 600 iteration is : 0.7696164482831955\n",
            "Evaluation Accuracy is : 0.695\n",
            "Average Loss for 100 iteration is : 0.7293401822447777\n",
            "Average Loss for 200 iteration is : 0.7560257166624069\n",
            "Average Loss for 300 iteration is : 0.7671872135996819\n",
            "Average Loss for 400 iteration is : 0.7746417638659477\n",
            "Average Loss for 500 iteration is : 0.7713918480277061\n",
            "Average Loss for 600 iteration is : 0.7665823656320572\n",
            "Evaluation Accuracy is : 0.6977\n",
            "Average Loss for 100 iteration is : 0.7343285614252091\n",
            "Average Loss for 200 iteration is : 0.7481929486989976\n",
            "Average Loss for 300 iteration is : 0.7742393428087234\n",
            "Average Loss for 400 iteration is : 0.7680591407418251\n",
            "Average Loss for 500 iteration is : 0.7698443788290024\n",
            "Average Loss for 600 iteration is : 0.7589021402597428\n",
            "Evaluation Accuracy is : 0.6974\n",
            "Average Loss for 100 iteration is : 0.738566045165062\n",
            "Average Loss for 200 iteration is : 0.7672500029206276\n",
            "Average Loss for 300 iteration is : 0.7898953449726105\n",
            "Average Loss for 400 iteration is : 0.7531321033835411\n",
            "Average Loss for 500 iteration is : 0.746189275085926\n",
            "Average Loss for 600 iteration is : 0.781506040096283\n",
            "Evaluation Accuracy is : 0.6891\n",
            "Average Loss for 100 iteration is : 0.7714188379049302\n",
            "Average Loss for 200 iteration is : 0.7630184006690979\n",
            "Average Loss for 300 iteration is : 0.7478813827037811\n",
            "Average Loss for 400 iteration is : 0.7991312900185585\n",
            "Average Loss for 500 iteration is : 0.7577487236261368\n",
            "Average Loss for 600 iteration is : 0.7490574020147324\n",
            "Evaluation Accuracy is : 0.6956\n",
            "Average Loss for 100 iteration is : 0.7435805198550224\n",
            "Average Loss for 200 iteration is : 0.7585227799415588\n",
            "Average Loss for 300 iteration is : 0.7458706957101822\n",
            "Average Loss for 400 iteration is : 0.7512435835599899\n",
            "Average Loss for 500 iteration is : 0.7668328875303269\n",
            "Average Loss for 600 iteration is : 0.7949747115373611\n",
            "Evaluation Accuracy is : 0.6924\n",
            "Average Loss for 100 iteration is : 0.7814122012257576\n",
            "Average Loss for 200 iteration is : 0.7621808731555939\n",
            "Average Loss for 300 iteration is : 0.7412602233886719\n",
            "Average Loss for 400 iteration is : 0.7691036131978035\n",
            "Average Loss for 500 iteration is : 0.7669184392690659\n",
            "Average Loss for 600 iteration is : 0.7524970677495003\n",
            "Evaluation Accuracy is : 0.6938\n",
            "Average Loss for 100 iteration is : 0.7595675653219223\n",
            "Average Loss for 200 iteration is : 0.7681628996133805\n",
            "Average Loss for 300 iteration is : 0.7630374774336814\n",
            "Average Loss for 400 iteration is : 0.7552846947312355\n",
            "Average Loss for 500 iteration is : 0.7830919408798218\n",
            "Average Loss for 600 iteration is : 0.7550720334053039\n",
            "Evaluation Accuracy is : 0.6988\n",
            "Average Loss for 100 iteration is : 0.7400193411111832\n",
            "Average Loss for 200 iteration is : 0.7641789251565934\n",
            "Average Loss for 300 iteration is : 0.7618409493565559\n",
            "Average Loss for 400 iteration is : 0.761423727273941\n",
            "Average Loss for 500 iteration is : 0.7601077622175216\n",
            "Average Loss for 600 iteration is : 0.7659351277351379\n",
            "Evaluation Accuracy is : 0.6872\n",
            "Average Loss for 100 iteration is : 0.7543932887911796\n",
            "Average Loss for 200 iteration is : 0.7628592529892921\n",
            "Average Loss for 300 iteration is : 0.7634603697061538\n",
            "Average Loss for 400 iteration is : 0.7463399478793145\n",
            "Average Loss for 500 iteration is : 0.7558915001153946\n",
            "Average Loss for 600 iteration is : 0.7649931275844574\n",
            "Evaluation Accuracy is : 0.6938\n",
            "Average Loss for 100 iteration is : 0.7758212649822235\n",
            "Average Loss for 200 iteration is : 0.7534327310323715\n",
            "Average Loss for 300 iteration is : 0.7538227578997612\n",
            "Average Loss for 400 iteration is : 0.7625126731395722\n",
            "Average Loss for 500 iteration is : 0.7518655768036843\n",
            "Average Loss for 600 iteration is : 0.7710806626081467\n",
            "Evaluation Accuracy is : 0.6935\n",
            "Average Loss for 100 iteration is : 0.7656151375174522\n",
            "Average Loss for 200 iteration is : 0.7571845582127571\n",
            "Average Loss for 300 iteration is : 0.7777121528983116\n",
            "Average Loss for 400 iteration is : 0.7456339916586876\n",
            "Average Loss for 500 iteration is : 0.7742434030771256\n",
            "Average Loss for 600 iteration is : 0.7399869304895401\n",
            "Evaluation Accuracy is : 0.6944\n",
            "Average Loss for 100 iteration is : 0.7617647930979728\n",
            "Average Loss for 200 iteration is : 0.7619490712881088\n",
            "Average Loss for 300 iteration is : 0.7668975180387497\n",
            "Average Loss for 400 iteration is : 0.7789312893152237\n",
            "Average Loss for 500 iteration is : 0.770152696967125\n",
            "Average Loss for 600 iteration is : 0.7508565831184387\n",
            "Evaluation Accuracy is : 0.6851\n",
            "Average Loss for 100 iteration is : 0.7638483619689942\n",
            "Average Loss for 200 iteration is : 0.7602451574802399\n",
            "Average Loss for 300 iteration is : 0.7606832879781723\n",
            "Average Loss for 400 iteration is : 0.7812216028571128\n",
            "Average Loss for 500 iteration is : 0.7578887945413589\n",
            "Average Loss for 600 iteration is : 0.7697130814194679\n",
            "Evaluation Accuracy is : 0.6926\n",
            "Average Loss for 100 iteration is : 0.7496929997205735\n",
            "Average Loss for 200 iteration is : 0.7439323872327804\n",
            "Average Loss for 300 iteration is : 0.7523459595441818\n",
            "Average Loss for 400 iteration is : 0.7543219006061554\n",
            "Average Loss for 500 iteration is : 0.7558231496810913\n",
            "Average Loss for 600 iteration is : 0.7496897315979004\n",
            "Evaluation Accuracy is : 0.6927\n",
            "Average Loss for 100 iteration is : 0.7384921509027481\n",
            "Average Loss for 200 iteration is : 0.7720064806938172\n",
            "Average Loss for 300 iteration is : 0.7412447139620781\n",
            "Average Loss for 400 iteration is : 0.7651589208841324\n",
            "Average Loss for 500 iteration is : 0.7664039438962936\n",
            "Average Loss for 600 iteration is : 0.7575511115789414\n",
            "Evaluation Accuracy is : 0.6927\n",
            "Average Loss for 100 iteration is : 0.7763156905770302\n",
            "Average Loss for 200 iteration is : 0.7476658719778061\n",
            "Average Loss for 300 iteration is : 0.7383700355887413\n",
            "Average Loss for 400 iteration is : 0.7660866361856461\n",
            "Average Loss for 500 iteration is : 0.7802360045909882\n",
            "Average Loss for 600 iteration is : 0.7588006806373596\n",
            "Evaluation Accuracy is : 0.6936\n",
            "Average Loss for 100 iteration is : 0.7422467324137688\n",
            "Average Loss for 200 iteration is : 0.7499276614189148\n",
            "Average Loss for 300 iteration is : 0.7496169489622116\n",
            "Average Loss for 400 iteration is : 0.7566928344964982\n",
            "Average Loss for 500 iteration is : 0.7599158054590225\n",
            "Average Loss for 600 iteration is : 0.763092320561409\n",
            "Evaluation Accuracy is : 0.6928\n",
            "Average Loss for 100 iteration is : 0.7719071942567826\n",
            "Average Loss for 200 iteration is : 0.7503803843259811\n",
            "Average Loss for 300 iteration is : 0.7428860971331597\n",
            "Average Loss for 400 iteration is : 0.7510142004489899\n",
            "Average Loss for 500 iteration is : 0.7664287346601486\n",
            "Average Loss for 600 iteration is : 0.7676109835505486\n",
            "Evaluation Accuracy is : 0.6863\n",
            "Average Loss for 100 iteration is : 0.7485335078835488\n",
            "Average Loss for 200 iteration is : 0.7565328168869019\n",
            "Average Loss for 300 iteration is : 0.7350620305538178\n",
            "Average Loss for 400 iteration is : 0.7582278960943222\n",
            "Average Loss for 500 iteration is : 0.7480118983983993\n",
            "Average Loss for 600 iteration is : 0.7623118144273758\n",
            "Evaluation Accuracy is : 0.6903\n",
            "Average Loss for 100 iteration is : 0.7544299647212028\n",
            "Average Loss for 200 iteration is : 0.7592557775974274\n",
            "Average Loss for 300 iteration is : 0.7702031055092812\n",
            "Average Loss for 400 iteration is : 0.7584913042187691\n",
            "Average Loss for 500 iteration is : 0.7530530831217765\n",
            "Average Loss for 600 iteration is : 0.7540480786561966\n",
            "Evaluation Accuracy is : 0.6877\n",
            "Average Loss for 100 iteration is : 0.7264028003811837\n",
            "Average Loss for 200 iteration is : 0.7478054350614548\n",
            "Average Loss for 300 iteration is : 0.7625014021992683\n",
            "Average Loss for 400 iteration is : 0.7566456100344658\n",
            "Average Loss for 500 iteration is : 0.7535981309413909\n",
            "Average Loss for 600 iteration is : 0.7743919545412064\n",
            "Evaluation Accuracy is : 0.6899\n",
            "Average Loss for 100 iteration is : 0.7485000360012054\n",
            "Average Loss for 200 iteration is : 0.7431091040372848\n",
            "Average Loss for 300 iteration is : 0.744799236357212\n",
            "Average Loss for 400 iteration is : 0.7695706725120545\n",
            "Average Loss for 500 iteration is : 0.7618096673488617\n",
            "Average Loss for 600 iteration is : 0.7523112338781357\n",
            "Evaluation Accuracy is : 0.6907\n",
            "Average Loss for 100 iteration is : 0.7367175024747848\n",
            "Average Loss for 200 iteration is : 0.7418513184785843\n",
            "Average Loss for 300 iteration is : 0.7552457201480866\n",
            "Average Loss for 400 iteration is : 0.7428843173384666\n",
            "Average Loss for 500 iteration is : 0.7652287217974663\n",
            "Average Loss for 600 iteration is : 0.7872718885540962\n",
            "Evaluation Accuracy is : 0.6931\n",
            "Average Loss for 100 iteration is : 0.7579013133049011\n",
            "Average Loss for 200 iteration is : 0.7586125886440277\n",
            "Average Loss for 300 iteration is : 0.7540229448676109\n",
            "Average Loss for 400 iteration is : 0.7617837873101234\n",
            "Average Loss for 500 iteration is : 0.7472313100099564\n",
            "Average Loss for 600 iteration is : 0.7425275966525078\n",
            "Evaluation Accuracy is : 0.6914\n",
            "Average Loss for 100 iteration is : 0.7520807296037674\n",
            "Average Loss for 200 iteration is : 0.7340452957153321\n",
            "Average Loss for 300 iteration is : 0.7644301837682724\n",
            "Average Loss for 400 iteration is : 0.760724064707756\n",
            "Average Loss for 500 iteration is : 0.7511071670055389\n",
            "Average Loss for 600 iteration is : 0.7511253425478935\n",
            "Evaluation Accuracy is : 0.6923\n",
            "Average Loss for 100 iteration is : 0.750651767551899\n",
            "Average Loss for 200 iteration is : 0.7464723813533783\n",
            "Average Loss for 300 iteration is : 0.769236518740654\n",
            "Average Loss for 400 iteration is : 0.7284635007381439\n",
            "Average Loss for 500 iteration is : 0.7746027904748917\n",
            "Average Loss for 600 iteration is : 0.7498529869318008\n",
            "Evaluation Accuracy is : 0.6983\n",
            "Average Loss for 100 iteration is : 0.7641491079330445\n",
            "Average Loss for 200 iteration is : 0.7251484271883964\n",
            "Average Loss for 300 iteration is : 0.749440250992775\n",
            "Average Loss for 400 iteration is : 0.7607552796602249\n",
            "Average Loss for 500 iteration is : 0.7445965641736985\n",
            "Average Loss for 600 iteration is : 0.7340531325340272\n",
            "Evaluation Accuracy is : 0.6911\n",
            "Average Loss for 100 iteration is : 0.741830926835537\n",
            "Average Loss for 200 iteration is : 0.7371847680211068\n",
            "Average Loss for 300 iteration is : 0.7452878677845001\n",
            "Average Loss for 400 iteration is : 0.7810717868804932\n",
            "Average Loss for 500 iteration is : 0.7499568727612496\n",
            "Average Loss for 600 iteration is : 0.7491197347640991\n",
            "Evaluation Accuracy is : 0.7001\n",
            "Average Loss for 100 iteration is : 0.774385977089405\n",
            "Average Loss for 200 iteration is : 0.7657411932945252\n",
            "Average Loss for 300 iteration is : 0.7516325682401657\n",
            "Average Loss for 400 iteration is : 0.739217629134655\n",
            "Average Loss for 500 iteration is : 0.7615099626779557\n",
            "Average Loss for 600 iteration is : 0.7487216782569885\n",
            "Evaluation Accuracy is : 0.7004\n",
            "Average Loss for 100 iteration is : 0.7517189526557922\n",
            "Average Loss for 200 iteration is : 0.7552990370988846\n",
            "Average Loss for 300 iteration is : 0.757169015109539\n",
            "Average Loss for 400 iteration is : 0.7667302191257477\n",
            "Average Loss for 500 iteration is : 0.7664973545074463\n",
            "Average Loss for 600 iteration is : 0.7270234957337379\n",
            "Evaluation Accuracy is : 0.688\n",
            "Average Loss for 100 iteration is : 0.7545486280322075\n",
            "Average Loss for 200 iteration is : 0.7372010028362275\n",
            "Average Loss for 300 iteration is : 0.7659456598758697\n",
            "Average Loss for 400 iteration is : 0.7799409872293472\n",
            "Average Loss for 500 iteration is : 0.7385663205385208\n",
            "Average Loss for 600 iteration is : 0.7525635278224945\n",
            "Evaluation Accuracy is : 0.694\n",
            "Average Loss for 100 iteration is : 0.7299697449803353\n",
            "Average Loss for 200 iteration is : 0.7412024602293968\n",
            "Average Loss for 300 iteration is : 0.7535791221261025\n",
            "Average Loss for 400 iteration is : 0.762708537876606\n",
            "Average Loss for 500 iteration is : 0.7620940971374511\n",
            "Average Loss for 600 iteration is : 0.7652076324820518\n",
            "Evaluation Accuracy is : 0.6937\n",
            "Average Loss for 100 iteration is : 0.7449841448664665\n",
            "Average Loss for 200 iteration is : 0.7742307612299919\n",
            "Average Loss for 300 iteration is : 0.7497378435730934\n",
            "Average Loss for 400 iteration is : 0.739654751420021\n",
            "Average Loss for 500 iteration is : 0.7497833484411239\n",
            "Average Loss for 600 iteration is : 0.7697258260846138\n",
            "Evaluation Accuracy is : 0.7002\n",
            "Average Loss for 100 iteration is : 0.7243156933784485\n",
            "Average Loss for 200 iteration is : 0.7569088131189347\n",
            "Average Loss for 300 iteration is : 0.7417525032162666\n",
            "Average Loss for 400 iteration is : 0.7547032219171524\n",
            "Average Loss for 500 iteration is : 0.7414196634292602\n",
            "Average Loss for 600 iteration is : 0.7745697742700577\n",
            "Evaluation Accuracy is : 0.6978\n",
            "Average Loss for 100 iteration is : 0.7469974315166473\n",
            "Average Loss for 200 iteration is : 0.7493344292044639\n",
            "Average Loss for 300 iteration is : 0.7632429230213166\n",
            "Average Loss for 400 iteration is : 0.7641301846504212\n",
            "Average Loss for 500 iteration is : 0.7381494084000587\n",
            "Average Loss for 600 iteration is : 0.7486093783378601\n",
            "Evaluation Accuracy is : 0.6909\n",
            "Average Loss for 100 iteration is : 0.7613026779890061\n",
            "Average Loss for 200 iteration is : 0.7412462210655213\n",
            "Average Loss for 300 iteration is : 0.7462076658010482\n",
            "Average Loss for 400 iteration is : 0.7485272598266601\n",
            "Average Loss for 500 iteration is : 0.7682766070961953\n",
            "Average Loss for 600 iteration is : 0.74324602663517\n",
            "Evaluation Accuracy is : 0.6958\n",
            "Average Loss for 100 iteration is : 0.7232612842321395\n",
            "Average Loss for 200 iteration is : 0.7607619705796241\n"
          ]
        }
      ]
    }
  ]
}